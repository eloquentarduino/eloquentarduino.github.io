{
    "version": "https://jsonfeed.org/version/1.1",
    "user_comment": "This feed allows you to read the posts from this site in any feed reader that supports the JSON Feed format. To add this feed to your reader, copy the following URL -- https://eloquentarduino.github.io/category/programming/feed/json/ -- and add it your reader.",
    "home_page_url": "https://eloquentarduino.github.io/category/programming/",
    "feed_url": "https://eloquentarduino.github.io/category/programming/feed/json/",
    "language": "en-US",
    "title": "Programming &#8211; Eloquent Arduino Blog",
    "description": "Machine learning on Arduino, programming &amp; electronics",
    "items": [
        {
            "id": "https://eloquentarduino.github.io/?p=1282",
            "url": "https://eloquentarduino.github.io/2020/08/better-word-classification-with-arduino-33-ble-sense-and-machine-learning/",
            "title": "Better word classification with Arduino Nano 33 BLE Sense and Machine Learning",
            "content_html": "<p>Let's revamp the post I wrote about <a href=\"/2019/12/word-classification-using-arduino/\">word classification using Machine Learning on Arduino</a>, this time using a proper microphone (the MP34DT05 mounted on the Arduino Nano 33 BLE Sense) instead of a chinese, analog one: will the results improve?</p>\n<div id=\"attachment_653\" style=\"width: 760px\" class=\"wp-caption alignnone\"><img aria-describedby=\"caption-attachment-653\" src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/WakeWord.jpg\" width=\"750\" height=\"422\" class=\"size-full wp-image-653\" srcset=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/WakeWord.jpg 750w, https://eloquentarduino.github.io/wp-content/uploads/2019/12/WakeWord-300x169.jpg 300w\" sizes=\"(max-width: 750px) 100vw, 750px\" /><p id=\"caption-attachment-653\" class=\"wp-caption-text\">from https://www.udemy.com/course/learn-audio-processing-complete-engineers-course/</p></div>\n<p><span id=\"more-1282\"></span></p>\n<p><div class=\"toc\"><h6>Table of contents</h6><ol><li><a href=\"#tocpulse-density-modulation-a-k-a-pdm\">Pulse-density modulation (a.k.a. PDM)</a><ol><li><a href=\"#tocwheres-the-fft\">Where's the FFT?</a></li></ol><li><a href=\"#tocmachine-learning-model\">Machine learning model</a></ol></div></p>\n<h2 id=\"tocpulse-density-modulation-a-k-a-pdm\">Pulse-density modulation (a.k.a. PDM)</h2>\n<p>In the original post, I used an analog microphone to record the audio. It is for sure the easiest way to interact with audio on a microcontroller since you only need to <code>analogRead()</code> the selected pin to get a value from the sensor.</p>\n<p>This semplicity, however, comes at the cost of a nearly inexistent signal pre-processing from the sensor itself: most of the time, you will get junk - I don't want to be rude, but that's it.</p>\n<p>The microphone mounted on the Arduino Nano 33 BLE Sense (the <a href=\"https://content.arduino.cc/assets/Nano_BLE_Sense_mp34dt05-a.pdf\">MP34DT05</a>), gives you access to modulated signal much more suitable for our processing needs.</p>\n<p>The modulation used is Pulse-density: I won't try to explain you how this works since I'm not an expert in DSP and neither it is the main scope of this article (refer to <a href=\"https://en.wikipedia.org/wiki/Pulse-density_modulation\">Wikipedia</a> for some more information).</p>\n<p>What matters to us is that we can grab an array of bytes from the microphone and extract its <a href=\"https://en.wikipedia.org/wiki/Root_mean_square\">Root Mean Square</a> (a.k.a. RMS) to be used as a feature for our Machine Learning model.</p>\n<p>I had some difficulty finding examples on how to access the microphone on the Arduino Nano 33 BLE Sense board: fortunately, there's a <a href=\"https://github.com/DaleGia/nano-33-sense-serial-example\">Github repo</a> from <em>DelaGia</em> that shows how to access all the sensors of the board.</p>\n<p>I extracted the microphone part and incapsulated it in an easy to use class, so you don't really need to dig into the implementation details if you're not interested.</p>\n<p>The following code extract highlights the steps you need to access the microphone recordings.</p>\n<pre><code class=\"language-cpp\">// you&#039;ll find this file in the Github repo\n#include &quot;Mic.h&quot;\n\n// tune these constants to your needs\n#define SAMPLES 64\n#define SOUND_THRESHOLD 1500\n\nfloat features[SAMPLES];\nMic mic;\n\n/**\n *\n */\nvoid setup() {\n    Serial.begin(115200);\n    // the PDM library is asynchronous, so we need a callback\n    PDM.onReceive(onAudio);\n    mic.begin();\n}\n\n/**\n * PDM callback to update mic object\n */\nvoid onAudio() {\n    mic.update();\n}\n\n/**\n * Read given number of samples from mic\n */\nbool record() {\n    if (mic.hasData() &amp;&amp; mic.pop() &gt; SOUND_THRESHOLD) {\n        for (int i = 0; i &lt; SAMPLES; i++) {\n            while (!mic.hasData()) ; // wait for data\n\n            features[i] = mic.pop();\n        }\n\n        return true;\n    }\n\n    return false;\n}</code></pre>\n<p>The things to note in the above code are:</p>\n<ul>\n<li>the <code>PDM</code> library works asynchronously: it won't block your main code waiting for data, but will report you back when data is ready calling the callback you define. In this case, the callback just instructs the <code>mic</code> object to update</li>\n<li>since the <code>PDM</code> is asynchronous, when acquiring data you will first check if it's available: this is the case for <code>while (!mic.hasData()) ;</code>, which loops awaiting for new data</li>\n</ul>\n<p>Now that we have the acquisition logic in place, it's time for you to record some samples of the words you want to classify. I advise you to record many samples for each word, varying both the distance of your mounth from the mic and the intensity with which you speak: this will produce a more robust classification model later on.</p>\n<p>As always, save each word in a different file, one feature vector per row.</p>\n<p>Here I report an extract of the features I recorded for some words (scaled and converted to int).</p>\n<pre><code>// word &quot;yes&quot;\n43,47,41,48,60,68,67,54,40,29,17,9,6,6,10,15,10,10,8,8,8,5,7,7,12,6,8,11,7,5,3,3,13,14,15,17,15,16,10,10,16,13,8,9,14,8,0,3,3,3,8,5,3,8,11,10,12,10,11,13,8,6,5,12\n34,47,50,51,60,67,65,63,54,42,30,19,25,22,28,7,6,5,7,7,5,8,6,3,3,3,6,7,3,0,0,0,3,5,5,3,5,3,3,3,0,6,3,0,0,5,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,3,0,5\n33,41,45,47,53,61,64,59,50,41,31,17,8,9,7,9,9,7,8,8,8,10,13,8,8,7,5,5,5,3,0,0,0,0,3,8,8,3,0,3,5,5,5,7,0,0,0,0,0,5,0,3,3,5,0,0,0,5,3,0,5,7,0,9\n38,44,48,55,67,74,66,65,60,48,38,19,12,12,8,8,6,7,5,6,6,6,3,3,3,3,5,3,5,3,6,5,0,3,5,0,0,0,3,0,5,3,0,3,0,0,5,6,3,5,3,5,0,0,0,5,3,0,0,0,0,0,0,0\n\n// word &quot;no&quot;\n35,47,49,55,63,65,68,64,60,59,58,41,29,22,14,8,7,5,8,6,0,3,0,0,3,3,0,3,0,0,0,5,3,0,0,0,0,0,0,0,0,0,5,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,7,5,5,3\n42,51,55,59,68,70,73,70,71,67,67,52,52,29,16,9,6,9,3,3,5,8,8,11,10,7,8,5,3,3,0,0,0,0,0,3,3,3,6,7,7,8,9,6,8,8,7,8,6,8,8,6,8,7,6,9,5,3,5,6,5,3,3,3\n56,68,78,91,84,84,84,74,69,64,57,44,33,18,12,8,5,9,15,12,12,9,12,7,3,10,12,6,3,0,0,0,0,6,3,6,10,10,8,3,9,9,9,8,9,9,11,3,8,9,8,8,8,6,7,3,3,8,5,3,0,3,0,0\n31,42,62,69,74,81,78,78,79,74,74,68,54,44,26,15,8,8,21,10,15,12,11,8,6,5,0,0,0,0,3,5,8,3,9,5,6,9,10,6,10,12,7,15,14,5,8,7,8,9,5,8,5,6,5,0,3,6,3,5,3,5,0,0\n\n// word &quot;play&quot;\n31,195,106,60,45,44,55,51,42,36,36,33,38,37,37,29,24,21,20,20,18,19,14,10,14,12,18,11,8,11,10,12,27,8,10,6,7,6,10,6,6,6,8,6,6,3,5,6,0,0,0,0,0,7,5,3,0,5,0,0,8,8,7,5\n138,158,83,64,44,34,36,41,44,39,35,29,27,26,28,33,33,30,23,19,22,18,16,15,15,13,13,14,9,10,9,7,14,8,3,9,0,0,0,3,5,3,7,7,5,0,0,0,5,0,0,3,5,0,0,0,0,10,3,3,7,7,8,3\n89,36,27,30,22,24,38,41,37,33,32,32,32,35,34,30,25,19,18,18,15,16,14,14,12,9,8,10,9,7,3,0,0,8,7,7,6,3,5,9,8,5,7,3,5,7,6,6,3,0,3,3,0,8,8,5,6,0,0,6,0,7,8,6\n71,98,51,31,27,35,48,50,45,38,34,30,31,30,36,35,28,21,20,16,15,16,16,14,12,10,12,10,8,8,6,7,5,7,12,6,10,10,10,8,8,0,0,8,7,0,5,6,3,0,5,3,0,0,3,5,8,6,5,3,10,3,6,0\n\n// word &quot;stop&quot;\n61,93,135,157,140,148,128,92,85,64,160,75,23,28,28,22,14,8,0,3,3,5,3,6,12,202,154,100,102,94,40,54,52,40,35,22,20,19,11,18,9,7,10,12,8,7,5,7,12,14,16,12,8,6,5,11,5,7,9,10,12,21,20,16\n62,84,110,111,113,99,79,70,60,95,71,22,14,19,16,16,6,12,9,7,3,0,3,6,184,209,116,50,33,49,47,45,32,28,21,16,13,13,3,0,0,8,21,14,10,19,19,15,16,15,22,14,14,14,17,14,12,10,3,9,17,11,10,12\n94,139,168,178,165,143,100,82,128,169,34,22,26,26,22,13,8,8,3,0,3,0,5,202,191,123,119,119,64,31,71,39,35,30,19,16,14,8,19,7,8,7,6,11,18,17,13,20,24,27,29,22,23,22,25,23,21,23,21,18,17,14,14,13\n121,159,181,165,170,154,134,99,75,121,51,8,27,14,18,10,7,3,5,0,5,3,6,11,152,118,160,115,68,42,29,36,53,35,38,30,26,22,19,12,7,6,0,0,0,6,11,15,17,19,18,24,22,24,23,16,15,20,22,12,10,16,21,14</code></pre>\n<h3 id=\"tocwheres-the-fft\">Where's the FFT?</h3>\n<p>If you noticed, I didn't mention the <a href=\"https://en.wikipedia.org/wiki/Fast_Fourier_transform\">Fast Fourier Transform</a> until now.</p>\n<p>Why?</p>\n<p>Well, it is believed (at least, I believed) that the Fourier Transform is the go-to transformation when working with audio recordings: it can extract frequency-related features useful to extract information from raw signals.</p>\n<p>For this project, I tried not to use it and I was surprised that it worked fine in spite of everything. Since I like to keep things as lean as possible, I won't apply any complex transformation to the samples.</p>\n<p>If you're having poor results, however, remember you can try to apply FFT and see if it helps improve the accuracy.</p>\n<h2 id=\"tocmachine-learning-model\">Machine learning model</h2>\n<p>Now that we have the samples, it's time to train the classifier.</p>\n<p>This step is the same as in any other tutorial I wrote so far, so I won't spend much time on this part. Among the classifiers I tried, SVM produced the best accuracy at 96% with 32 support vectors: it's not a super-tiny model, but it's quite small nevertheless.</p>\n<pre><code class=\"language-python\">import numpy as np\nfrom os.path import basename\nfrom glob import glob\nfrom sklearn.svm import SVC\nfrom micromlgen import port\n\ndef load_features(folder):\n    dataset = None\n    classmap = {}\n    for class_idx, filename in enumerate(glob(&#039;%s/*.csv&#039; % folder)):\n        class_name = basename(filename)[:-4]\n        classmap[class_idx] = class_name\n        samples = np.loadtxt(filename, dtype=float, delimiter=&#039;,&#039;)\n        labels = np.ones((len(samples), 1)) * class_idx\n        samples = np.hstack((samples, labels))\n        dataset = samples if dataset is None else np.vstack((dataset, samples))\n    return dataset, classmap\n\ndataset, classmap = load_features(&#039;64&#039;)\nX, y = dataset[:, :-1], dataset[:, -1]\nclf = SVC(kernel=&#039;poly&#039;, degree=2, gamma=0.1, C=100)\nclf.fit(X_train, y_train)\nprint(port(clf, classmap=classmap))</code></pre>\n<pre><code class=\"language-cpp\">// The produced ouput for my SVM model\n\n#pragma once\nnamespace Eloquent {\n    namespace ML {\n        namespace Port {\n            class SVM {\n            public:\n                /**\n                * Predict class for features vector\n                */\n                int predict(float *x) {\n                    float kernels[35] = { 0 };\n                    float decisions[6] = { 0 };\n                    int votes[4] = { 0 };\n                    kernels[0] = compute_kernel(x,   33.0  , 41.0  , 47.0  , 54.0  , 59.0  , 61.0  , 56.0  , 51.0  , 50.0  , 51.0  , 44.0  , 32.0  , 23.0  , 15.0  , 12.0  , 8.0  , 5.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 5.0  , 3.0  , 5.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0 );\n                    kernels[1] = compute_kernel(x,   40.0  , 50.0  , 51.0  , 60.0  , 56.0  , 57.0  , 58.0  , 53.0  , 50.0  , 45.0  , 42.0  , 34.0  , 23.0  , 16.0  , 10.0  , 7.0  , 3.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 14.0  , 3.0  , 8.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 5.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 5.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 3.0 );\n                    kernels[2] = compute_kernel(x,   56.0  , 68.0  , 78.0  , 91.0  , 84.0  , 84.0  , 84.0  , 74.0  , 69.0  , 64.0  , 57.0  , 44.0  , 33.0  , 18.0  , 12.0  , 8.0  , 5.0  , 9.0  , 15.0  , 12.0  , 12.0  , 9.0  , 12.0  , 7.0  , 3.0  , 10.0  , 12.0  , 6.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 6.0  , 3.0  , 6.0  , 10.0  , 10.0  , 8.0  , 3.0  , 9.0  , 9.0  , 9.0  , 8.0  , 9.0  , 9.0  , 11.0  , 3.0  , 8.0  , 9.0  , 8.0  , 8.0  , 8.0  , 6.0  , 7.0  , 3.0  , 3.0  , 8.0  , 5.0  , 3.0  , 0.0  , 3.0  , 0.0  , 0.0 );\n                    kernels[3] = compute_kernel(x,   33.0  , 18.0  , 26.0  , 39.0  , 46.0  , 60.0  , 66.0  , 72.0  , 82.0  , 76.0  , 82.0  , 77.0  , 78.0  , 79.0  , 76.0  , 73.0  , 63.0  , 41.0  , 33.0  , 21.0  , 13.0  , 7.0  , 3.0  , 10.0  , 3.0  , 5.0  , 6.0  , 21.0  , 21.0  , 14.0  , 5.0  , 8.0  , 5.0  , 5.0  , 0.0  , 8.0  , 8.0  , 3.0  , 0.0  , 3.0  , 3.0  , 5.0  , 0.0  , 3.0  , 8.0  , 7.0  , 6.0  , 7.0  , 8.0  , 9.0  , 9.0  , 8.0  , 8.0  , 7.0  , 17.0  , 3.0  , 3.0  , 6.0  , 6.0  , 5.0  , 3.0  , 6.0  , 6.0  , 3.0 );\n                    kernels[4] = compute_kernel(x,   54.0  , 57.0  , 62.0  , 58.0  , 61.0  , 61.0  , 59.0  , 58.0  , 57.0  , 51.0  , 34.0  , 25.0  , 18.0  , 10.0  , 6.0  , 6.0  , 10.0  , 7.0  , 5.0  , 10.0  , 5.0  , 7.0  , 8.0  , 6.0  , 5.0  , 5.0  , 5.0  , 7.0  , 3.0  , 5.0  , 0.0  , 0.0  , 0.0  , 3.0  , 3.0  , 6.0  , 0.0  , 7.0  , 0.0  , 5.0  , 6.0  , 0.0  , 0.0  , 6.0  , 7.0  , 5.0  , 3.0  , 5.0  , 6.0  , 0.0  , 0.0  , 0.0  , 12.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0 );\n                    kernels[5] = compute_kernel(x,   49.0  , 58.0  , 68.0  , 69.0  , 72.0  , 72.0  , 75.0  , 76.0  , 73.0  , 59.0  , 59.0  , 36.0  , 19.0  , 12.0  , 12.0  , 17.0  , 12.0  , 21.0  , 9.0  , 6.0  , 8.0  , 6.0  , 7.0  , 15.0  , 14.0  , 14.0  , 10.0  , 8.0  , 5.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 7.0  , 10.0  , 7.0  , 6.0  , 8.0  , 12.0  , 13.0  , 15.0  , 11.0  , 16.0  , 15.0  , 13.0  , 7.0  , 6.0  , 12.0  , 5.0  , 8.0  , 8.0  , 12.0  , 8.0  , 0.0  , 3.0  , 7.0  , 10.0  , 9.0  , 8.0  , 5.0 );\n                    kernels[6] = compute_kernel(x,   43.0  , 63.0  , 76.0  , 73.0  , 67.0  , 72.0  , 64.0  , 50.0  , 31.0  , 123.0  , 95.0  , 27.0  , 17.0  , 20.0  , 12.0  , 14.0  , 11.0  , 9.0  , 6.0  , 3.0  , 3.0  , 15.0  , 156.0  , 172.0  , 69.0  , 52.0  , 47.0  , 41.0  , 18.0  , 29.0  , 46.0  , 20.0  , 22.0  , 21.0  , 0.0  , 0.0  , 6.0  , 3.0  , 7.0  , 10.0  , 10.0  , 14.0  , 13.0  , 13.0  , 11.0  , 8.0  , 18.0  , 26.0  , 19.0  , 15.0  , 15.0  , 16.0  , 17.0  , 13.0  , 11.0  , 8.0  , 20.0  , 19.0  , 10.0  , 9.0  , 10.0  , 12.0  , 9.0  , 12.0 );\n                    kernels[7] = compute_kernel(x,   66.0  , 85.0  , 105.0  , 116.0  , 118.0  , 104.0  , 102.0  , 81.0  , 58.0  , 129.0  , 222.0  , 48.0  , 80.0  , 70.0  , 50.0  , 40.0  , 19.0  , 11.0  , 3.0  , 0.0  , 0.0  , 0.0  , 7.0  , 5.0  , 15.0  , 16.0  , 9.0  , 5.0  , 25.0  , 29.0  , 43.0  , 32.0  , 28.0  , 31.0  , 21.0  , 8.0  , 0.0  , 9.0  , 8.0  , 3.0  , 3.0  , 0.0  , 0.0  , 7.0  , 11.0  , 9.0  , 26.0  , 16.0  , 13.0  , 9.0  , 20.0  , 16.0  , 16.0  , 26.0  , 18.0  , 10.0  , 7.0  , 12.0  , 10.0  , 8.0  , 7.0  , 17.0  , 15.0  , 7.0 );\n                    kernels[8] = compute_kernel(x,   64.0  , 77.0  , 90.0  , 92.0  , 93.0  , 93.0  , 83.0  , 58.0  , 112.0  , 80.0  , 34.0  , 13.0  , 16.0  , 10.0  , 5.0  , 3.0  , 7.0  , 0.0  , 0.0  , 0.0  , 8.0  , 10.0  , 50.0  , 101.0  , 44.0  , 41.0  , 16.0  , 23.0  , 19.0  , 6.0  , 13.0  , 19.0  , 25.0  , 15.0  , 8.0  , 0.0  , 0.0  , 0.0  , 0.0  , 5.0  , 10.0  , 19.0  , 8.0  , 8.0  , 10.0  , 7.0  , 8.0  , 9.0  , 14.0  , 7.0  , 9.0  , 8.0  , 10.0  , 8.0  , 7.0  , 6.0  , 6.0  , 3.0  , 7.0  , 6.0  , 3.0  , 3.0  , 3.0  , 3.0 );\n                    kernels[9] = compute_kernel(x,   33.0  , 28.0  , 20.0  , 9.0  , 5.0  , 7.0  , 7.0  , 13.0  , 130.0  , 183.0  , 212.0  , 197.0  , 190.0  , 167.0  , 151.0  , 110.0  , 83.0  , 54.0  , 67.0  , 20.0  , 23.0  , 24.0  , 16.0  , 12.0  , 7.0  , 0.0  , 3.0  , 9.0  , 0.0  , 3.0  , 5.0  , 10.0  , 79.0  , 109.0  , 80.0  , 75.0  , 38.0  , 38.0  , 29.0  , 26.0  , 29.0  , 27.0  , 26.0  , 27.0  , 22.0  , 22.0  , 15.0  , 6.0  , 0.0  , 3.0  , 12.0  , 18.0  , 21.0  , 24.0  , 27.0  , 27.0  , 25.0  , 26.0  , 25.0  , 25.0  , 27.0  , 25.0  , 22.0  , 19.0 );\n                    kernels[10] = compute_kernel(x,   36.0  , 58.0  , 70.0  , 69.0  , 62.0  , 56.0  , 52.0  , 50.0  , 26.0  , 9.0  , 3.0  , 0.0  , 3.0  , 6.0  , 3.0  , 0.0  , 0.0  , 5.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 5.0  , 0.0  , 0.0  , 7.0  , 6.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 3.0  , 0.0  , 3.0  , 5.0  , 7.0  , 5.0  , 0.0  , 0.0  , 7.0  , 9.0  , 6.0  , 5.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 3.0  , 0.0  , 5.0  , 5.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 8.0  , 6.0 );\n                    kernels[11] = compute_kernel(x,   99.0  , 122.0  , 127.0  , 115.0  , 110.0  , 101.0  , 88.0  , 64.0  , 51.0  , 186.0  , 73.0  , 16.0  , 25.0  , 26.0  , 22.0  , 18.0  , 12.0  , 9.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 21.0  , 14.0  , 3.0  , 11.0  , 19.0  , 34.0  , 31.0  , 33.0  , 18.0  , 15.0  , 9.0  , 19.0  , 19.0  , 16.0  , 6.0  , 0.0  , 0.0  , 0.0  , 7.0  , 12.0  , 9.0  , 10.0  , 12.0  , 14.0  , 12.0  , 13.0  , 10.0  , 10.0  , 12.0  , 9.0  , 13.0  , 13.0  , 14.0  , 8.0  , 11.0  , 8.0  , 6.0  , 3.0  , 7.0  , 3.0  , 5.0 );\n                    kernels[12] = compute_kernel(x,   51.0  , 69.0  , 82.0  , 82.0  , 78.0  , 82.0  , 71.0  , 68.0  , 50.0  , 33.0  , 58.0  , 76.0  , 28.0  , 5.0  , 12.0  , 12.0  , 6.0  , 6.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 5.0  , 52.0  , 90.0  , 45.0  , 30.0  , 19.0  , 12.0  , 19.0  , 19.0  , 18.0  , 7.0  , 13.0  , 16.0  , 10.0  , 7.0  , 3.0  , 0.0  , 5.0  , 6.0  , 0.0  , 11.0  , 17.0  , 14.0  , 12.0  , 16.0  , 9.0  , 11.0  , 11.0  , 18.0  , 13.0  , 8.0  , 8.0  , 10.0  , 12.0  , 8.0  , 9.0  , 8.0  , 8.0  , 5.0  , 6.0 );\n                    kernels[13] = compute_kernel(x,   55.0  , 102.0  , 134.0  , 149.0  , 145.0  , 149.0  , 148.0  , 127.0  , 94.0  , 64.0  , 108.0  , 94.0  , 37.0  , 15.0  , 22.0  , 17.0  , 17.0  , 14.0  , 13.0  , 0.0  , 8.0  , 14.0  , 9.0  , 0.0  , 6.0  , 3.0  , 7.0  , 5.0  , 6.0  , 5.0  , 5.0  , 12.0  , 8.0  , 0.0  , 10.0  , 14.0  , 8.0  , 9.0  , 0.0  , 3.0  , 3.0  , 0.0  , 5.0  , 3.0  , 8.0  , 8.0  , 3.0  , 3.0  , 3.0  , 3.0  , 8.0  , 3.0  , 5.0  , 0.0  , 0.0  , 0.0  , 12.0  , 3.0  , 0.0  , 7.0  , 5.0  , 3.0  , 0.0  , 0.0 );\n                    kernels[14] = compute_kernel(x,   75.0  , 89.0  , 116.0  , 125.0  , 124.0  , 102.0  , 109.0  , 99.0  , 80.0  , 57.0  , 136.0  , 108.0  , 55.0  , 10.0  , 20.0  , 20.0  , 16.0  , 10.0  , 8.0  , 14.0  , 6.0  , 0.0  , 3.0  , 3.0  , 6.0  , 19.0  , 8.0  , 11.0  , 3.0  , 46.0  , 33.0  , 29.0  , 26.0  , 22.0  , 12.0  , 14.0  , 21.0  , 16.0  , 18.0  , 16.0  , 13.0  , 3.0  , 0.0  , 8.0  , 6.0  , 14.0  , 10.0  , 21.0  , 21.0  , 17.0  , 16.0  , 16.0  , 19.0  , 17.0  , 16.0  , 20.0  , 14.0  , 10.0  , 14.0  , 13.0  , 12.0  , 12.0  , 10.0  , 6.0 );\n                    kernels[15] = compute_kernel(x,   43.0  , 57.0  , 63.0  , 60.0  , 64.0  , 57.0  , 55.0  , 35.0  , 18.0  , 14.0  , 13.0  , 5.0  , 3.0  , 10.0  , 5.0  , 3.0  , 3.0  , 0.0  , 7.0  , 3.0  , 5.0  , 5.0  , 0.0  , 23.0  , 8.0  , 3.0  , 3.0  , 17.0  , 6.0  , 13.0  , 10.0  , 5.0  , 0.0  , 10.0  , 7.0  , 9.0  , 8.0  , 13.0  , 6.0  , 7.0  , 5.0  , 6.0  , 3.0  , 3.0  , 5.0  , 8.0  , 3.0  , 3.0  , 5.0  , 5.0  , 5.0  , 7.0  , 8.0  , 6.0  , 6.0  , 7.0  , 6.0  , 6.0  , 5.0  , 5.0  , 5.0  , 5.0  , 5.0  , 3.0 );\n                    kernels[16] = compute_kernel(x,   31.0  , 33.0  , 27.0  , 19.0  , 14.0  , 9.0  , 3.0  , 6.0  , 16.0  , 131.0  , 186.0  , 214.0  , 206.0  , 212.0  , 192.0  , 186.0  , 147.0  , 90.0  , 157.0  , 98.0  , 34.0  , 37.0  , 35.0  , 31.0  , 17.0  , 10.0  , 7.0  , 0.0  , 3.0  , 3.0  , 5.0  , 6.0  , 10.0  , 12.0  , 22.0  , 50.0  , 48.0  , 48.0  , 61.0  , 28.0  , 26.0  , 29.0  , 30.0  , 24.0  , 26.0  , 19.0  , 26.0  , 15.0  , 26.0  , 19.0  , 17.0  , 10.0  , 3.0  , 3.0  , 0.0  , 6.0  , 12.0  , 16.0  , 16.0  , 21.0  , 25.0  , 27.0  , 27.0  , 26.0 );\n                    kernels[17] = compute_kernel(x,   50.0  , 70.0  , 80.0  , 83.0  , 79.0  , 73.0  , 80.0  , 74.0  , 54.0  , 34.0  , 16.0  , 7.0  , 3.0  , 3.0  , 3.0  , 3.0  , 6.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 5.0  , 3.0  , 10.0  , 3.0  , 7.0  , 5.0  , 0.0  , 3.0  , 3.0  , 3.0  , 3.0  , 0.0  , 5.0  , 6.0  , 0.0  , 0.0  , 3.0  , 3.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 7.0  , 3.0  , 0.0  , 3.0  , 0.0 );\n                    kernels[18] = compute_kernel(x,   38.0  , 50.0  , 52.0  , 49.0  , 44.0  , 42.0  , 43.0  , 41.0  , 41.0  , 42.0  , 42.0  , 40.0  , 35.0  , 29.0  , 23.0  , 22.0  , 20.0  , 20.0  , 18.0  , 16.0  , 16.0  , 15.0  , 11.0  , 12.0  , 15.0  , 11.0  , 13.0  , 8.0  , 5.0  , 5.0  , 3.0  , 0.0  , 0.0  , 3.0  , 7.0  , 3.0  , 8.0  , 3.0  , 0.0  , 5.0  , 6.0  , 5.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 6.0  , 3.0  , 8.0  , 5.0  , 7.0  , 5.0  , 8.0  , 8.0  , 7.0  , 6.0  , 10.0  , 11.0  , 3.0  , 5.0 );\n                    kernels[19] = compute_kernel(x,   33.0  , 37.0  , 34.0  , 30.0  , 25.0  , 22.0  , 37.0  , 44.0  , 40.0  , 36.0  , 33.0  , 29.0  , 27.0  , 26.0  , 28.0  , 28.0  , 28.0  , 25.0  , 20.0  , 16.0  , 14.0  , 13.0  , 12.0  , 11.0  , 10.0  , 10.0  , 10.0  , 7.0  , 6.0  , 6.0  , 6.0  , 6.0  , 5.0  , 0.0  , 5.0  , 5.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0 );\n                    kernels[20] = compute_kernel(x,   43.0  , 52.0  , 49.0  , 45.0  , 44.0  , 43.0  , 43.0  , 41.0  , 43.0  , 42.0  , 36.0  , 34.0  , 28.0  , 27.0  , 21.0  , 18.0  , 19.0  , 17.0  , 16.0  , 15.0  , 13.0  , 14.0  , 14.0  , 12.0  , 13.0  , 14.0  , 10.0  , 8.0  , 7.0  , 5.0  , 3.0  , 5.0  , 8.0  , 0.0  , 0.0  , 5.0  , 8.0  , 7.0  , 3.0  , 0.0  , 3.0  , 5.0  , 3.0  , 7.0  , 6.0  , 8.0  , 0.0  , 6.0  , 3.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 7.0  , 10.0  , 8.0  , 14.0  , 7.0  , 5.0  , 11.0 );\n                    kernels[21] = compute_kernel(x,   33.0  , 28.0  , 26.0  , 21.0  , 22.0  , 31.0  , 38.0  , 35.0  , 33.0  , 32.0  , 30.0  , 28.0  , 25.0  , 28.0  , 29.0  , 30.0  , 27.0  , 25.0  , 20.0  , 16.0  , 16.0  , 15.0  , 15.0  , 13.0  , 11.0  , 10.0  , 9.0  , 8.0  , 5.0  , 6.0  , 5.0  , 0.0  , 9.0  , 12.0  , 9.0  , 12.0  , 12.0  , 9.0  , 8.0  , 13.0  , 12.0  , 10.0  , 13.0  , 7.0  , 10.0  , 16.0  , 10.0  , 16.0  , 6.0  , 0.0  , 0.0  , 8.0  , 0.0  , 6.0  , 10.0  , 8.0  , 11.0  , 10.0  , 5.0  , 8.0  , 9.0  , 8.0  , 6.0  , 6.0 );\n                    kernels[22] = compute_kernel(x,   40.0  , 49.0  , 48.0  , 45.0  , 48.0  , 47.0  , 51.0  , 55.0  , 52.0  , 43.0  , 35.0  , 30.0  , 16.0  , 8.0  , 6.0  , 8.0  , 8.0  , 7.0  , 7.0  , 9.0  , 10.0  , 8.0  , 9.0  , 8.0  , 6.0  , 8.0  , 6.0  , 5.0  , 10.0  , 7.0  , 3.0  , 3.0  , 0.0  , 3.0  , 3.0  , 0.0  , 0.0  , 5.0  , 6.0  , 8.0  , 9.0  , 14.0  , 13.0  , 14.0  , 10.0  , 10.0  , 10.0  , 8.0  , 7.0  , 0.0  , 5.0  , 0.0  , 0.0  , 3.0  , 3.0  , 10.0  , 10.0  , 0.0  , 8.0  , 14.0  , 9.0  , 12.0  , 5.0  , 14.0 );\n                    kernels[23] = compute_kernel(x,   37.0  , 42.0  , 57.0  , 68.0  , 69.0  , 75.0  , 74.0  , 67.0  , 51.0  , 38.0  , 26.0  , 13.0  , 6.0  , 13.0  , 15.0  , 14.0  , 11.0  , 10.0  , 8.0  , 12.0  , 9.0  , 8.0  , 5.0  , 8.0  , 13.0  , 8.0  , 3.0  , 3.0  , 0.0  , 0.0  , 9.0  , 9.0  , 5.0  , 7.0  , 6.0  , 3.0  , 3.0  , 5.0  , 5.0  , 7.0  , 3.0  , 6.0  , 3.0  , 6.0  , 3.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 5.0  , 0.0  , 0.0  , 3.0  , 0.0 );\n                    kernels[24] = compute_kernel(x,   42.0  , 39.0  , 41.0  , 45.0  , 46.0  , 49.0  , 46.0  , 43.0  , 35.0  , 28.0  , 18.0  , 11.0  , 7.0  , 10.0  , 8.0  , 10.0  , 8.0  , 8.0  , 7.0  , 8.0  , 8.0  , 8.0  , 8.0  , 8.0  , 6.0  , 5.0  , 6.0  , 5.0  , 6.0  , 5.0  , 0.0  , 3.0  , 5.0  , 6.0  , 0.0  , 5.0  , 3.0  , 8.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 3.0 );\n                    kernels[25] = compute_kernel(x,   45.0  , 43.0  , 45.0  , 48.0  , 56.0  , 54.0  , 54.0  , 44.0  , 35.0  , 25.0  , 19.0  , 8.0  , 6.0  , 5.0  , 6.0  , 5.0  , 5.0  , 6.0  , 5.0  , 6.0  , 6.0  , 6.0  , 5.0  , 5.0  , 3.0  , 3.0  , 5.0  , 5.0  , 6.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 7.0  , 9.0  , 5.0  , 5.0  , 0.0  , 0.0  , 0.0  , 5.0  , 3.0  , 3.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 5.0  , 6.0  , 5.0  , 0.0  , 0.0 );\n                    kernels[26] = compute_kernel(x,   31.0  , 43.0  , 66.0  , 75.0  , 75.0  , 81.0  , 89.0  , 85.0  , 79.0  , 68.0  , 50.0  , 32.0  , 22.0  , 10.0  , 8.0  , 12.0  , 10.0  , 10.0  , 12.0  , 12.0  , 11.0  , 10.0  , 10.0  , 8.0  , 8.0  , 9.0  , 8.0  , 7.0  , 7.0  , 6.0  , 3.0  , 3.0  , 3.0  , 0.0  , 0.0  , 5.0  , 8.0  , 8.0  , 6.0  , 3.0  , 7.0  , 8.0  , 11.0  , 12.0  , 12.0  , 16.0  , 9.0  , 0.0  , 0.0  , 0.0  , 3.0  , 7.0  , 7.0  , 8.0  , 6.0  , 8.0  , 12.0  , 10.0  , 8.0  , 7.0  , 5.0  , 3.0  , 6.0  , 8.0 );\n                    kernels[27] = compute_kernel(x,   33.0  , 40.0  , 41.0  , 41.0  , 43.0  , 48.0  , 49.0  , 49.0  , 47.0  , 36.0  , 27.0  , 18.0  , 9.0  , 3.0  , 5.0  , 3.0  , 5.0  , 5.0  , 5.0  , 3.0  , 3.0  , 3.0  , 3.0  , 3.0  , 3.0  , 3.0  , 3.0  , 3.0  , 3.0  , 0.0  , 3.0  , 3.0  , 7.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0 );\n                    kernels[28] = compute_kernel(x,   30.0  , 47.0  , 72.0  , 81.0  , 81.0  , 79.0  , 85.0  , 88.0  , 85.0  , 86.0  , 64.0  , 45.0  , 27.0  , 15.0  , 13.0  , 14.0  , 11.0  , 18.0  , 20.0  , 24.0  , 18.0  , 17.0  , 20.0  , 15.0  , 19.0  , 14.0  , 10.0  , 10.0  , 8.0  , 6.0  , 6.0  , 3.0  , 3.0  , 0.0  , 6.0  , 7.0  , 18.0  , 15.0  , 11.0  , 12.0  , 19.0  , 20.0  , 10.0  , 8.0  , 0.0  , 0.0  , 0.0  , 6.0  , 6.0  , 9.0  , 10.0  , 9.0  , 12.0  , 12.0  , 10.0  , 12.0  , 12.0  , 3.0  , 6.0  , 7.0  , 8.0  , 10.0  , 8.0  , 5.0 );\n                    kernels[29] = compute_kernel(x,   33.0  , 31.0  , 31.0  , 33.0  , 36.0  , 36.0  , 36.0  , 32.0  , 25.0  , 19.0  , 12.0  , 5.0  , 5.0  , 10.0  , 6.0  , 6.0  , 8.0  , 6.0  , 7.0  , 6.0  , 6.0  , 6.0  , 11.0  , 6.0  , 6.0  , 6.0  , 5.0  , 3.0  , 3.0  , 0.0  , 0.0  , 6.0  , 3.0  , 5.0  , 3.0  , 10.0  , 5.0  , 6.0  , 9.0  , 3.0  , 7.0  , 6.0  , 6.0  , 8.0  , 7.0  , 0.0  , 6.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 6.0  , 6.0  , 0.0  , 5.0  , 3.0  , 3.0  , 5.0  , 8.0  , 7.0  , 0.0 );\n                    kernels[30] = compute_kernel(x,   31.0  , 48.0  , 65.0  , 60.0  , 68.0  , 81.0  , 88.0  , 91.0  , 93.0  , 79.0  , 56.0  , 32.0  , 22.0  , 12.0  , 16.0  , 13.0  , 12.0  , 13.0  , 13.0  , 13.0  , 14.0  , 11.0  , 11.0  , 14.0  , 12.0  , 10.0  , 8.0  , 8.0  , 7.0  , 5.0  , 3.0  , 0.0  , 3.0  , 5.0  , 5.0  , 7.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 6.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 3.0  , 5.0  , 0.0  , 0.0  , 0.0 );\n                    kernels[31] = compute_kernel(x,   34.0  , 47.0  , 50.0  , 51.0  , 60.0  , 67.0  , 65.0  , 63.0  , 54.0  , 42.0  , 30.0  , 19.0  , 25.0  , 22.0  , 28.0  , 7.0  , 6.0  , 5.0  , 7.0  , 7.0  , 5.0  , 8.0  , 6.0  , 3.0  , 3.0  , 3.0  , 6.0  , 7.0  , 3.0  , 0.0  , 0.0  , 0.0  , 3.0  , 5.0  , 5.0  , 3.0  , 5.0  , 3.0  , 3.0  , 3.0  , 0.0  , 6.0  , 3.0  , 0.0  , 0.0  , 5.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 5.0 );\n                    kernels[32] = compute_kernel(x,   34.0  , 48.0  , 58.0  , 55.0  , 59.0  , 69.0  , 77.0  , 75.0  , 75.0  , 69.0  , 56.0  , 43.0  , 22.0  , 13.0  , 10.0  , 6.0  , 9.0  , 15.0  , 11.0  , 10.0  , 8.0  , 8.0  , 7.0  , 3.0  , 6.0  , 5.0  , 5.0  , 7.0  , 6.0  , 6.0  , 7.0  , 3.0  , 5.0  , 11.0  , 5.0  , 7.0  , 6.0  , 8.0  , 11.0  , 8.0  , 16.0  , 9.0  , 7.0  , 8.0  , 6.0  , 3.0  , 6.0  , 3.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 6.0  , 3.0  , 0.0  , 3.0  , 5.0  , 8.0  , 10.0  , 13.0  , 13.0 );\n                    kernels[33] = compute_kernel(x,   32.0  , 31.0  , 33.0  , 33.0  , 35.0  , 37.0  , 34.0  , 28.0  , 25.0  , 15.0  , 10.0  , 5.0  , 6.0  , 5.0  , 7.0  , 8.0  , 6.0  , 6.0  , 7.0  , 8.0  , 5.0  , 6.0  , 5.0  , 7.0  , 6.0  , 5.0  , 3.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 5.0  , 3.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0 );\n                    kernels[34] = compute_kernel(x,   44.0  , 43.0  , 48.0  , 58.0  , 59.0  , 54.0  , 55.0  , 49.0  , 48.0  , 38.0  , 26.0  , 14.0  , 8.0  , 9.0  , 14.0  , 12.0  , 7.0  , 9.0  , 10.0  , 8.0  , 9.0  , 7.0  , 6.0  , 6.0  , 6.0  , 6.0  , 6.0  , 5.0  , 6.0  , 8.0  , 6.0  , 0.0  , 0.0  , 13.0  , 8.0  , 6.0  , 17.0  , 10.0  , 8.0  , 17.0  , 13.0  , 15.0  , 13.0  , 14.0  , 8.0  , 8.0  , 11.0  , 8.0  , 8.0  , 6.0  , 5.0  , 3.0  , 5.0  , 3.0  , 8.0  , 7.0  , 6.0  , 10.0  , 9.0  , 12.0  , 13.0  , 10.0  , 7.0  , 10.0 );\n                    decisions[0] = 0.722587775297\n                                   + kernels[1] * 3.35855e-07\n                                   + kernels[2] * 1.64612e-07\n                                   + kernels[4] * 6.00056e-07\n                                   + kernels[5] * 3.5195e-08\n                                   + kernels[7] * -4.2079e-08\n                                   + kernels[8] * -4.2843e-08\n                                   + kernels[9] * -9.994e-09\n                                   + kernels[10] * -5.11065e-07\n                                   + kernels[11] * -5.979e-09\n                                   + kernels[12] * -4.4672e-08\n                                   + kernels[13] * -1.5606e-08\n                                   + kernels[14] * -1.2941e-08\n                                   + kernels[15] * -2.18903e-07\n                                   + kernels[17] * -2.31635e-07\n                            ;\n                    decisions[1] = -1.658344586719\n                                   + kernels[0] * 2.45018e-07\n                                   + kernels[1] * 4.30223e-07\n                                   + kernels[3] * 1.00277e-07\n                                   + kernels[4] * 2.16524e-07\n                                   + kernels[18] * -4.81187e-07\n                                   + kernels[20] * -5.10856e-07\n                            ;\n                    decisions[2] = -1.968607562265\n                                   + kernels[0] * 3.001833e-06\n                                   + kernels[3] * 4.5201e-08\n                                   + kernels[4] * 1.54493e-06\n                                   + kernels[5] * 2.81834e-07\n                                   + kernels[25] * -5.93581e-07\n                                   + kernels[26] * -2.89779e-07\n                                   + kernels[27] * -1.73958e-06\n                                   + kernels[28] * -1.09552e-07\n                                   + kernels[30] * -3.09126e-07\n                                   + kernels[31] * -1.294219e-06\n                                   + kernels[32] * -5.37961e-07\n                            ;\n                    decisions[3] = -0.720663029823\n                                   + kernels[6] * 1.4362e-08\n                                   + kernels[7] * 6.177e-09\n                                   + kernels[9] * 1.25e-08\n                                   + kernels[10] * 2.05478e-07\n                                   + kernels[12] * 2.501e-08\n                                   + kernels[15] * 4.363e-07\n                                   + kernels[16] * 9.147e-09\n                                   + kernels[18] * -1.82182e-07\n                                   + kernels[20] * -4.93707e-07\n                                   + kernels[21] * -3.3084e-08\n                            ;\n                    decisions[4] = -1.605747746589\n                                   + kernels[6] * 6.182e-09\n                                   + kernels[7] * 1.3853e-08\n                                   + kernels[8] * 2.12e-10\n                                   + kernels[9] * 1.1243e-08\n                                   + kernels[10] * 7.80681e-07\n                                   + kernels[15] * 8.347e-07\n                                   + kernels[17] * 1.64985e-07\n                                   + kernels[23] * -4.25014e-07\n                                   + kernels[25] * -1.134803e-06\n                                   + kernels[34] * -2.52038e-07\n                            ;\n                    decisions[5] = -0.934328303475\n                                   + kernels[19] * 3.3529e-07\n                                   + kernels[20] * 1.121946e-06\n                                   + kernels[21] * 3.44683e-07\n                                   + kernels[22] * -6.23056e-07\n                                   + kernels[24] * -1.4612e-07\n                                   + kernels[28] * -1.24025e-07\n                                   + kernels[29] * -4.31701e-07\n                                   + kernels[31] * -9.2146e-08\n                                   + kernels[33] * -3.8487e-07\n                            ;\n                    votes[decisions[0] &gt; 0 ? 0 : 1] += 1;\n                    votes[decisions[1] &gt; 0 ? 0 : 2] += 1;\n                    votes[decisions[2] &gt; 0 ? 0 : 3] += 1;\n                    votes[decisions[3] &gt; 0 ? 1 : 2] += 1;\n                    votes[decisions[4] &gt; 0 ? 1 : 3] += 1;\n                    votes[decisions[5] &gt; 0 ? 2 : 3] += 1;\n                    int val = votes[0];\n                    int idx = 0;\n\n                    for (int i = 1; i &lt; 4; i++) {\n                        if (votes[i] &gt; val) {\n                            val = votes[i];\n                            idx = i;\n                        }\n                    }\n\n                    return idx;\n                }\n\n                /**\n                * Convert class idx to readable name\n                */\n                const char* predictLabel(float *x) {\n                    switch (predict(x)) {\n                        case 0:\n                            return &quot;no&quot;;\n                        case 1:\n                            return &quot;stop&quot;;\n                        case 2:\n                            return &quot;play&quot;;\n                        case 3:\n                            return &quot;yes&quot;;\n                        default:\n                            return &quot;Houston we have a problem&quot;;\n                    }\n                }\n\n            protected:\n                /**\n                * Compute kernel between feature vector and support vector.\n                * Kernel type: poly\n                */\n                float compute_kernel(float *x, ...) {\n                    va_list w;\n                    va_start(w, 64);\n                    float kernel = 0.0;\n\n                    for (uint16_t i = 0; i &lt; 64; i++) {\n                        kernel += x[i] * va_arg(w, double);\n                    }\n\n                    return pow((0.1 * kernel) + 0.0, 2);\n                }\n            };\n        }\n    }\n}</code></pre>\n<p>Done! Deploy the sketch to your board and it should now be able to &quot;understand&quot; what you tell it!</p>\n<p>Here's a quick demo (please forgive me for the bad video quality).</p>\n<div style=\"width: 576px;\" class=\"wp-video\"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->\n<video class=\"wp-video-shortcode\" id=\"video-1282-1\" width=\"576\" height=\"482\" preload=\"metadata\" controls=\"controls\"><source type=\"video/mp4\" src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/08/Arduino-Nano-33-BLE-Sense-Word-classification.mp4?_=1\" /><a href=\"https://eloquentarduino.github.io/wp-content/uploads/2020/08/Arduino-Nano-33-BLE-Sense-Word-classification.mp4\">https://eloquentarduino.github.io/wp-content/uploads/2020/08/Arduino-Nano-33-BLE-Sense-Word-classification.mp4</a></video></div>\n<hr />\n<p>Link to the <a href=\"https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/BleSenseWordClassificationExample/BleSenseWordClassificationExample.ino\">Github repo</a></p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2020/08/better-word-classification-with-arduino-33-ble-sense-and-machine-learning/\">Better word classification with Arduino Nano 33 BLE Sense and Machine Learning</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "Let's revamp the post I wrote about word classification using Machine Learning on Arduino, this time using a proper microphone (the MP34DT05 mounted on the Arduino Nano 33 BLE Sense) instead of a chinese, analog one: will the results improve?\nfrom https://www.udemy.com/course/learn-audio-processing-complete-engineers-course/\n\nTable of contentsPulse-density modulation (a.k.a. PDM)Where's the FFT?Machine learning model\nPulse-density modulation (a.k.a. PDM)\nIn the original post, I used an analog microphone to record the audio. It is for sure the easiest way to interact with audio on a microcontroller since you only need to analogRead() the selected pin to get a value from the sensor.\nThis semplicity, however, comes at the cost of a nearly inexistent signal pre-processing from the sensor itself: most of the time, you will get junk - I don't want to be rude, but that's it.\nThe microphone mounted on the Arduino Nano 33 BLE Sense (the MP34DT05), gives you access to modulated signal much more suitable for our processing needs.\nThe modulation used is Pulse-density: I won't try to explain you how this works since I'm not an expert in DSP and neither it is the main scope of this article (refer to Wikipedia for some more information).\nWhat matters to us is that we can grab an array of bytes from the microphone and extract its Root Mean Square (a.k.a. RMS) to be used as a feature for our Machine Learning model.\nI had some difficulty finding examples on how to access the microphone on the Arduino Nano 33 BLE Sense board: fortunately, there's a Github repo from DelaGia that shows how to access all the sensors of the board.\nI extracted the microphone part and incapsulated it in an easy to use class, so you don't really need to dig into the implementation details if you're not interested.\nThe following code extract highlights the steps you need to access the microphone recordings.\n// you&#039;ll find this file in the Github repo\n#include &quot;Mic.h&quot;\n\n// tune these constants to your needs\n#define SAMPLES 64\n#define SOUND_THRESHOLD 1500\n\nfloat features[SAMPLES];\nMic mic;\n\n/**\n *\n */\nvoid setup() {\n    Serial.begin(115200);\n    // the PDM library is asynchronous, so we need a callback\n    PDM.onReceive(onAudio);\n    mic.begin();\n}\n\n/**\n * PDM callback to update mic object\n */\nvoid onAudio() {\n    mic.update();\n}\n\n/**\n * Read given number of samples from mic\n */\nbool record() {\n    if (mic.hasData() &amp;&amp; mic.pop() &gt; SOUND_THRESHOLD) {\n        for (int i = 0; i &lt; SAMPLES; i++) {\n            while (!mic.hasData()) ; // wait for data\n\n            features[i] = mic.pop();\n        }\n\n        return true;\n    }\n\n    return false;\n}\nThe things to note in the above code are:\n\nthe PDM library works asynchronously: it won't block your main code waiting for data, but will report you back when data is ready calling the callback you define. In this case, the callback just instructs the mic object to update\nsince the PDM is asynchronous, when acquiring data you will first check if it's available: this is the case for while (!mic.hasData()) ;, which loops awaiting for new data\n\nNow that we have the acquisition logic in place, it's time for you to record some samples of the words you want to classify. I advise you to record many samples for each word, varying both the distance of your mounth from the mic and the intensity with which you speak: this will produce a more robust classification model later on.\nAs always, save each word in a different file, one feature vector per row.\nHere I report an extract of the features I recorded for some words (scaled and converted to int).\n// word &quot;yes&quot;\n43,47,41,48,60,68,67,54,40,29,17,9,6,6,10,15,10,10,8,8,8,5,7,7,12,6,8,11,7,5,3,3,13,14,15,17,15,16,10,10,16,13,8,9,14,8,0,3,3,3,8,5,3,8,11,10,12,10,11,13,8,6,5,12\n34,47,50,51,60,67,65,63,54,42,30,19,25,22,28,7,6,5,7,7,5,8,6,3,3,3,6,7,3,0,0,0,3,5,5,3,5,3,3,3,0,6,3,0,0,5,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,3,0,5\n33,41,45,47,53,61,64,59,50,41,31,17,8,9,7,9,9,7,8,8,8,10,13,8,8,7,5,5,5,3,0,0,0,0,3,8,8,3,0,3,5,5,5,7,0,0,0,0,0,5,0,3,3,5,0,0,0,5,3,0,5,7,0,9\n38,44,48,55,67,74,66,65,60,48,38,19,12,12,8,8,6,7,5,6,6,6,3,3,3,3,5,3,5,3,6,5,0,3,5,0,0,0,3,0,5,3,0,3,0,0,5,6,3,5,3,5,0,0,0,5,3,0,0,0,0,0,0,0\n\n// word &quot;no&quot;\n35,47,49,55,63,65,68,64,60,59,58,41,29,22,14,8,7,5,8,6,0,3,0,0,3,3,0,3,0,0,0,5,3,0,0,0,0,0,0,0,0,0,5,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,7,5,5,3\n42,51,55,59,68,70,73,70,71,67,67,52,52,29,16,9,6,9,3,3,5,8,8,11,10,7,8,5,3,3,0,0,0,0,0,3,3,3,6,7,7,8,9,6,8,8,7,8,6,8,8,6,8,7,6,9,5,3,5,6,5,3,3,3\n56,68,78,91,84,84,84,74,69,64,57,44,33,18,12,8,5,9,15,12,12,9,12,7,3,10,12,6,3,0,0,0,0,6,3,6,10,10,8,3,9,9,9,8,9,9,11,3,8,9,8,8,8,6,7,3,3,8,5,3,0,3,0,0\n31,42,62,69,74,81,78,78,79,74,74,68,54,44,26,15,8,8,21,10,15,12,11,8,6,5,0,0,0,0,3,5,8,3,9,5,6,9,10,6,10,12,7,15,14,5,8,7,8,9,5,8,5,6,5,0,3,6,3,5,3,5,0,0\n\n// word &quot;play&quot;\n31,195,106,60,45,44,55,51,42,36,36,33,38,37,37,29,24,21,20,20,18,19,14,10,14,12,18,11,8,11,10,12,27,8,10,6,7,6,10,6,6,6,8,6,6,3,5,6,0,0,0,0,0,7,5,3,0,5,0,0,8,8,7,5\n138,158,83,64,44,34,36,41,44,39,35,29,27,26,28,33,33,30,23,19,22,18,16,15,15,13,13,14,9,10,9,7,14,8,3,9,0,0,0,3,5,3,7,7,5,0,0,0,5,0,0,3,5,0,0,0,0,10,3,3,7,7,8,3\n89,36,27,30,22,24,38,41,37,33,32,32,32,35,34,30,25,19,18,18,15,16,14,14,12,9,8,10,9,7,3,0,0,8,7,7,6,3,5,9,8,5,7,3,5,7,6,6,3,0,3,3,0,8,8,5,6,0,0,6,0,7,8,6\n71,98,51,31,27,35,48,50,45,38,34,30,31,30,36,35,28,21,20,16,15,16,16,14,12,10,12,10,8,8,6,7,5,7,12,6,10,10,10,8,8,0,0,8,7,0,5,6,3,0,5,3,0,0,3,5,8,6,5,3,10,3,6,0\n\n// word &quot;stop&quot;\n61,93,135,157,140,148,128,92,85,64,160,75,23,28,28,22,14,8,0,3,3,5,3,6,12,202,154,100,102,94,40,54,52,40,35,22,20,19,11,18,9,7,10,12,8,7,5,7,12,14,16,12,8,6,5,11,5,7,9,10,12,21,20,16\n62,84,110,111,113,99,79,70,60,95,71,22,14,19,16,16,6,12,9,7,3,0,3,6,184,209,116,50,33,49,47,45,32,28,21,16,13,13,3,0,0,8,21,14,10,19,19,15,16,15,22,14,14,14,17,14,12,10,3,9,17,11,10,12\n94,139,168,178,165,143,100,82,128,169,34,22,26,26,22,13,8,8,3,0,3,0,5,202,191,123,119,119,64,31,71,39,35,30,19,16,14,8,19,7,8,7,6,11,18,17,13,20,24,27,29,22,23,22,25,23,21,23,21,18,17,14,14,13\n121,159,181,165,170,154,134,99,75,121,51,8,27,14,18,10,7,3,5,0,5,3,6,11,152,118,160,115,68,42,29,36,53,35,38,30,26,22,19,12,7,6,0,0,0,6,11,15,17,19,18,24,22,24,23,16,15,20,22,12,10,16,21,14\nWhere's the FFT?\nIf you noticed, I didn't mention the Fast Fourier Transform until now.\nWhy?\nWell, it is believed (at least, I believed) that the Fourier Transform is the go-to transformation when working with audio recordings: it can extract frequency-related features useful to extract information from raw signals.\nFor this project, I tried not to use it and I was surprised that it worked fine in spite of everything. Since I like to keep things as lean as possible, I won't apply any complex transformation to the samples.\nIf you're having poor results, however, remember you can try to apply FFT and see if it helps improve the accuracy.\nMachine learning model\nNow that we have the samples, it's time to train the classifier.\nThis step is the same as in any other tutorial I wrote so far, so I won't spend much time on this part. Among the classifiers I tried, SVM produced the best accuracy at 96% with 32 support vectors: it's not a super-tiny model, but it's quite small nevertheless.\nimport numpy as np\nfrom os.path import basename\nfrom glob import glob\nfrom sklearn.svm import SVC\nfrom micromlgen import port\n\ndef load_features(folder):\n    dataset = None\n    classmap = {}\n    for class_idx, filename in enumerate(glob(&#039;%s/*.csv&#039; % folder)):\n        class_name = basename(filename)[:-4]\n        classmap[class_idx] = class_name\n        samples = np.loadtxt(filename, dtype=float, delimiter=&#039;,&#039;)\n        labels = np.ones((len(samples), 1)) * class_idx\n        samples = np.hstack((samples, labels))\n        dataset = samples if dataset is None else np.vstack((dataset, samples))\n    return dataset, classmap\n\ndataset, classmap = load_features(&#039;64&#039;)\nX, y = dataset[:, :-1], dataset[:, -1]\nclf = SVC(kernel=&#039;poly&#039;, degree=2, gamma=0.1, C=100)\nclf.fit(X_train, y_train)\nprint(port(clf, classmap=classmap))\n// The produced ouput for my SVM model\n\n#pragma once\nnamespace Eloquent {\n    namespace ML {\n        namespace Port {\n            class SVM {\n            public:\n                /**\n                * Predict class for features vector\n                */\n                int predict(float *x) {\n                    float kernels[35] = { 0 };\n                    float decisions[6] = { 0 };\n                    int votes[4] = { 0 };\n                    kernels[0] = compute_kernel(x,   33.0  , 41.0  , 47.0  , 54.0  , 59.0  , 61.0  , 56.0  , 51.0  , 50.0  , 51.0  , 44.0  , 32.0  , 23.0  , 15.0  , 12.0  , 8.0  , 5.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 5.0  , 3.0  , 5.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0 );\n                    kernels[1] = compute_kernel(x,   40.0  , 50.0  , 51.0  , 60.0  , 56.0  , 57.0  , 58.0  , 53.0  , 50.0  , 45.0  , 42.0  , 34.0  , 23.0  , 16.0  , 10.0  , 7.0  , 3.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 14.0  , 3.0  , 8.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 5.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 5.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 3.0 );\n                    kernels[2] = compute_kernel(x,   56.0  , 68.0  , 78.0  , 91.0  , 84.0  , 84.0  , 84.0  , 74.0  , 69.0  , 64.0  , 57.0  , 44.0  , 33.0  , 18.0  , 12.0  , 8.0  , 5.0  , 9.0  , 15.0  , 12.0  , 12.0  , 9.0  , 12.0  , 7.0  , 3.0  , 10.0  , 12.0  , 6.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 6.0  , 3.0  , 6.0  , 10.0  , 10.0  , 8.0  , 3.0  , 9.0  , 9.0  , 9.0  , 8.0  , 9.0  , 9.0  , 11.0  , 3.0  , 8.0  , 9.0  , 8.0  , 8.0  , 8.0  , 6.0  , 7.0  , 3.0  , 3.0  , 8.0  , 5.0  , 3.0  , 0.0  , 3.0  , 0.0  , 0.0 );\n                    kernels[3] = compute_kernel(x,   33.0  , 18.0  , 26.0  , 39.0  , 46.0  , 60.0  , 66.0  , 72.0  , 82.0  , 76.0  , 82.0  , 77.0  , 78.0  , 79.0  , 76.0  , 73.0  , 63.0  , 41.0  , 33.0  , 21.0  , 13.0  , 7.0  , 3.0  , 10.0  , 3.0  , 5.0  , 6.0  , 21.0  , 21.0  , 14.0  , 5.0  , 8.0  , 5.0  , 5.0  , 0.0  , 8.0  , 8.0  , 3.0  , 0.0  , 3.0  , 3.0  , 5.0  , 0.0  , 3.0  , 8.0  , 7.0  , 6.0  , 7.0  , 8.0  , 9.0  , 9.0  , 8.0  , 8.0  , 7.0  , 17.0  , 3.0  , 3.0  , 6.0  , 6.0  , 5.0  , 3.0  , 6.0  , 6.0  , 3.0 );\n                    kernels[4] = compute_kernel(x,   54.0  , 57.0  , 62.0  , 58.0  , 61.0  , 61.0  , 59.0  , 58.0  , 57.0  , 51.0  , 34.0  , 25.0  , 18.0  , 10.0  , 6.0  , 6.0  , 10.0  , 7.0  , 5.0  , 10.0  , 5.0  , 7.0  , 8.0  , 6.0  , 5.0  , 5.0  , 5.0  , 7.0  , 3.0  , 5.0  , 0.0  , 0.0  , 0.0  , 3.0  , 3.0  , 6.0  , 0.0  , 7.0  , 0.0  , 5.0  , 6.0  , 0.0  , 0.0  , 6.0  , 7.0  , 5.0  , 3.0  , 5.0  , 6.0  , 0.0  , 0.0  , 0.0  , 12.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0 );\n                    kernels[5] = compute_kernel(x,   49.0  , 58.0  , 68.0  , 69.0  , 72.0  , 72.0  , 75.0  , 76.0  , 73.0  , 59.0  , 59.0  , 36.0  , 19.0  , 12.0  , 12.0  , 17.0  , 12.0  , 21.0  , 9.0  , 6.0  , 8.0  , 6.0  , 7.0  , 15.0  , 14.0  , 14.0  , 10.0  , 8.0  , 5.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 7.0  , 10.0  , 7.0  , 6.0  , 8.0  , 12.0  , 13.0  , 15.0  , 11.0  , 16.0  , 15.0  , 13.0  , 7.0  , 6.0  , 12.0  , 5.0  , 8.0  , 8.0  , 12.0  , 8.0  , 0.0  , 3.0  , 7.0  , 10.0  , 9.0  , 8.0  , 5.0 );\n                    kernels[6] = compute_kernel(x,   43.0  , 63.0  , 76.0  , 73.0  , 67.0  , 72.0  , 64.0  , 50.0  , 31.0  , 123.0  , 95.0  , 27.0  , 17.0  , 20.0  , 12.0  , 14.0  , 11.0  , 9.0  , 6.0  , 3.0  , 3.0  , 15.0  , 156.0  , 172.0  , 69.0  , 52.0  , 47.0  , 41.0  , 18.0  , 29.0  , 46.0  , 20.0  , 22.0  , 21.0  , 0.0  , 0.0  , 6.0  , 3.0  , 7.0  , 10.0  , 10.0  , 14.0  , 13.0  , 13.0  , 11.0  , 8.0  , 18.0  , 26.0  , 19.0  , 15.0  , 15.0  , 16.0  , 17.0  , 13.0  , 11.0  , 8.0  , 20.0  , 19.0  , 10.0  , 9.0  , 10.0  , 12.0  , 9.0  , 12.0 );\n                    kernels[7] = compute_kernel(x,   66.0  , 85.0  , 105.0  , 116.0  , 118.0  , 104.0  , 102.0  , 81.0  , 58.0  , 129.0  , 222.0  , 48.0  , 80.0  , 70.0  , 50.0  , 40.0  , 19.0  , 11.0  , 3.0  , 0.0  , 0.0  , 0.0  , 7.0  , 5.0  , 15.0  , 16.0  , 9.0  , 5.0  , 25.0  , 29.0  , 43.0  , 32.0  , 28.0  , 31.0  , 21.0  , 8.0  , 0.0  , 9.0  , 8.0  , 3.0  , 3.0  , 0.0  , 0.0  , 7.0  , 11.0  , 9.0  , 26.0  , 16.0  , 13.0  , 9.0  , 20.0  , 16.0  , 16.0  , 26.0  , 18.0  , 10.0  , 7.0  , 12.0  , 10.0  , 8.0  , 7.0  , 17.0  , 15.0  , 7.0 );\n                    kernels[8] = compute_kernel(x,   64.0  , 77.0  , 90.0  , 92.0  , 93.0  , 93.0  , 83.0  , 58.0  , 112.0  , 80.0  , 34.0  , 13.0  , 16.0  , 10.0  , 5.0  , 3.0  , 7.0  , 0.0  , 0.0  , 0.0  , 8.0  , 10.0  , 50.0  , 101.0  , 44.0  , 41.0  , 16.0  , 23.0  , 19.0  , 6.0  , 13.0  , 19.0  , 25.0  , 15.0  , 8.0  , 0.0  , 0.0  , 0.0  , 0.0  , 5.0  , 10.0  , 19.0  , 8.0  , 8.0  , 10.0  , 7.0  , 8.0  , 9.0  , 14.0  , 7.0  , 9.0  , 8.0  , 10.0  , 8.0  , 7.0  , 6.0  , 6.0  , 3.0  , 7.0  , 6.0  , 3.0  , 3.0  , 3.0  , 3.0 );\n                    kernels[9] = compute_kernel(x,   33.0  , 28.0  , 20.0  , 9.0  , 5.0  , 7.0  , 7.0  , 13.0  , 130.0  , 183.0  , 212.0  , 197.0  , 190.0  , 167.0  , 151.0  , 110.0  , 83.0  , 54.0  , 67.0  , 20.0  , 23.0  , 24.0  , 16.0  , 12.0  , 7.0  , 0.0  , 3.0  , 9.0  , 0.0  , 3.0  , 5.0  , 10.0  , 79.0  , 109.0  , 80.0  , 75.0  , 38.0  , 38.0  , 29.0  , 26.0  , 29.0  , 27.0  , 26.0  , 27.0  , 22.0  , 22.0  , 15.0  , 6.0  , 0.0  , 3.0  , 12.0  , 18.0  , 21.0  , 24.0  , 27.0  , 27.0  , 25.0  , 26.0  , 25.0  , 25.0  , 27.0  , 25.0  , 22.0  , 19.0 );\n                    kernels[10] = compute_kernel(x,   36.0  , 58.0  , 70.0  , 69.0  , 62.0  , 56.0  , 52.0  , 50.0  , 26.0  , 9.0  , 3.0  , 0.0  , 3.0  , 6.0  , 3.0  , 0.0  , 0.0  , 5.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 5.0  , 0.0  , 0.0  , 7.0  , 6.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 3.0  , 0.0  , 3.0  , 5.0  , 7.0  , 5.0  , 0.0  , 0.0  , 7.0  , 9.0  , 6.0  , 5.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 3.0  , 0.0  , 5.0  , 5.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 8.0  , 6.0 );\n                    kernels[11] = compute_kernel(x,   99.0  , 122.0  , 127.0  , 115.0  , 110.0  , 101.0  , 88.0  , 64.0  , 51.0  , 186.0  , 73.0  , 16.0  , 25.0  , 26.0  , 22.0  , 18.0  , 12.0  , 9.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 21.0  , 14.0  , 3.0  , 11.0  , 19.0  , 34.0  , 31.0  , 33.0  , 18.0  , 15.0  , 9.0  , 19.0  , 19.0  , 16.0  , 6.0  , 0.0  , 0.0  , 0.0  , 7.0  , 12.0  , 9.0  , 10.0  , 12.0  , 14.0  , 12.0  , 13.0  , 10.0  , 10.0  , 12.0  , 9.0  , 13.0  , 13.0  , 14.0  , 8.0  , 11.0  , 8.0  , 6.0  , 3.0  , 7.0  , 3.0  , 5.0 );\n                    kernels[12] = compute_kernel(x,   51.0  , 69.0  , 82.0  , 82.0  , 78.0  , 82.0  , 71.0  , 68.0  , 50.0  , 33.0  , 58.0  , 76.0  , 28.0  , 5.0  , 12.0  , 12.0  , 6.0  , 6.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 5.0  , 52.0  , 90.0  , 45.0  , 30.0  , 19.0  , 12.0  , 19.0  , 19.0  , 18.0  , 7.0  , 13.0  , 16.0  , 10.0  , 7.0  , 3.0  , 0.0  , 5.0  , 6.0  , 0.0  , 11.0  , 17.0  , 14.0  , 12.0  , 16.0  , 9.0  , 11.0  , 11.0  , 18.0  , 13.0  , 8.0  , 8.0  , 10.0  , 12.0  , 8.0  , 9.0  , 8.0  , 8.0  , 5.0  , 6.0 );\n                    kernels[13] = compute_kernel(x,   55.0  , 102.0  , 134.0  , 149.0  , 145.0  , 149.0  , 148.0  , 127.0  , 94.0  , 64.0  , 108.0  , 94.0  , 37.0  , 15.0  , 22.0  , 17.0  , 17.0  , 14.0  , 13.0  , 0.0  , 8.0  , 14.0  , 9.0  , 0.0  , 6.0  , 3.0  , 7.0  , 5.0  , 6.0  , 5.0  , 5.0  , 12.0  , 8.0  , 0.0  , 10.0  , 14.0  , 8.0  , 9.0  , 0.0  , 3.0  , 3.0  , 0.0  , 5.0  , 3.0  , 8.0  , 8.0  , 3.0  , 3.0  , 3.0  , 3.0  , 8.0  , 3.0  , 5.0  , 0.0  , 0.0  , 0.0  , 12.0  , 3.0  , 0.0  , 7.0  , 5.0  , 3.0  , 0.0  , 0.0 );\n                    kernels[14] = compute_kernel(x,   75.0  , 89.0  , 116.0  , 125.0  , 124.0  , 102.0  , 109.0  , 99.0  , 80.0  , 57.0  , 136.0  , 108.0  , 55.0  , 10.0  , 20.0  , 20.0  , 16.0  , 10.0  , 8.0  , 14.0  , 6.0  , 0.0  , 3.0  , 3.0  , 6.0  , 19.0  , 8.0  , 11.0  , 3.0  , 46.0  , 33.0  , 29.0  , 26.0  , 22.0  , 12.0  , 14.0  , 21.0  , 16.0  , 18.0  , 16.0  , 13.0  , 3.0  , 0.0  , 8.0  , 6.0  , 14.0  , 10.0  , 21.0  , 21.0  , 17.0  , 16.0  , 16.0  , 19.0  , 17.0  , 16.0  , 20.0  , 14.0  , 10.0  , 14.0  , 13.0  , 12.0  , 12.0  , 10.0  , 6.0 );\n                    kernels[15] = compute_kernel(x,   43.0  , 57.0  , 63.0  , 60.0  , 64.0  , 57.0  , 55.0  , 35.0  , 18.0  , 14.0  , 13.0  , 5.0  , 3.0  , 10.0  , 5.0  , 3.0  , 3.0  , 0.0  , 7.0  , 3.0  , 5.0  , 5.0  , 0.0  , 23.0  , 8.0  , 3.0  , 3.0  , 17.0  , 6.0  , 13.0  , 10.0  , 5.0  , 0.0  , 10.0  , 7.0  , 9.0  , 8.0  , 13.0  , 6.0  , 7.0  , 5.0  , 6.0  , 3.0  , 3.0  , 5.0  , 8.0  , 3.0  , 3.0  , 5.0  , 5.0  , 5.0  , 7.0  , 8.0  , 6.0  , 6.0  , 7.0  , 6.0  , 6.0  , 5.0  , 5.0  , 5.0  , 5.0  , 5.0  , 3.0 );\n                    kernels[16] = compute_kernel(x,   31.0  , 33.0  , 27.0  , 19.0  , 14.0  , 9.0  , 3.0  , 6.0  , 16.0  , 131.0  , 186.0  , 214.0  , 206.0  , 212.0  , 192.0  , 186.0  , 147.0  , 90.0  , 157.0  , 98.0  , 34.0  , 37.0  , 35.0  , 31.0  , 17.0  , 10.0  , 7.0  , 0.0  , 3.0  , 3.0  , 5.0  , 6.0  , 10.0  , 12.0  , 22.0  , 50.0  , 48.0  , 48.0  , 61.0  , 28.0  , 26.0  , 29.0  , 30.0  , 24.0  , 26.0  , 19.0  , 26.0  , 15.0  , 26.0  , 19.0  , 17.0  , 10.0  , 3.0  , 3.0  , 0.0  , 6.0  , 12.0  , 16.0  , 16.0  , 21.0  , 25.0  , 27.0  , 27.0  , 26.0 );\n                    kernels[17] = compute_kernel(x,   50.0  , 70.0  , 80.0  , 83.0  , 79.0  , 73.0  , 80.0  , 74.0  , 54.0  , 34.0  , 16.0  , 7.0  , 3.0  , 3.0  , 3.0  , 3.0  , 6.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 5.0  , 3.0  , 10.0  , 3.0  , 7.0  , 5.0  , 0.0  , 3.0  , 3.0  , 3.0  , 3.0  , 0.0  , 5.0  , 6.0  , 0.0  , 0.0  , 3.0  , 3.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 7.0  , 3.0  , 0.0  , 3.0  , 0.0 );\n                    kernels[18] = compute_kernel(x,   38.0  , 50.0  , 52.0  , 49.0  , 44.0  , 42.0  , 43.0  , 41.0  , 41.0  , 42.0  , 42.0  , 40.0  , 35.0  , 29.0  , 23.0  , 22.0  , 20.0  , 20.0  , 18.0  , 16.0  , 16.0  , 15.0  , 11.0  , 12.0  , 15.0  , 11.0  , 13.0  , 8.0  , 5.0  , 5.0  , 3.0  , 0.0  , 0.0  , 3.0  , 7.0  , 3.0  , 8.0  , 3.0  , 0.0  , 5.0  , 6.0  , 5.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 6.0  , 3.0  , 8.0  , 5.0  , 7.0  , 5.0  , 8.0  , 8.0  , 7.0  , 6.0  , 10.0  , 11.0  , 3.0  , 5.0 );\n                    kernels[19] = compute_kernel(x,   33.0  , 37.0  , 34.0  , 30.0  , 25.0  , 22.0  , 37.0  , 44.0  , 40.0  , 36.0  , 33.0  , 29.0  , 27.0  , 26.0  , 28.0  , 28.0  , 28.0  , 25.0  , 20.0  , 16.0  , 14.0  , 13.0  , 12.0  , 11.0  , 10.0  , 10.0  , 10.0  , 7.0  , 6.0  , 6.0  , 6.0  , 6.0  , 5.0  , 0.0  , 5.0  , 5.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0 );\n                    kernels[20] = compute_kernel(x,   43.0  , 52.0  , 49.0  , 45.0  , 44.0  , 43.0  , 43.0  , 41.0  , 43.0  , 42.0  , 36.0  , 34.0  , 28.0  , 27.0  , 21.0  , 18.0  , 19.0  , 17.0  , 16.0  , 15.0  , 13.0  , 14.0  , 14.0  , 12.0  , 13.0  , 14.0  , 10.0  , 8.0  , 7.0  , 5.0  , 3.0  , 5.0  , 8.0  , 0.0  , 0.0  , 5.0  , 8.0  , 7.0  , 3.0  , 0.0  , 3.0  , 5.0  , 3.0  , 7.0  , 6.0  , 8.0  , 0.0  , 6.0  , 3.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 7.0  , 10.0  , 8.0  , 14.0  , 7.0  , 5.0  , 11.0 );\n                    kernels[21] = compute_kernel(x,   33.0  , 28.0  , 26.0  , 21.0  , 22.0  , 31.0  , 38.0  , 35.0  , 33.0  , 32.0  , 30.0  , 28.0  , 25.0  , 28.0  , 29.0  , 30.0  , 27.0  , 25.0  , 20.0  , 16.0  , 16.0  , 15.0  , 15.0  , 13.0  , 11.0  , 10.0  , 9.0  , 8.0  , 5.0  , 6.0  , 5.0  , 0.0  , 9.0  , 12.0  , 9.0  , 12.0  , 12.0  , 9.0  , 8.0  , 13.0  , 12.0  , 10.0  , 13.0  , 7.0  , 10.0  , 16.0  , 10.0  , 16.0  , 6.0  , 0.0  , 0.0  , 8.0  , 0.0  , 6.0  , 10.0  , 8.0  , 11.0  , 10.0  , 5.0  , 8.0  , 9.0  , 8.0  , 6.0  , 6.0 );\n                    kernels[22] = compute_kernel(x,   40.0  , 49.0  , 48.0  , 45.0  , 48.0  , 47.0  , 51.0  , 55.0  , 52.0  , 43.0  , 35.0  , 30.0  , 16.0  , 8.0  , 6.0  , 8.0  , 8.0  , 7.0  , 7.0  , 9.0  , 10.0  , 8.0  , 9.0  , 8.0  , 6.0  , 8.0  , 6.0  , 5.0  , 10.0  , 7.0  , 3.0  , 3.0  , 0.0  , 3.0  , 3.0  , 0.0  , 0.0  , 5.0  , 6.0  , 8.0  , 9.0  , 14.0  , 13.0  , 14.0  , 10.0  , 10.0  , 10.0  , 8.0  , 7.0  , 0.0  , 5.0  , 0.0  , 0.0  , 3.0  , 3.0  , 10.0  , 10.0  , 0.0  , 8.0  , 14.0  , 9.0  , 12.0  , 5.0  , 14.0 );\n                    kernels[23] = compute_kernel(x,   37.0  , 42.0  , 57.0  , 68.0  , 69.0  , 75.0  , 74.0  , 67.0  , 51.0  , 38.0  , 26.0  , 13.0  , 6.0  , 13.0  , 15.0  , 14.0  , 11.0  , 10.0  , 8.0  , 12.0  , 9.0  , 8.0  , 5.0  , 8.0  , 13.0  , 8.0  , 3.0  , 3.0  , 0.0  , 0.0  , 9.0  , 9.0  , 5.0  , 7.0  , 6.0  , 3.0  , 3.0  , 5.0  , 5.0  , 7.0  , 3.0  , 6.0  , 3.0  , 6.0  , 3.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 5.0  , 0.0  , 0.0  , 3.0  , 0.0 );\n                    kernels[24] = compute_kernel(x,   42.0  , 39.0  , 41.0  , 45.0  , 46.0  , 49.0  , 46.0  , 43.0  , 35.0  , 28.0  , 18.0  , 11.0  , 7.0  , 10.0  , 8.0  , 10.0  , 8.0  , 8.0  , 7.0  , 8.0  , 8.0  , 8.0  , 8.0  , 8.0  , 6.0  , 5.0  , 6.0  , 5.0  , 6.0  , 5.0  , 0.0  , 3.0  , 5.0  , 6.0  , 0.0  , 5.0  , 3.0  , 8.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 3.0 );\n                    kernels[25] = compute_kernel(x,   45.0  , 43.0  , 45.0  , 48.0  , 56.0  , 54.0  , 54.0  , 44.0  , 35.0  , 25.0  , 19.0  , 8.0  , 6.0  , 5.0  , 6.0  , 5.0  , 5.0  , 6.0  , 5.0  , 6.0  , 6.0  , 6.0  , 5.0  , 5.0  , 3.0  , 3.0  , 5.0  , 5.0  , 6.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 7.0  , 9.0  , 5.0  , 5.0  , 0.0  , 0.0  , 0.0  , 5.0  , 3.0  , 3.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 5.0  , 6.0  , 5.0  , 0.0  , 0.0 );\n                    kernels[26] = compute_kernel(x,   31.0  , 43.0  , 66.0  , 75.0  , 75.0  , 81.0  , 89.0  , 85.0  , 79.0  , 68.0  , 50.0  , 32.0  , 22.0  , 10.0  , 8.0  , 12.0  , 10.0  , 10.0  , 12.0  , 12.0  , 11.0  , 10.0  , 10.0  , 8.0  , 8.0  , 9.0  , 8.0  , 7.0  , 7.0  , 6.0  , 3.0  , 3.0  , 3.0  , 0.0  , 0.0  , 5.0  , 8.0  , 8.0  , 6.0  , 3.0  , 7.0  , 8.0  , 11.0  , 12.0  , 12.0  , 16.0  , 9.0  , 0.0  , 0.0  , 0.0  , 3.0  , 7.0  , 7.0  , 8.0  , 6.0  , 8.0  , 12.0  , 10.0  , 8.0  , 7.0  , 5.0  , 3.0  , 6.0  , 8.0 );\n                    kernels[27] = compute_kernel(x,   33.0  , 40.0  , 41.0  , 41.0  , 43.0  , 48.0  , 49.0  , 49.0  , 47.0  , 36.0  , 27.0  , 18.0  , 9.0  , 3.0  , 5.0  , 3.0  , 5.0  , 5.0  , 5.0  , 3.0  , 3.0  , 3.0  , 3.0  , 3.0  , 3.0  , 3.0  , 3.0  , 3.0  , 3.0  , 0.0  , 3.0  , 3.0  , 7.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0 );\n                    kernels[28] = compute_kernel(x,   30.0  , 47.0  , 72.0  , 81.0  , 81.0  , 79.0  , 85.0  , 88.0  , 85.0  , 86.0  , 64.0  , 45.0  , 27.0  , 15.0  , 13.0  , 14.0  , 11.0  , 18.0  , 20.0  , 24.0  , 18.0  , 17.0  , 20.0  , 15.0  , 19.0  , 14.0  , 10.0  , 10.0  , 8.0  , 6.0  , 6.0  , 3.0  , 3.0  , 0.0  , 6.0  , 7.0  , 18.0  , 15.0  , 11.0  , 12.0  , 19.0  , 20.0  , 10.0  , 8.0  , 0.0  , 0.0  , 0.0  , 6.0  , 6.0  , 9.0  , 10.0  , 9.0  , 12.0  , 12.0  , 10.0  , 12.0  , 12.0  , 3.0  , 6.0  , 7.0  , 8.0  , 10.0  , 8.0  , 5.0 );\n                    kernels[29] = compute_kernel(x,   33.0  , 31.0  , 31.0  , 33.0  , 36.0  , 36.0  , 36.0  , 32.0  , 25.0  , 19.0  , 12.0  , 5.0  , 5.0  , 10.0  , 6.0  , 6.0  , 8.0  , 6.0  , 7.0  , 6.0  , 6.0  , 6.0  , 11.0  , 6.0  , 6.0  , 6.0  , 5.0  , 3.0  , 3.0  , 0.0  , 0.0  , 6.0  , 3.0  , 5.0  , 3.0  , 10.0  , 5.0  , 6.0  , 9.0  , 3.0  , 7.0  , 6.0  , 6.0  , 8.0  , 7.0  , 0.0  , 6.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 6.0  , 6.0  , 0.0  , 5.0  , 3.0  , 3.0  , 5.0  , 8.0  , 7.0  , 0.0 );\n                    kernels[30] = compute_kernel(x,   31.0  , 48.0  , 65.0  , 60.0  , 68.0  , 81.0  , 88.0  , 91.0  , 93.0  , 79.0  , 56.0  , 32.0  , 22.0  , 12.0  , 16.0  , 13.0  , 12.0  , 13.0  , 13.0  , 13.0  , 14.0  , 11.0  , 11.0  , 14.0  , 12.0  , 10.0  , 8.0  , 8.0  , 7.0  , 5.0  , 3.0  , 0.0  , 3.0  , 5.0  , 5.0  , 7.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 6.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 3.0  , 5.0  , 0.0  , 0.0  , 0.0 );\n                    kernels[31] = compute_kernel(x,   34.0  , 47.0  , 50.0  , 51.0  , 60.0  , 67.0  , 65.0  , 63.0  , 54.0  , 42.0  , 30.0  , 19.0  , 25.0  , 22.0  , 28.0  , 7.0  , 6.0  , 5.0  , 7.0  , 7.0  , 5.0  , 8.0  , 6.0  , 3.0  , 3.0  , 3.0  , 6.0  , 7.0  , 3.0  , 0.0  , 0.0  , 0.0  , 3.0  , 5.0  , 5.0  , 3.0  , 5.0  , 3.0  , 3.0  , 3.0  , 0.0  , 6.0  , 3.0  , 0.0  , 0.0  , 5.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 5.0 );\n                    kernels[32] = compute_kernel(x,   34.0  , 48.0  , 58.0  , 55.0  , 59.0  , 69.0  , 77.0  , 75.0  , 75.0  , 69.0  , 56.0  , 43.0  , 22.0  , 13.0  , 10.0  , 6.0  , 9.0  , 15.0  , 11.0  , 10.0  , 8.0  , 8.0  , 7.0  , 3.0  , 6.0  , 5.0  , 5.0  , 7.0  , 6.0  , 6.0  , 7.0  , 3.0  , 5.0  , 11.0  , 5.0  , 7.0  , 6.0  , 8.0  , 11.0  , 8.0  , 16.0  , 9.0  , 7.0  , 8.0  , 6.0  , 3.0  , 6.0  , 3.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 6.0  , 3.0  , 0.0  , 3.0  , 5.0  , 8.0  , 10.0  , 13.0  , 13.0 );\n                    kernels[33] = compute_kernel(x,   32.0  , 31.0  , 33.0  , 33.0  , 35.0  , 37.0  , 34.0  , 28.0  , 25.0  , 15.0  , 10.0  , 5.0  , 6.0  , 5.0  , 7.0  , 8.0  , 6.0  , 6.0  , 7.0  , 8.0  , 5.0  , 6.0  , 5.0  , 7.0  , 6.0  , 5.0  , 3.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 3.0  , 0.0  , 0.0  , 5.0  , 3.0  , 0.0  , 3.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0  , 0.0 );\n                    kernels[34] = compute_kernel(x,   44.0  , 43.0  , 48.0  , 58.0  , 59.0  , 54.0  , 55.0  , 49.0  , 48.0  , 38.0  , 26.0  , 14.0  , 8.0  , 9.0  , 14.0  , 12.0  , 7.0  , 9.0  , 10.0  , 8.0  , 9.0  , 7.0  , 6.0  , 6.0  , 6.0  , 6.0  , 6.0  , 5.0  , 6.0  , 8.0  , 6.0  , 0.0  , 0.0  , 13.0  , 8.0  , 6.0  , 17.0  , 10.0  , 8.0  , 17.0  , 13.0  , 15.0  , 13.0  , 14.0  , 8.0  , 8.0  , 11.0  , 8.0  , 8.0  , 6.0  , 5.0  , 3.0  , 5.0  , 3.0  , 8.0  , 7.0  , 6.0  , 10.0  , 9.0  , 12.0  , 13.0  , 10.0  , 7.0  , 10.0 );\n                    decisions[0] = 0.722587775297\n                                   + kernels[1] * 3.35855e-07\n                                   + kernels[2] * 1.64612e-07\n                                   + kernels[4] * 6.00056e-07\n                                   + kernels[5] * 3.5195e-08\n                                   + kernels[7] * -4.2079e-08\n                                   + kernels[8] * -4.2843e-08\n                                   + kernels[9] * -9.994e-09\n                                   + kernels[10] * -5.11065e-07\n                                   + kernels[11] * -5.979e-09\n                                   + kernels[12] * -4.4672e-08\n                                   + kernels[13] * -1.5606e-08\n                                   + kernels[14] * -1.2941e-08\n                                   + kernels[15] * -2.18903e-07\n                                   + kernels[17] * -2.31635e-07\n                            ;\n                    decisions[1] = -1.658344586719\n                                   + kernels[0] * 2.45018e-07\n                                   + kernels[1] * 4.30223e-07\n                                   + kernels[3] * 1.00277e-07\n                                   + kernels[4] * 2.16524e-07\n                                   + kernels[18] * -4.81187e-07\n                                   + kernels[20] * -5.10856e-07\n                            ;\n                    decisions[2] = -1.968607562265\n                                   + kernels[0] * 3.001833e-06\n                                   + kernels[3] * 4.5201e-08\n                                   + kernels[4] * 1.54493e-06\n                                   + kernels[5] * 2.81834e-07\n                                   + kernels[25] * -5.93581e-07\n                                   + kernels[26] * -2.89779e-07\n                                   + kernels[27] * -1.73958e-06\n                                   + kernels[28] * -1.09552e-07\n                                   + kernels[30] * -3.09126e-07\n                                   + kernels[31] * -1.294219e-06\n                                   + kernels[32] * -5.37961e-07\n                            ;\n                    decisions[3] = -0.720663029823\n                                   + kernels[6] * 1.4362e-08\n                                   + kernels[7] * 6.177e-09\n                                   + kernels[9] * 1.25e-08\n                                   + kernels[10] * 2.05478e-07\n                                   + kernels[12] * 2.501e-08\n                                   + kernels[15] * 4.363e-07\n                                   + kernels[16] * 9.147e-09\n                                   + kernels[18] * -1.82182e-07\n                                   + kernels[20] * -4.93707e-07\n                                   + kernels[21] * -3.3084e-08\n                            ;\n                    decisions[4] = -1.605747746589\n                                   + kernels[6] * 6.182e-09\n                                   + kernels[7] * 1.3853e-08\n                                   + kernels[8] * 2.12e-10\n                                   + kernels[9] * 1.1243e-08\n                                   + kernels[10] * 7.80681e-07\n                                   + kernels[15] * 8.347e-07\n                                   + kernels[17] * 1.64985e-07\n                                   + kernels[23] * -4.25014e-07\n                                   + kernels[25] * -1.134803e-06\n                                   + kernels[34] * -2.52038e-07\n                            ;\n                    decisions[5] = -0.934328303475\n                                   + kernels[19] * 3.3529e-07\n                                   + kernels[20] * 1.121946e-06\n                                   + kernels[21] * 3.44683e-07\n                                   + kernels[22] * -6.23056e-07\n                                   + kernels[24] * -1.4612e-07\n                                   + kernels[28] * -1.24025e-07\n                                   + kernels[29] * -4.31701e-07\n                                   + kernels[31] * -9.2146e-08\n                                   + kernels[33] * -3.8487e-07\n                            ;\n                    votes[decisions[0] &gt; 0 ? 0 : 1] += 1;\n                    votes[decisions[1] &gt; 0 ? 0 : 2] += 1;\n                    votes[decisions[2] &gt; 0 ? 0 : 3] += 1;\n                    votes[decisions[3] &gt; 0 ? 1 : 2] += 1;\n                    votes[decisions[4] &gt; 0 ? 1 : 3] += 1;\n                    votes[decisions[5] &gt; 0 ? 2 : 3] += 1;\n                    int val = votes[0];\n                    int idx = 0;\n\n                    for (int i = 1; i &lt; 4; i++) {\n                        if (votes[i] &gt; val) {\n                            val = votes[i];\n                            idx = i;\n                        }\n                    }\n\n                    return idx;\n                }\n\n                /**\n                * Convert class idx to readable name\n                */\n                const char* predictLabel(float *x) {\n                    switch (predict(x)) {\n                        case 0:\n                            return &quot;no&quot;;\n                        case 1:\n                            return &quot;stop&quot;;\n                        case 2:\n                            return &quot;play&quot;;\n                        case 3:\n                            return &quot;yes&quot;;\n                        default:\n                            return &quot;Houston we have a problem&quot;;\n                    }\n                }\n\n            protected:\n                /**\n                * Compute kernel between feature vector and support vector.\n                * Kernel type: poly\n                */\n                float compute_kernel(float *x, ...) {\n                    va_list w;\n                    va_start(w, 64);\n                    float kernel = 0.0;\n\n                    for (uint16_t i = 0; i &lt; 64; i++) {\n                        kernel += x[i] * va_arg(w, double);\n                    }\n\n                    return pow((0.1 * kernel) + 0.0, 2);\n                }\n            };\n        }\n    }\n}\nDone! Deploy the sketch to your board and it should now be able to &quot;understand&quot; what you tell it!\nHere's a quick demo (please forgive me for the bad video quality).\n\nhttps://eloquentarduino.github.io/wp-content/uploads/2020/08/Arduino-Nano-33-BLE-Sense-Word-classification.mp4\n\nLink to the Github repo\nL'articolo Better word classification with Arduino Nano 33 BLE Sense and Machine Learning proviene da Eloquent Arduino Blog.",
            "date_published": "2020-08-24T19:04:57+02:00",
            "date_modified": "2020-08-24T20:34:04+02:00",
            "authors": [
                {
                    "name": "simone",
                    "url": "https://eloquentarduino.github.io/author/simone/",
                    "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "ml",
                "Arduino Machine learning"
            ],
            "attachments": [
                {
                    "url": "https://eloquentarduino.github.io/wp-content/uploads/2020/08/Arduino-Nano-33-BLE-Sense-Word-classification.mp4",
                    "mime_type": "video/mp4",
                    "size_in_bytes": 5594095
                }
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/?p=1225",
            "url": "https://eloquentarduino.github.io/2020/08/eloquentml-grows-its-family-of-classifiers-gaussian-naive-bayes-on-arduino/",
            "title": "EloquentML grows its family of classifiers: Gaussian Naive Bayes on Arduino",
            "content_html": "<p>Are you looking for a top-performer classifiers with a minimal amount of parameters to tune? Look no further: Gaussian Naive Bayes is what you're looking for. And thanks to EloquentML you can now port it to your microcontroller.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/08/GaussianNB.png\" alt=\"GaussianNB\" /></p>\n<p><span id=\"more-1225\"></span></p>\n<h2>(Gaussian) Naive Bayes</h2>\n<p><a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">Naive Bayes</a> classifiers are simple models based on the probability theory that can be used for classification.</p>\n<p>They originate from the assumption of independence among the input variables. Even though this assumption doesn't hold true in the vast majority of the cases, they often perform very good at many classification tasks, so they're quite popular.</p>\n<p>Gaussian Naive Bayes stack another (mostly wrong) assumption: that the variables exhibit a Gaussian probability distribution.</p>\n<p>I (and many others like me) will never understand how it is possible that so many wrong assumptions lead to such good performances!</p>\n<p>Nevertheless, what is important to us is that <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\">sklearn implements GaussianNB</a>, so we easily train such a classifier.<br />\nThe most interesting part is that <code>GaussianNB</code> can be tuned with just a single parameter: <code>var_smoothing</code>.</p>\n<p>Don't ask me what it does in theory: in practice you change it and your accuracy can boost. This leads to an easy tuning process that doesn't involves expensive <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\">grid search</a>.</p>\n<pre><code class=\"language-python\">import sklearn.datasets as d\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import normalize\nfrom sklearn.naive_bayes import GaussianNB\n\ndef pick_best(X_train, X_test, y_train, y_test):\n    best = (None, 0)\n    for var_smoothing in range(-7, 1):\n        clf = GaussianNB(var_smoothing=pow(10, var_smoothing))\n        clf.fit(X_train, y_train)\n        y_pred = clf.predict(X_test)\n        accuracy = (y_pred == y_test).sum()\n        if accuracy &gt; best[1]:\n            best = (clf, accuracy)\n    print(&#039;best accuracy&#039;, best[1] / len(y_test))\n    return best[0]\n\niris = d.load_iris()\nX = normalize(iris.data)\ny = iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\nclf = pick_best(X_train, X_test, y_train, y_test)</code></pre>\n<p>This simple procedure will train a bunch of classifiers with a different <code>var_smoothing</code> factor and pick the best performing one.</p>\n<h2>EloquentML integration</h2>\n<p>Once you have your trained classifier, porting it to C is as easy as always:</p>\n<pre><code class=\"language-python\">from micromlgen import port\n\nclf = pick_best()\nprint(port(clf))</code></pre>\n<p class=\"watchout\">Always remember to run </p>\n<pre><code>pip install --upgrade micromlgen</code></pre>\n</p>\n<p><code>port</code> is a magic method able to port many classifiers: it will automatically detect the proper converter for you.</p>\n<p>What does the exported code looks like?</p>\n<pre><code class=\"language-cpp\">#pragma once\nnamespace Eloquent {\n    namespace ML {\n        namespace Port {\n            class GaussianNB {\n                public:\n                    /**\n                    * Predict class for features vector\n                    */\n                    int predict(float *x) {\n                        float votes[3] = { 0.0f };\n                        float theta[4] = { 0 };\n                        float sigma[4] = { 0 };\n                        theta[0] = 0.801139789889; theta[1] = 0.54726920354; theta[2] = 0.234408773313; theta[3] = 0.039178084094;\n                        sigma[0] = 0.000366881742; sigma[1] = 0.000907992556; sigma[2] = 0.000740960787; sigma[3] = 0.000274925514;\n                        votes[0] = 0.333333333333 - gauss(x, theta, sigma);\n                        theta[0] = 0.748563871324; theta[1] = 0.349390892644; theta[2] = 0.536186138345; theta[3] = 0.166747384117;\n                        sigma[0] = 0.000529727082; sigma[1] = 0.000847956504; sigma[2] = 0.000690057342; sigma[3] = 0.000311828658;\n                        votes[1] = 0.333333333333 - gauss(x, theta, sigma);\n                        theta[0] = 0.704497203305; theta[1] = 0.318862439835; theta[2] = 0.593755956917; theta[3] = 0.217288784452;\n                        sigma[0] = 0.000363782089; sigma[1] = 0.000813846722; sigma[2] = 0.000415475678; sigma[3] = 0.000758478249;\n                        votes[2] = 0.333333333333 - gauss(x, theta, sigma);\n                        // return argmax of votes\n                        uint8_t classIdx = 0;\n                        float maxVotes = votes[0];\n\n                        for (uint8_t i = 1; i &lt; 3; i++) {\n                            if (votes[i] &gt; maxVotes) {\n                                classIdx = i;\n                                maxVotes = votes[i];\n                            }\n                        }\n\n                        return classIdx;\n                    }\n\n                protected:\n                    /**\n                    * Compute gaussian value\n                    */\n                    float gauss(float *x, float *theta, float *sigma) {\n                        float gauss = 0.0f;\n\n                        for (uint16_t i = 0; i &lt; 4; i++) {\n                            gauss += log(sigma[i]);\n                            gauss += pow(x[i] - theta[i], 2) / sigma[i];\n                        }\n\n                        return gauss;\n                    }\n                };\n            }\n        }\n    }</code></pre>\n<!-- Begin Mailchimp Signup Form -->\r\n<div id=\"mc_embed_signup\">\r\n<form action=\"https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\r\n    <div id=\"mc_embed_signup_scroll\">\r\n\t<h2 style=\"margin: 0; text-align: center\">Finding this content useful?</h2>\r\n<div class=\"mc-field-group\">\r\n\t<input type=\"email\" value=\"\" name=\"EMAIL\" class=\"required email\" id=\"mce-EMAIL\" placeholder=\"join the monthly newsletter\">\r\n</div>\r\n\t<div id=\"mce-responses\" class=\"clear\">\r\n\t\t<div class=\"response\" id=\"mce-error-response\" style=\"display:none\"></div>\r\n\t\t<div class=\"response\" id=\"mce-success-response\" style=\"display:none\"></div>\r\n\t</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->\r\n    <div style=\"position: absolute; left: -5000px;\" aria-hidden=\"true\"><input type=\"text\" name=\"b_f0eaedd94d554cf2ee781742a_37d3496031\" tabindex=\"-1\" value=\"\"></div>\r\n    <div class=\"clear\" style=\"position: relative; top: 8px\"><input type=\"submit\" value=\"Subscribe\" name=\"subscribe\" id=\"mc-embedded-subscribe\" class=\"button\"></div>\r\n    </div>\r\n</form>\r\n</div>\r\n\r\n<!--End mc_embed_signup-->\n<p>As you can see, we need a couple of &quot;weight vectors&quot;:</p>\n<ul>\n<li><code>theta</code> is the mean of each feature</li>\n<li><code>sigma</code> is the standard deviation</li>\n</ul>\n<p>The computation is quite thin: just a couple of operations; the class with the highest score is then selected.</p>\n<h2>Benchmarks</h2>\n<p>Following there's a recap of a couple benchmarks I run on an Arduino Nano 33 Ble Sense.</p>\n<table>\n<thead>\n<tr>\n<th>Classifier</th>\n<th>Dataset</th>\n<th style=\"text-align: center;\">Flash</th>\n<th style=\"text-align: center;\">RAM</th>\n<th style=\"text-align: center;\">Execution time</th>\n<th style=\"text-align: center;\">Accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>GaussianNB</td>\n<td>Iris (150x4)</td>\n<td style=\"text-align: center;\">82 kb</td>\n<td style=\"text-align: center;\">42 Kb</td>\n<td style=\"text-align: center;\">65 ms</td>\n<td style=\"text-align: center;\">97%</td>\n</tr>\n<tr>\n<td>LinearSVC</td>\n<td>Iris (150x4)</td>\n<td style=\"text-align: center;\">83 Kb</td>\n<td style=\"text-align: center;\">42 Kb</td>\n<td style=\"text-align: center;\">76 ms</td>\n<td style=\"text-align: center;\">99%</td>\n</tr>\n<tr>\n<td>GaussianNB</td>\n<td>Breast cancer (80x40)</td>\n<td style=\"text-align: center;\">90 Kb</td>\n<td style=\"text-align: center;\">42 Kb</td>\n<td style=\"text-align: center;\">160 ms</td>\n<td style=\"text-align: center;\">77%</td>\n</tr>\n<tr>\n<td>LinearSVC</td>\n<td>Breast cancer (80x40)</td>\n<td style=\"text-align: center;\">112 Kb</td>\n<td style=\"text-align: center;\">42 Kb</td>\n<td style=\"text-align: center;\">378 ms</td>\n<td style=\"text-align: center;\">73%</td>\n</tr>\n<tr>\n<td>GaussianNB</td>\n<td>Wine (100x13)</td>\n<td style=\"text-align: center;\">85 Kb</td>\n<td style=\"text-align: center;\">42 Kb</td>\n<td style=\"text-align: center;\">130 ms</td>\n<td style=\"text-align: center;\">97%</td>\n</tr>\n<tr>\n<td>LinearSVC</td>\n<td>Wine (100x13)</td>\n<td style=\"text-align: center;\">89 Kb</td>\n<td style=\"text-align: center;\">42 Kb</td>\n<td style=\"text-align: center;\">125 ms</td>\n<td style=\"text-align: center;\">99%</td>\n</tr>\n</tbody>\n</table>\n<p>We can see that the accuracy is on par with a linear SVM, reaching up to 97% on some datasets. Its semplicity shines with high-dimensional datasets (breast cancer) where execution time is half of the LinearSVC: I can see this pattern repeating with other real-world, medium-sized datasets.</p>\n<hr />\n<p>This is it, you can find the example project on <a href=\"https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/GaussianNBClassificationExample/GaussianNBClassificationExample.ino\">Github</a>.</p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2020/08/eloquentml-grows-its-family-of-classifiers-gaussian-naive-bayes-on-arduino/\">EloquentML grows its family of classifiers: Gaussian Naive Bayes on Arduino</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "Are you looking for a top-performer classifiers with a minimal amount of parameters to tune? Look no further: Gaussian Naive Bayes is what you're looking for. And thanks to EloquentML you can now port it to your microcontroller.\n\n\n(Gaussian) Naive Bayes\nNaive Bayes classifiers are simple models based on the probability theory that can be used for classification.\nThey originate from the assumption of independence among the input variables. Even though this assumption doesn't hold true in the vast majority of the cases, they often perform very good at many classification tasks, so they're quite popular.\nGaussian Naive Bayes stack another (mostly wrong) assumption: that the variables exhibit a Gaussian probability distribution.\nI (and many others like me) will never understand how it is possible that so many wrong assumptions lead to such good performances!\nNevertheless, what is important to us is that sklearn implements GaussianNB, so we easily train such a classifier.\nThe most interesting part is that GaussianNB can be tuned with just a single parameter: var_smoothing.\nDon't ask me what it does in theory: in practice you change it and your accuracy can boost. This leads to an easy tuning process that doesn't involves expensive grid search.\nimport sklearn.datasets as d\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import normalize\nfrom sklearn.naive_bayes import GaussianNB\n\ndef pick_best(X_train, X_test, y_train, y_test):\n    best = (None, 0)\n    for var_smoothing in range(-7, 1):\n        clf = GaussianNB(var_smoothing=pow(10, var_smoothing))\n        clf.fit(X_train, y_train)\n        y_pred = clf.predict(X_test)\n        accuracy = (y_pred == y_test).sum()\n        if accuracy &gt; best[1]:\n            best = (clf, accuracy)\n    print(&#039;best accuracy&#039;, best[1] / len(y_test))\n    return best[0]\n\niris = d.load_iris()\nX = normalize(iris.data)\ny = iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\nclf = pick_best(X_train, X_test, y_train, y_test)\nThis simple procedure will train a bunch of classifiers with a different var_smoothing factor and pick the best performing one.\nEloquentML integration\nOnce you have your trained classifier, porting it to C is as easy as always:\nfrom micromlgen import port\n\nclf = pick_best()\nprint(port(clf))\nAlways remember to run \npip install --upgrade micromlgen\n\nport is a magic method able to port many classifiers: it will automatically detect the proper converter for you.\nWhat does the exported code looks like?\n#pragma once\nnamespace Eloquent {\n    namespace ML {\n        namespace Port {\n            class GaussianNB {\n                public:\n                    /**\n                    * Predict class for features vector\n                    */\n                    int predict(float *x) {\n                        float votes[3] = { 0.0f };\n                        float theta[4] = { 0 };\n                        float sigma[4] = { 0 };\n                        theta[0] = 0.801139789889; theta[1] = 0.54726920354; theta[2] = 0.234408773313; theta[3] = 0.039178084094;\n                        sigma[0] = 0.000366881742; sigma[1] = 0.000907992556; sigma[2] = 0.000740960787; sigma[3] = 0.000274925514;\n                        votes[0] = 0.333333333333 - gauss(x, theta, sigma);\n                        theta[0] = 0.748563871324; theta[1] = 0.349390892644; theta[2] = 0.536186138345; theta[3] = 0.166747384117;\n                        sigma[0] = 0.000529727082; sigma[1] = 0.000847956504; sigma[2] = 0.000690057342; sigma[3] = 0.000311828658;\n                        votes[1] = 0.333333333333 - gauss(x, theta, sigma);\n                        theta[0] = 0.704497203305; theta[1] = 0.318862439835; theta[2] = 0.593755956917; theta[3] = 0.217288784452;\n                        sigma[0] = 0.000363782089; sigma[1] = 0.000813846722; sigma[2] = 0.000415475678; sigma[3] = 0.000758478249;\n                        votes[2] = 0.333333333333 - gauss(x, theta, sigma);\n                        // return argmax of votes\n                        uint8_t classIdx = 0;\n                        float maxVotes = votes[0];\n\n                        for (uint8_t i = 1; i &lt; 3; i++) {\n                            if (votes[i] &gt; maxVotes) {\n                                classIdx = i;\n                                maxVotes = votes[i];\n                            }\n                        }\n\n                        return classIdx;\n                    }\n\n                protected:\n                    /**\n                    * Compute gaussian value\n                    */\n                    float gauss(float *x, float *theta, float *sigma) {\n                        float gauss = 0.0f;\n\n                        for (uint16_t i = 0; i &lt; 4; i++) {\n                            gauss += log(sigma[i]);\n                            gauss += pow(x[i] - theta[i], 2) / sigma[i];\n                        }\n\n                        return gauss;\n                    }\n                };\n            }\n        }\n    }\n\r\n\r\n\r\n    \r\n\tFinding this content useful?\r\n\r\n\t\r\n\r\n\t\r\n\t\t\r\n\t\t\r\n\t    \r\n    \r\n    \r\n    \r\n\r\n\r\n\r\n\nAs you can see, we need a couple of &quot;weight vectors&quot;:\n\ntheta is the mean of each feature\nsigma is the standard deviation\n\nThe computation is quite thin: just a couple of operations; the class with the highest score is then selected.\nBenchmarks\nFollowing there's a recap of a couple benchmarks I run on an Arduino Nano 33 Ble Sense.\n\n\n\nClassifier\nDataset\nFlash\nRAM\nExecution time\nAccuracy\n\n\n\n\nGaussianNB\nIris (150x4)\n82 kb\n42 Kb\n65 ms\n97%\n\n\nLinearSVC\nIris (150x4)\n83 Kb\n42 Kb\n76 ms\n99%\n\n\nGaussianNB\nBreast cancer (80x40)\n90 Kb\n42 Kb\n160 ms\n77%\n\n\nLinearSVC\nBreast cancer (80x40)\n112 Kb\n42 Kb\n378 ms\n73%\n\n\nGaussianNB\nWine (100x13)\n85 Kb\n42 Kb\n130 ms\n97%\n\n\nLinearSVC\nWine (100x13)\n89 Kb\n42 Kb\n125 ms\n99%\n\n\n\nWe can see that the accuracy is on par with a linear SVM, reaching up to 97% on some datasets. Its semplicity shines with high-dimensional datasets (breast cancer) where execution time is half of the LinearSVC: I can see this pattern repeating with other real-world, medium-sized datasets.\n\nThis is it, you can find the example project on Github.\nL'articolo EloquentML grows its family of classifiers: Gaussian Naive Bayes on Arduino proviene da Eloquent Arduino Blog.",
            "date_published": "2020-08-02T10:44:36+02:00",
            "date_modified": "2020-08-02T11:36:42+02:00",
            "authors": [
                {
                    "name": "simone",
                    "url": "https://eloquentarduino.github.io/author/simone/",
                    "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "ml",
                "Arduino Machine learning"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/?p=1214",
            "url": "https://eloquentarduino.github.io/2020/07/sefr-a-fast-linear-time-classifier-for-ultra-low-power-devices/",
            "title": "SEFR: A Fast Linear-Time Classifier for Ultra-Low Power Devices",
            "content_html": "<p>A brand new binary classifier that's tiny and accurate, perfect for embedded scenarios: easily achieve 90+ % accuracy with a minimal memory footprint!</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/07/Binary-classification.png\" alt=\"Binary classification - from https://towardsdatascience.com\" /></p>\n<p><span id=\"more-1214\"></span></p>\n<p>A few weeks ago I was wandering over <a href=\"https://arxiv.org/search/cs?query=microcontroller&amp;searchtype=all&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50\">arxiv.org</a> looking for insipiration relative to Machine learning on microcontrollers when I found exactly what I was looking for.</p>\n<p><a href=\"https://arxiv.org/abs/2006.04620\">SEFR: A Fast Linear-Time Classifier for Ultra-Low Power Devices</a> is a paper from Hamidreza Keshavarz, Mohammad Saniee Abadeh, Reza Rawassizadeh where the authors develop a binary classifier that is:</p>\n<ul>\n<li>fast during training</li>\n<li>fast during prediction</li>\n<li>requires minimal memory</li>\n</ul>\n<p>It has been specifically designed for embedded machine learning, so no optimization is required to run in on microcontrollers: it is tiny by design. In short, it uses a combination of the averages of the features as weights plus a bias to distinguish between positive and negative class. If you read the paper you will sure understand it: it's very straightforward.</p>\n<h2>How to use</h2>\n<p>The authors both provided a <a href=\"https://github.com/sefr-classifier/sefr\">C and Python implementation</a> on Github you can read.  I ported the C version &quot;manually&quot; to my <a href=\"https://github.com/eloquentarduino/EloquentMicroML\">Eloquent ML library</a> and created a <a href=\"https://github.com/eloquentarduino/sefr\">Python package called sefr</a> copy-pasting from the original repo.</p>\n<p>Here's a Python example.</p>\n<pre><code class=\"language-python\">from sefr import SEFR\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import normalize\nfrom sklearn.model_selection import train_test_split\n\nif __name__ == &#039;__main__&#039;:\n    iris = load_iris()\n    X = normalize(iris.data)\n    y = iris.target\n    X = X[y &lt; 2]\n    y = y[y &lt; 2]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n    clf = SEFR()\n    clf.fit(X_train, y_train)\n    print(&#039;accuracy&#039;, (clf.predict(X_test) == y_test).sum() / len(y_test))</code></pre>\n<p>How good is it?</p>\n<table>\n<thead>\n<tr>\n<th>Dataset</th>\n<th style=\"text-align: center;\">No. of features</th>\n<th style=\"text-align: center;\">Accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Iris</td>\n<td style=\"text-align: center;\">4</td>\n<td style=\"text-align: center;\">100%</td>\n</tr>\n<tr>\n<td>Breast cancer</td>\n<td style=\"text-align: center;\">30</td>\n<td style=\"text-align: center;\">89%</td>\n</tr>\n<tr>\n<td>Wine</td>\n<td style=\"text-align: center;\">13</td>\n<td style=\"text-align: center;\">84%</td>\n</tr>\n<tr>\n<td>Digits</td>\n<td style=\"text-align: center;\">64</td>\n<td style=\"text-align: center;\">99%</td>\n</tr>\n</tbody>\n</table>\n<p>Considering that the model only needs 1 weight per feature, I think this results are impressive!</p>\n<h2>Micromlgen integration</h2>\n<p>The Python porting was done so I could integrate it easily in my <a href=\"https://github.com/eloquentarduino/micromlgen\">micromlgen</a> package.</p>\n<p>How to use it?</p>\n<pre><code class=\"language-python\">from sefr import SEFR\nfrom sklearn.datasets import load_iris\nfrom micromlgen import port\n\nif __name__ == &#039;__main__&#039;:\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    X = X[y &lt; 2]\n    y = y[y &lt; 2]\n    clf = SEFR()\n    clf.fit(X_train, y_train)\n    print(port(clf))</code></pre>\n<p>The produced code is so compact I will report it here.</p>\n<!-- Begin Mailchimp Signup Form -->\r\n<div id=\"mc_embed_signup\">\r\n<form action=\"https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\r\n    <div id=\"mc_embed_signup_scroll\">\r\n\t<h2 style=\"margin: 0; text-align: center\">Finding this content useful?</h2>\r\n<div class=\"mc-field-group\">\r\n\t<input type=\"email\" value=\"\" name=\"EMAIL\" class=\"required email\" id=\"mce-EMAIL\" placeholder=\"join the monthly newsletter\">\r\n</div>\r\n\t<div id=\"mce-responses\" class=\"clear\">\r\n\t\t<div class=\"response\" id=\"mce-error-response\" style=\"display:none\"></div>\r\n\t\t<div class=\"response\" id=\"mce-success-response\" style=\"display:none\"></div>\r\n\t</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->\r\n    <div style=\"position: absolute; left: -5000px;\" aria-hidden=\"true\"><input type=\"text\" name=\"b_f0eaedd94d554cf2ee781742a_37d3496031\" tabindex=\"-1\" value=\"\"></div>\r\n    <div class=\"clear\" style=\"position: relative; top: 8px\"><input type=\"submit\" value=\"Subscribe\" name=\"subscribe\" id=\"mc-embedded-subscribe\" class=\"button\"></div>\r\n    </div>\r\n</form>\r\n</div>\r\n\r\n<!--End mc_embed_signup-->\n<pre><code class=\"language-cpp\">#pragma once\nnamespace Eloquent {\n    namespace ML {\n        namespace Port {\n            class SEFR {\n                public:\n                    /**\n                    * Predict class for features vector\n                    */\n                    int predict(float *x) {\n                        return dot(x,   0.084993602632  , -0.106163278477  , 0.488989863684  , 0.687022900763 ) &lt;= 2.075 ? 0 : 1;\n                    }\n\n                protected:\n                    /**\n                    * Compute dot product between features vector and classifier weights\n                    */\n                    float dot(float *x, ...) {\n                        va_list w;\n                        va_start(w, 4);\n                        float kernel = 0.0;\n\n                        for (uint16_t i = 0; i &lt; 4; i++) {\n                            kernel += x[i] * va_arg(w, double);\n                        }\n\n                        return kernel;\n                    }\n                };\n            }\n        }\n    }</code></pre>\n<p>In your sketch:</p>\n<pre><code class=\"language-cpp\">#include &quot;IrisSEFR.h&quot;\n#include &quot;IrisTest.h&quot;\n\nvoid setup() {\n    Serial.begin(115200);\n}\n\nvoid loop() {\n    Eloquent::ML::Port::SEFR clf;\n    Eloquent::ML::Test::IrisTestSet testSet;\n\n    testSet.test(clf);\n    Serial.println(testSet.dump());\n    delay(5000);\n}</code></pre>\n<p>You have to clone the <a href=\"https://github.com/eloquentarduino/EloquentMicroML/tree/master/examples/OffboardSEFRExample\">Github example</a> to compile the code.</p>\n<hr />\n<p>That's all for today, I hope you will try this classifier and find a project it fits in: I'm very impressed by the easiness of implementation yet the accuracy it can achieve on benchmark datasets.</p>\n<p>In the next weeks I'm thinking in implementing a multi-class version of this and see how it performs, so stay tuned!</p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2020/07/sefr-a-fast-linear-time-classifier-for-ultra-low-power-devices/\">SEFR: A Fast Linear-Time Classifier for Ultra-Low Power Devices</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "A brand new binary classifier that's tiny and accurate, perfect for embedded scenarios: easily achieve 90+ % accuracy with a minimal memory footprint!\n\n\nA few weeks ago I was wandering over arxiv.org looking for insipiration relative to Machine learning on microcontrollers when I found exactly what I was looking for.\nSEFR: A Fast Linear-Time Classifier for Ultra-Low Power Devices is a paper from Hamidreza Keshavarz, Mohammad Saniee Abadeh, Reza Rawassizadeh where the authors develop a binary classifier that is:\n\nfast during training\nfast during prediction\nrequires minimal memory\n\nIt has been specifically designed for embedded machine learning, so no optimization is required to run in on microcontrollers: it is tiny by design. In short, it uses a combination of the averages of the features as weights plus a bias to distinguish between positive and negative class. If you read the paper you will sure understand it: it's very straightforward.\nHow to use\nThe authors both provided a C and Python implementation on Github you can read.  I ported the C version &quot;manually&quot; to my Eloquent ML library and created a Python package called sefr copy-pasting from the original repo.\nHere's a Python example.\nfrom sefr import SEFR\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import normalize\nfrom sklearn.model_selection import train_test_split\n\nif __name__ == &#039;__main__&#039;:\n    iris = load_iris()\n    X = normalize(iris.data)\n    y = iris.target\n    X = X[y &lt; 2]\n    y = y[y &lt; 2]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n    clf = SEFR()\n    clf.fit(X_train, y_train)\n    print(&#039;accuracy&#039;, (clf.predict(X_test) == y_test).sum() / len(y_test))\nHow good is it?\n\n\n\nDataset\nNo. of features\nAccuracy\n\n\n\n\nIris\n4\n100%\n\n\nBreast cancer\n30\n89%\n\n\nWine\n13\n84%\n\n\nDigits\n64\n99%\n\n\n\nConsidering that the model only needs 1 weight per feature, I think this results are impressive!\nMicromlgen integration\nThe Python porting was done so I could integrate it easily in my micromlgen package.\nHow to use it?\nfrom sefr import SEFR\nfrom sklearn.datasets import load_iris\nfrom micromlgen import port\n\nif __name__ == &#039;__main__&#039;:\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    X = X[y &lt; 2]\n    y = y[y &lt; 2]\n    clf = SEFR()\n    clf.fit(X_train, y_train)\n    print(port(clf))\nThe produced code is so compact I will report it here.\n\r\n\r\n\r\n    \r\n\tFinding this content useful?\r\n\r\n\t\r\n\r\n\t\r\n\t\t\r\n\t\t\r\n\t    \r\n    \r\n    \r\n    \r\n\r\n\r\n\r\n\n#pragma once\nnamespace Eloquent {\n    namespace ML {\n        namespace Port {\n            class SEFR {\n                public:\n                    /**\n                    * Predict class for features vector\n                    */\n                    int predict(float *x) {\n                        return dot(x,   0.084993602632  , -0.106163278477  , 0.488989863684  , 0.687022900763 ) &lt;= 2.075 ? 0 : 1;\n                    }\n\n                protected:\n                    /**\n                    * Compute dot product between features vector and classifier weights\n                    */\n                    float dot(float *x, ...) {\n                        va_list w;\n                        va_start(w, 4);\n                        float kernel = 0.0;\n\n                        for (uint16_t i = 0; i &lt; 4; i++) {\n                            kernel += x[i] * va_arg(w, double);\n                        }\n\n                        return kernel;\n                    }\n                };\n            }\n        }\n    }\nIn your sketch:\n#include &quot;IrisSEFR.h&quot;\n#include &quot;IrisTest.h&quot;\n\nvoid setup() {\n    Serial.begin(115200);\n}\n\nvoid loop() {\n    Eloquent::ML::Port::SEFR clf;\n    Eloquent::ML::Test::IrisTestSet testSet;\n\n    testSet.test(clf);\n    Serial.println(testSet.dump());\n    delay(5000);\n}\nYou have to clone the Github example to compile the code.\n\nThat's all for today, I hope you will try this classifier and find a project it fits in: I'm very impressed by the easiness of implementation yet the accuracy it can achieve on benchmark datasets.\nIn the next weeks I'm thinking in implementing a multi-class version of this and see how it performs, so stay tuned!\nL'articolo SEFR: A Fast Linear-Time Classifier for Ultra-Low Power Devices proviene da Eloquent Arduino Blog.",
            "date_published": "2020-07-10T17:09:58+02:00",
            "date_modified": "2020-07-12T17:04:14+02:00",
            "authors": [
                {
                    "name": "simone",
                    "url": "https://eloquentarduino.github.io/author/simone/",
                    "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "Arduino Machine learning"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/?p=1203",
            "url": "https://eloquentarduino.github.io/2020/06/easy-esp32-camera-http-video-streaming-server/",
            "title": "Easy ESP32 camera HTTP video streaming server",
            "content_html": "<p>This will be a short post where I introduce a new addition to the Arduino Eloquent library aimed to make video streaming from an ESP32 camera over HTTP super easy. It will be the first component of a larger project I'm going to implement.</p>\n<p><span id=\"more-1203\"></span></p>\n<p>If you Google &quot;esp32 video streaming&quot; you will get a bunch of results that are essentialy copy-pasted from the official Espressif repo: many of them neither copy-pasted the code, just tell you to load the example sketch.</p>\n<p>And if you try to read it and try to modify just a bit for your own use-case, you won't understand much.</p>\n<p>This is the exact environment for an Eloquent component to live: make it painfully easy what's messy.</p>\n<p>I still have to find a good naming scheme for my libraries since Arduino IDE doesn't allow nested imports, so forgive me if &quot;ESP32CameraHTTPVideoStreamingServer.h&quot; was the best that came to mind.</p>\n<p>How easy is it to use?</p>\n<p>1 line of code if used in conjuction with my other library <a href=\"https://github.com/eloquentarduino/EloquentVision\">EloquentVision</a>.</p>\n<pre><code class=\"language-cpp\">#define CAMERA_MODEL_M5STACK_WIDE\n#include &quot;WiFi.h&quot;\n#include &quot;EloquentVision.h&quot;\n#include &quot;ESP32CameraHTTPVideoStreamingServer.h&quot;\n\nusing namespace Eloquent::Vision;\nusing namespace Eloquent::Vision::Camera;\n\nESP32Camera camera;\nHTTPVideoStreamingServer server(81);\n\n/**\n *\n */\nvoid setup() {\n    Serial.begin(115200);\n    WiFi.softAP(&quot;ESP32&quot;, &quot;12345678&quot;);\n\n    camera.begin(FRAMESIZE_QVGA, PIXFORMAT_JPEG);\n    server.start();\n\n    Serial.print(&quot;Camera Ready! Use &#039;http://&quot;);\n    Serial.print(WiFi.softAPIP());\n    Serial.println(&quot;:81&#039; to stream&quot;);\n}\n\nvoid loop() {\n}</code></pre>\n<p><code>HTTPVideoStreamingServer</code> assumes you already initialized your camera. You can achieve this task in the way you prefer: <code>ESP32Camera</code> class makes this a breeze.</p>\n<p><code>81</code> in the server constructor is the port you want the server to be listening to.</p>\n<p>Once connected to WiFi or started in AP mode, all you have to do is call <code>start()</code>: that's it!</p>\n<!-- Begin Mailchimp Signup Form -->\r\n<div id=\"mc_embed_signup\">\r\n<form action=\"https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\r\n    <div id=\"mc_embed_signup_scroll\">\r\n\t<h2 style=\"margin: 0; text-align: center\">Finding this content useful?</h2>\r\n<div class=\"mc-field-group\">\r\n\t<input type=\"email\" value=\"\" name=\"EMAIL\" class=\"required email\" id=\"mce-EMAIL\" placeholder=\"join the monthly newsletter\">\r\n</div>\r\n\t<div id=\"mce-responses\" class=\"clear\">\r\n\t\t<div class=\"response\" id=\"mce-error-response\" style=\"display:none\"></div>\r\n\t\t<div class=\"response\" id=\"mce-success-response\" style=\"display:none\"></div>\r\n\t</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->\r\n    <div style=\"position: absolute; left: -5000px;\" aria-hidden=\"true\"><input type=\"text\" name=\"b_f0eaedd94d554cf2ee781742a_37d3496031\" tabindex=\"-1\" value=\"\"></div>\r\n    <div class=\"clear\" style=\"position: relative; top: 8px\"><input type=\"submit\" value=\"Subscribe\" name=\"subscribe\" id=\"mc-embedded-subscribe\" class=\"button\"></div>\r\n    </div>\r\n</form>\r\n</div>\r\n\r\n<!--End mc_embed_signup-->\n<p>What else is it good for?</p>\n<p>The main reason I wrote this piece of library is because one of you reader commented on the <a href=\"/2020/05/easier-faster-pure-video-esp32-cam-motion-detection/\">motion detection post</a> asking if it would be possible to start the video streaming once motion is detected.</p>\n<p>Of course it is.</p>\n<p>It's just a matter of composing the Eloquent pieces.</p>\n<pre><code class=\"language-cpp\">#define CAMERA_MODEL_M5STACK_WIDE\n#include &quot;WiFi.h&quot;\n#include &quot;EloquentVision.h&quot;\n#include &quot;ESP32CameraHTTPVideoStreamingServer.h&quot;\n\n#define SOURCE_WIDTH 320\n#define SOURCE_HEIGHT 240\n#define BLOCK_SIZE 10\n#define BLOCK_DIFF_THRESHOLD 0.2\n#define IMAGE_DIFF_THRESHOLD 0.1\n\nusing namespace Eloquent::Vision;\nusing namespace Eloquent::Vision::Camera;\nusing namespace Eloquent::Vision::ImageProcessing;\nusing namespace Eloquent::Vision::ImageProcessing::Downscale;\n\nESP32Camera camera;\nHTTPVideoStreamingServer server(81);\nMotionDetection&lt; SOURCE_WIDTH, SOURCE_HEIGHT, BLOCK_SIZE&gt; motion(nearest);\n\n/**\n *\n */\nvoid setup() {\n    Serial.begin(115200);\n    WiFi.softAP(&quot;ESP32&quot;, &quot;12345678&quot;);\n\n    camera.begin(FRAMESIZE_QVGA, PIXFORMAT_JPEG);\n\n    Serial.print(&quot;Camera Ready! Use &#039;http://&quot;);\n    Serial.print(WiFi.softAPIP());\n    Serial.println(&quot;:81&#039; to stream&quot;);\n}\n\nvoid loop() {\n    motion.update(camera.capture()-&gt;buf);\n\n    if (motion.detectRatio() &gt; IMAGE_DIFF_THRESHOLD) {\n        Serial.print(&quot;Motion detected&quot;);\n        // start the streaming server when motion is detected\n        // shutdown after 20 seconds if no one connects\n        server.start();\n        delay(20000);\n        server.stop();\n    }\n\n    // probably we don&#039;t need 30 fps, save some power\n    delay(300);\n}</code></pre>\n<p>Does it look good?</p>\n<p>Now the rationale behind Eloquent components should be starting to be clear to you: easy to use objects you can compose the way it fits to achieve the result you want.</p>\n<p>Would you suggest me more piece of functionality you would like to see wrapped in an Eloquent component?</p>\n<hr />\n<p>You can find the <a href=\"https://github.com/eloquentarduino/EloquentVision/blob/master/src/ESP32CameraHTTPVideoStreamingServer.h\">class code</a> and the <a href=\"https://github.com/eloquentarduino/EloquentVision/blob/master/examples/ESP32CameraHTTPVideoStreamingServerExample/ESP32CameraHTTPVideoStreamingServerExample.ino\">example sketch</a> on the <a href=\"https://github.com/eloquentarduino/EloquentVision\">Github repo</a>.</p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2020/06/easy-esp32-camera-http-video-streaming-server/\">Easy ESP32 camera HTTP video streaming server</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "This will be a short post where I introduce a new addition to the Arduino Eloquent library aimed to make video streaming from an ESP32 camera over HTTP super easy. It will be the first component of a larger project I'm going to implement.\n\nIf you Google &quot;esp32 video streaming&quot; you will get a bunch of results that are essentialy copy-pasted from the official Espressif repo: many of them neither copy-pasted the code, just tell you to load the example sketch.\nAnd if you try to read it and try to modify just a bit for your own use-case, you won't understand much.\nThis is the exact environment for an Eloquent component to live: make it painfully easy what's messy.\nI still have to find a good naming scheme for my libraries since Arduino IDE doesn't allow nested imports, so forgive me if &quot;ESP32CameraHTTPVideoStreamingServer.h&quot; was the best that came to mind.\nHow easy is it to use?\n1 line of code if used in conjuction with my other library EloquentVision.\n#define CAMERA_MODEL_M5STACK_WIDE\n#include &quot;WiFi.h&quot;\n#include &quot;EloquentVision.h&quot;\n#include &quot;ESP32CameraHTTPVideoStreamingServer.h&quot;\n\nusing namespace Eloquent::Vision;\nusing namespace Eloquent::Vision::Camera;\n\nESP32Camera camera;\nHTTPVideoStreamingServer server(81);\n\n/**\n *\n */\nvoid setup() {\n    Serial.begin(115200);\n    WiFi.softAP(&quot;ESP32&quot;, &quot;12345678&quot;);\n\n    camera.begin(FRAMESIZE_QVGA, PIXFORMAT_JPEG);\n    server.start();\n\n    Serial.print(&quot;Camera Ready! Use &#039;http://&quot;);\n    Serial.print(WiFi.softAPIP());\n    Serial.println(&quot;:81&#039; to stream&quot;);\n}\n\nvoid loop() {\n}\nHTTPVideoStreamingServer assumes you already initialized your camera. You can achieve this task in the way you prefer: ESP32Camera class makes this a breeze.\n81 in the server constructor is the port you want the server to be listening to.\nOnce connected to WiFi or started in AP mode, all you have to do is call start(): that's it!\n\r\n\r\n\r\n    \r\n\tFinding this content useful?\r\n\r\n\t\r\n\r\n\t\r\n\t\t\r\n\t\t\r\n\t    \r\n    \r\n    \r\n    \r\n\r\n\r\n\r\n\nWhat else is it good for?\nThe main reason I wrote this piece of library is because one of you reader commented on the motion detection post asking if it would be possible to start the video streaming once motion is detected.\nOf course it is.\nIt's just a matter of composing the Eloquent pieces.\n#define CAMERA_MODEL_M5STACK_WIDE\n#include &quot;WiFi.h&quot;\n#include &quot;EloquentVision.h&quot;\n#include &quot;ESP32CameraHTTPVideoStreamingServer.h&quot;\n\n#define SOURCE_WIDTH 320\n#define SOURCE_HEIGHT 240\n#define BLOCK_SIZE 10\n#define BLOCK_DIFF_THRESHOLD 0.2\n#define IMAGE_DIFF_THRESHOLD 0.1\n\nusing namespace Eloquent::Vision;\nusing namespace Eloquent::Vision::Camera;\nusing namespace Eloquent::Vision::ImageProcessing;\nusing namespace Eloquent::Vision::ImageProcessing::Downscale;\n\nESP32Camera camera;\nHTTPVideoStreamingServer server(81);\nMotionDetection&lt; SOURCE_WIDTH, SOURCE_HEIGHT, BLOCK_SIZE&gt; motion(nearest);\n\n/**\n *\n */\nvoid setup() {\n    Serial.begin(115200);\n    WiFi.softAP(&quot;ESP32&quot;, &quot;12345678&quot;);\n\n    camera.begin(FRAMESIZE_QVGA, PIXFORMAT_JPEG);\n\n    Serial.print(&quot;Camera Ready! Use &#039;http://&quot;);\n    Serial.print(WiFi.softAPIP());\n    Serial.println(&quot;:81&#039; to stream&quot;);\n}\n\nvoid loop() {\n    motion.update(camera.capture()-&gt;buf);\n\n    if (motion.detectRatio() &gt; IMAGE_DIFF_THRESHOLD) {\n        Serial.print(&quot;Motion detected&quot;);\n        // start the streaming server when motion is detected\n        // shutdown after 20 seconds if no one connects\n        server.start();\n        delay(20000);\n        server.stop();\n    }\n\n    // probably we don&#039;t need 30 fps, save some power\n    delay(300);\n}\nDoes it look good?\nNow the rationale behind Eloquent components should be starting to be clear to you: easy to use objects you can compose the way it fits to achieve the result you want.\nWould you suggest me more piece of functionality you would like to see wrapped in an Eloquent component?\n\nYou can find the class code and the example sketch on the Github repo.\nL'articolo Easy ESP32 camera HTTP video streaming server proviene da Eloquent Arduino Blog.",
            "date_published": "2020-06-24T19:27:33+02:00",
            "date_modified": "2020-06-24T20:26:23+02:00",
            "authors": [
                {
                    "name": "simone",
                    "url": "https://eloquentarduino.github.io/author/simone/",
                    "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "camera",
                "esp32",
                "Eloquent library"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/?p=1174",
            "url": "https://eloquentarduino.github.io/2020/06/arduino-dimensionality-reduction-pca-for-machine-learning-projects/",
            "title": "Arduino dimensionality reduction (PCA) for Machine Learning projects",
            "content_html": "<p>When working with <strong>Machine Learning projects</strong> on microcontrollers and embedded devices the dimension of features can become a limiting factor due to the lack of RAM: <strong>dimensionality reduction</strong> (eg. PCA) will help you shrink your models and even achieve higher prediction accuracy.</p>\n<p><a href=\"https://setosa.io/ev/principal-component-analysis\"><img src=\"https://setosa.io/ev/principal-component-analysis/fb-thumb.png\" alt=\"PCA application example\" /></a></p>\n<p><span id=\"more-1174\"></span></p>\n<h2>Why dimensionality reduction on Arduino microcontrollers?</h2>\n<p><a href=\"https://en.wikipedia.org/wiki/Dimensionality_reduction\">Dimensionality reduction</a> is a tecnique you see often in Machine Learning projects. By stripping away &quot;unimportant&quot; or redundant information, it generally helps speeding up the training process and achieving higher classification performances.</p>\n<p>Since we now know we can run Machine Learning on Arduino boards and embedded microcontrollers, it can become a key tool at our disposal to squeeze out the most out of our boards.</p>\n<p>In the specific case of resource-constrained devices as old Arduino boards (the UNO for example, with only 2 kb of RAM), it can become a decisive turn in unlocking even more application scenarios where the high dimensionality of the input features would not allow any model to fit.</p>\n<p>Let's take the <a href=\"/2019/12/how-to-do-gesture-identification-on-arduino/\">Gesture classification project</a> as an example: among the different classifiers we trained, only one fitted on the Arduino UNO, since most of them required too much flash memory due to the high dimension of features (90) and support vectors (25 to 61).</p>\n<p>In this post I will resume that example and see if dimensionality reduction can help reduce this gap.</p>\n<p>If you are working on a project with many features, let me know in the comments so I can create a detailed list of real world examples.</p>\n<h2>How to export PCA (Principal Component Analysis) to plain C</h2>\n<p>Among the many algorithms available for dimensionality reduction, I decided to start with <a href=\"https://en.wikipedia.org/wiki/Principal_component_analysis\">PCA (Principal Component Analysis)</a> because it's one of the most widespread. In the next weeks I will probably work on porting other alternatives.</p>\n<p>If you never used my Python package <a href=\"https://github.com/eloquentarduino/micromlgen\">micromlgen</a> I first invite you to read <a href=\"/2019/11/you-can-run-machine-learning-on-arduino/\">the introduction post</a> to get familiar with it.</p>\n<p>Always remember to install the latest version, since I publish frequent updates.</p>\n<pre><code class=\"language-bash\">pip install --upgrade micromlgen</code></pre>\n<p>Now it is pretty straight-forward to convert a sklearn PCA transformer to plain C: you use the magic method <code>port</code>. In addition to converting SVM/RVM classifiers, it is now able to export PCA too.</p>\n<pre><code class=\"language-python\">from sklearn.decomposition import PCA\nfrom sklearn.datasets import load_iris\nfrom micromlgen import port\n\nif __name__ == &#039;__main__&#039;:\n    X = load_iris().data\n    pca = PCA(n_components=2, whiten=False).fit(X)\n\n    print(port(pca))</code></pre>\n<h2>How to deploy PCA to Arduino</h2>\n<p>To use the exported code, we first have to include it in our sketch. Save the contents to a file (I named it <code>pca.h</code>) in the same folder of your <code>.ino</code> project and include it.</p>\n<pre><code class=\"language-cpp\">#include &quot;pca.h&quot;\n\n// this was trained on the IRIS dataset, with 2 principal components\nEloquent::ML::Port::PCA pca;</code></pre>\n<p>The <code>pca</code> object is now able to take an array of size N as input and return an array of size K as output, with K &lt; N usually.</p>\n<pre><code class=\"language-cpp\">void setup() {\n    float x_input[4] = {5.1, 3.5, 1.4, 0.2};\n    float x_output[2];\n\n    pca.transform(x_input, x_output);\n}</code></pre>\n<p>That's it: now you can run your classifier on <code>x_output</code>.</p>\n<pre><code class=\"language-cpp\">#include &quot;pca.h&quot;\n#include &quot;svm.h&quot;\n\nEloquent::ML::Port::PCA pca;\nEloquent::ML::Port::SVM clf;\n\nvoid setup() {\n    float x_input[4] = {5.1, 3.5, 1.4, 0.2};\n    float x_output[2];\n    int y_pred;\n\n    pca.transform(x_input, x_output);\n\n    y_pred = clf.predict(x_output);\n}</code></pre>\n<!-- Begin Mailchimp Signup Form -->\r\n<div id=\"mc_embed_signup\">\r\n<form action=\"https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\r\n    <div id=\"mc_embed_signup_scroll\">\r\n\t<h2 style=\"margin: 0; text-align: center\">Finding this content useful?</h2>\r\n<div class=\"mc-field-group\">\r\n\t<input type=\"email\" value=\"\" name=\"EMAIL\" class=\"required email\" id=\"mce-EMAIL\" placeholder=\"join the monthly newsletter\">\r\n</div>\r\n\t<div id=\"mce-responses\" class=\"clear\">\r\n\t\t<div class=\"response\" id=\"mce-error-response\" style=\"display:none\"></div>\r\n\t\t<div class=\"response\" id=\"mce-success-response\" style=\"display:none\"></div>\r\n\t</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->\r\n    <div style=\"position: absolute; left: -5000px;\" aria-hidden=\"true\"><input type=\"text\" name=\"b_f0eaedd94d554cf2ee781742a_37d3496031\" tabindex=\"-1\" value=\"\"></div>\r\n    <div class=\"clear\" style=\"position: relative; top: 8px\"><input type=\"submit\" value=\"Subscribe\" name=\"subscribe\" id=\"mc-embedded-subscribe\" class=\"button\"></div>\r\n    </div>\r\n</form>\r\n</div>\r\n\r\n<!--End mc_embed_signup-->\n<h2>A real world example</h2>\n<p>As I anticipated, let's take a look at how PCA dimensionality reduction can help in fitting classifiers that would otherwise be too large to fit on our microcontrollers.</p>\n<p>This is the exact table from the <a href=\"/2019/12/how-to-do-gesture-identification-on-arduino/\">Gesture classification project</a>.</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">Kernel</th>\n<th style=\"text-align: center;\">C</th>\n<th style=\"text-align: center;\">Gamma</th>\n<th style=\"text-align: center;\">Degree</th>\n<th style=\"text-align: center;\">Vectors</th>\n<th style=\"text-align: center;\">Flash size</th>\n<th style=\"text-align: center;\">RAM (b)</th>\n<th style=\"text-align: center;\">Avg accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\">RBF</td>\n<td style=\"text-align: center;\">10</td>\n<td style=\"text-align: center;\">0.001</td>\n<td style=\"text-align: center;\">-</td>\n<td style=\"text-align: center;\">37</td>\n<td style=\"text-align: center;\">53 Kb</td>\n<td style=\"text-align: center;\">1228</td>\n<td style=\"text-align: center;\">99%</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>Poly</strong></td>\n<td style=\"text-align: center;\"><strong>100</strong></td>\n<td style=\"text-align: center;\"><strong>0.001</strong></td>\n<td style=\"text-align: center;\"><strong>2</strong></td>\n<td style=\"text-align: center;\"><strong>12</strong></td>\n<td style=\"text-align: center;\"><strong>25 Kb</strong></td>\n<td style=\"text-align: center;\"><strong>1228</strong></td>\n<td style=\"text-align: center;\"><strong>99%</strong></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">Poly</td>\n<td style=\"text-align: center;\">100</td>\n<td style=\"text-align: center;\">0.001</td>\n<td style=\"text-align: center;\">3</td>\n<td style=\"text-align: center;\">25</td>\n<td style=\"text-align: center;\">40 Kb</td>\n<td style=\"text-align: center;\">1228</td>\n<td style=\"text-align: center;\">97%</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">Linear</td>\n<td style=\"text-align: center;\">50</td>\n<td style=\"text-align: center;\">-</td>\n<td style=\"text-align: center;\">1</td>\n<td style=\"text-align: center;\">40</td>\n<td style=\"text-align: center;\">55 Kb</td>\n<td style=\"text-align: center;\">1228</td>\n<td style=\"text-align: center;\">95%</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">RBF</td>\n<td style=\"text-align: center;\">100</td>\n<td style=\"text-align: center;\">0.01</td>\n<td style=\"text-align: center;\">-</td>\n<td style=\"text-align: center;\">61</td>\n<td style=\"text-align: center;\">80 Kb</td>\n<td style=\"text-align: center;\">1228</td>\n<td style=\"text-align: center;\">95%</td>\n</tr>\n</tbody>\n</table>\n<p>The dataset has 90 features (30 samples x 3 axes) and achieves 99% accuracy. </p>\n<p>Let's pick the <code>poly</code> kernel with degree <code>2</code> and see how much we can decrease the number of components while still achieving a good accuracy.</p>\n<table>\n<thead>\n<tr>\n<th>PCA components</th>\n<th style=\"text-align: center;\">Accuracy</th>\n<th style=\"text-align: center;\">Support vectors</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>90</td>\n<td style=\"text-align: center;\">99%</td>\n<td style=\"text-align: center;\">31</td>\n</tr>\n<tr>\n<td>50</td>\n<td style=\"text-align: center;\">99%</td>\n<td style=\"text-align: center;\">31</td>\n</tr>\n<tr>\n<td>40</td>\n<td style=\"text-align: center;\">99%</td>\n<td style=\"text-align: center;\">31</td>\n</tr>\n<tr>\n<td>30</td>\n<td style=\"text-align: center;\">90%</td>\n<td style=\"text-align: center;\">30</td>\n</tr>\n<tr>\n<td>20</td>\n<td style=\"text-align: center;\">90%</td>\n<td style=\"text-align: center;\">28</td>\n</tr>\n<tr>\n<td>15</td>\n<td style=\"text-align: center;\">90%</td>\n<td style=\"text-align: center;\">24</td>\n</tr>\n<tr>\n<td><strong>10</strong></td>\n<td style=\"text-align: center;\"><strong>99%</strong></td>\n<td style=\"text-align: center;\"><strong>18</strong></td>\n</tr>\n<tr>\n<td>5</td>\n<td style=\"text-align: center;\">76%</td>\n<td style=\"text-align: center;\">28</td>\n</tr>\n</tbody>\n</table>\n<p>We clearly see a couple of things:</p>\n<ol>\n<li>we still achieve 99% accuracy even with only 40 out of 90 principal components</li>\n<li>we get a satisfactory 90% accuracy even <strong>with only 15 components</strong></li>\n<li>(this is a bit unexpected) it looks like there's a sweet spot at 10 components where the accuracy skyrockets to 99% again. <em>This could be just a contingency of this particular dataset, don't expect to replicate this results on your own dataset</em></li>\n</ol>\n<p>What do these numbers mean to you? It means your board has to do many less computations to give you a prediction and will probably be able to host a more complex model.</p>\n<p>Let's check out the figures with <code>n_components = 10</code> compared with the ones without PCA.</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">Kernel</th>\n<th style=\"text-align: center;\">PCA support vectors</th>\n<th style=\"text-align: center;\">PCA flash size</th>\n<th style=\"text-align: center;\">Accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\">RBF C=10</td>\n<td style=\"text-align: center;\">46 (+24%)</td>\n<td style=\"text-align: center;\">32 Kb (-40%)</td>\n<td style=\"text-align: center;\">99%</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">RBF C=100</td>\n<td style=\"text-align: center;\">28 (-54%)</td>\n<td style=\"text-align: center;\">32 Kb (-60%)</td>\n<td style=\"text-align: center;\">99%</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>Poly 2</strong></td>\n<td style=\"text-align: center;\">13 (-48%)</td>\n<td style=\"text-align: center;\">28 Kb (+12%)</td>\n<td style=\"text-align: center;\">99%</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>Poly 3</strong></td>\n<td style=\"text-align: center;\">24 (-4%)</td>\n<td style=\"text-align: center;\">32 Kb (-20%)</td>\n<td style=\"text-align: center;\">99%</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>Linear</strong></td>\n<td style=\"text-align: center;\">18 (-64%)</td>\n<td style=\"text-align: center;\">29 Kb (-47%)</td>\n<td style=\"text-align: center;\">99%</td>\n</tr>\n</tbody>\n</table>\n<p>A couple notes:</p>\n<ol>\n<li>accuracy increased (on stayed the same) for all kernels</li>\n<li>with one exception, flash size decreased in the range 20 - 50%</li>\n<li>now we can fit 3 classifiers on our Arduino UNO instead of only one</li>\n</ol>\n<p>I will probably spend some more time investingating the usefulness of PCA for Arduino Machine Learning projects, but for now that's it: it's a good starting point in my opinion.</p>\n<hr />\n<p>There's a little example sketch on <a href=\"https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/PCAExample/PCAExample.ino\">Github</a> that applies PCA to the IRIS dataset.</p>\n<p>Tell me what you think may be a clever application of dimensionality reduction in the world of microcontrollers and see if we can build something great together.</p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2020/06/arduino-dimensionality-reduction-pca-for-machine-learning-projects/\">Arduino dimensionality reduction (PCA) for Machine Learning projects</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "When working with Machine Learning projects on microcontrollers and embedded devices the dimension of features can become a limiting factor due to the lack of RAM: dimensionality reduction (eg. PCA) will help you shrink your models and even achieve higher prediction accuracy.\n\n\nWhy dimensionality reduction on Arduino microcontrollers?\nDimensionality reduction is a tecnique you see often in Machine Learning projects. By stripping away &quot;unimportant&quot; or redundant information, it generally helps speeding up the training process and achieving higher classification performances.\nSince we now know we can run Machine Learning on Arduino boards and embedded microcontrollers, it can become a key tool at our disposal to squeeze out the most out of our boards.\nIn the specific case of resource-constrained devices as old Arduino boards (the UNO for example, with only 2 kb of RAM), it can become a decisive turn in unlocking even more application scenarios where the high dimensionality of the input features would not allow any model to fit.\nLet's take the Gesture classification project as an example: among the different classifiers we trained, only one fitted on the Arduino UNO, since most of them required too much flash memory due to the high dimension of features (90) and support vectors (25 to 61).\nIn this post I will resume that example and see if dimensionality reduction can help reduce this gap.\nIf you are working on a project with many features, let me know in the comments so I can create a detailed list of real world examples.\nHow to export PCA (Principal Component Analysis) to plain C\nAmong the many algorithms available for dimensionality reduction, I decided to start with PCA (Principal Component Analysis) because it's one of the most widespread. In the next weeks I will probably work on porting other alternatives.\nIf you never used my Python package micromlgen I first invite you to read the introduction post to get familiar with it.\nAlways remember to install the latest version, since I publish frequent updates.\npip install --upgrade micromlgen\nNow it is pretty straight-forward to convert a sklearn PCA transformer to plain C: you use the magic method port. In addition to converting SVM/RVM classifiers, it is now able to export PCA too.\nfrom sklearn.decomposition import PCA\nfrom sklearn.datasets import load_iris\nfrom micromlgen import port\n\nif __name__ == &#039;__main__&#039;:\n    X = load_iris().data\n    pca = PCA(n_components=2, whiten=False).fit(X)\n\n    print(port(pca))\nHow to deploy PCA to Arduino\nTo use the exported code, we first have to include it in our sketch. Save the contents to a file (I named it pca.h) in the same folder of your .ino project and include it.\n#include &quot;pca.h&quot;\n\n// this was trained on the IRIS dataset, with 2 principal components\nEloquent::ML::Port::PCA pca;\nThe pca object is now able to take an array of size N as input and return an array of size K as output, with K &lt; N usually.\nvoid setup() {\n    float x_input[4] = {5.1, 3.5, 1.4, 0.2};\n    float x_output[2];\n\n    pca.transform(x_input, x_output);\n}\nThat's it: now you can run your classifier on x_output.\n#include &quot;pca.h&quot;\n#include &quot;svm.h&quot;\n\nEloquent::ML::Port::PCA pca;\nEloquent::ML::Port::SVM clf;\n\nvoid setup() {\n    float x_input[4] = {5.1, 3.5, 1.4, 0.2};\n    float x_output[2];\n    int y_pred;\n\n    pca.transform(x_input, x_output);\n\n    y_pred = clf.predict(x_output);\n}\n\r\n\r\n\r\n    \r\n\tFinding this content useful?\r\n\r\n\t\r\n\r\n\t\r\n\t\t\r\n\t\t\r\n\t    \r\n    \r\n    \r\n    \r\n\r\n\r\n\r\n\nA real world example\nAs I anticipated, let's take a look at how PCA dimensionality reduction can help in fitting classifiers that would otherwise be too large to fit on our microcontrollers.\nThis is the exact table from the Gesture classification project.\n\n\n\nKernel\nC\nGamma\nDegree\nVectors\nFlash size\nRAM (b)\nAvg accuracy\n\n\n\n\nRBF\n10\n0.001\n-\n37\n53 Kb\n1228\n99%\n\n\nPoly\n100\n0.001\n2\n12\n25 Kb\n1228\n99%\n\n\nPoly\n100\n0.001\n3\n25\n40 Kb\n1228\n97%\n\n\nLinear\n50\n-\n1\n40\n55 Kb\n1228\n95%\n\n\nRBF\n100\n0.01\n-\n61\n80 Kb\n1228\n95%\n\n\n\nThe dataset has 90 features (30 samples x 3 axes) and achieves 99% accuracy. \nLet's pick the poly kernel with degree 2 and see how much we can decrease the number of components while still achieving a good accuracy.\n\n\n\nPCA components\nAccuracy\nSupport vectors\n\n\n\n\n90\n99%\n31\n\n\n50\n99%\n31\n\n\n40\n99%\n31\n\n\n30\n90%\n30\n\n\n20\n90%\n28\n\n\n15\n90%\n24\n\n\n10\n99%\n18\n\n\n5\n76%\n28\n\n\n\nWe clearly see a couple of things:\n\nwe still achieve 99% accuracy even with only 40 out of 90 principal components\nwe get a satisfactory 90% accuracy even with only 15 components\n(this is a bit unexpected) it looks like there's a sweet spot at 10 components where the accuracy skyrockets to 99% again. This could be just a contingency of this particular dataset, don't expect to replicate this results on your own dataset\n\nWhat do these numbers mean to you? It means your board has to do many less computations to give you a prediction and will probably be able to host a more complex model.\nLet's check out the figures with n_components = 10 compared with the ones without PCA.\n\n\n\nKernel\nPCA support vectors\nPCA flash size\nAccuracy\n\n\n\n\nRBF C=10\n46 (+24%)\n32 Kb (-40%)\n99%\n\n\nRBF C=100\n28 (-54%)\n32 Kb (-60%)\n99%\n\n\nPoly 2\n13 (-48%)\n28 Kb (+12%)\n99%\n\n\nPoly 3\n24 (-4%)\n32 Kb (-20%)\n99%\n\n\nLinear\n18 (-64%)\n29 Kb (-47%)\n99%\n\n\n\nA couple notes:\n\naccuracy increased (on stayed the same) for all kernels\nwith one exception, flash size decreased in the range 20 - 50%\nnow we can fit 3 classifiers on our Arduino UNO instead of only one\n\nI will probably spend some more time investingating the usefulness of PCA for Arduino Machine Learning projects, but for now that's it: it's a good starting point in my opinion.\n\nThere's a little example sketch on Github that applies PCA to the IRIS dataset.\nTell me what you think may be a clever application of dimensionality reduction in the world of microcontrollers and see if we can build something great together.\nL'articolo Arduino dimensionality reduction (PCA) for Machine Learning projects proviene da Eloquent Arduino Blog.",
            "date_published": "2020-06-07T09:24:20+02:00",
            "date_modified": "2020-06-07T11:26:25+02:00",
            "authors": [
                {
                    "name": "simone",
                    "url": "https://eloquentarduino.github.io/author/simone/",
                    "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "pca",
                "Arduino Machine learning"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/?p=1156",
            "url": "https://eloquentarduino.github.io/2020/05/anomaly-detection-on-your-arduino-microcontroller-via-one-class-svm/",
            "title": "Anomaly detection on your Arduino microcontroller via One Class SVM",
            "content_html": "<p><a href=\"/tag/svm/\">Support Vector Machines</a> are very often used for classification tasks: but you may not know that they're so flexible they can be used for <a href=\"https://scikit-learn.org/stable/modules/outlier_detection.html\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>anomaly detection and novelty detection</strong></a>. Thanks to the <a href=\"https://github.com/eloquentarduino/micromlgen\">micromlgen</a> package, you can run One Class SVM on your Arduino microcontorller.</p>\n<p><img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_oneclass_001.png\" alt=\"Novelty detection from sklearn documentation\" title=\"Novelty detection from sklearn documentation\" /><br />\n<span id=\"more-1156\"></span></p>\n<h2>What is anomaly / novelty detection useful for?</h2>\n<h3>Detect noise or anomalies</h3>\n<p>As the name implies, anomaly detection can be used to monitor a stream of data and alert you when something unexpected happens.<br />\nThink of an Industrial IoT setup where you have a bunch of sensors monitoring the working state of a production plant: you want to know as soon as possible if something bad is gonna happen.</p>\n<p>In this case, anomaly detection tells you if your machinery is acting in a different way from the normal state so you can take action.</p>\n<h3>Ignore irrelevant data</h3>\n<p><em>(This application was suggested from two of my readers)</em><br />\nSay you're developing a super simple word classification project: you want to distinguish door bell from fire alarm (as per one of the two readers).<br />\nSo you train your SVM classifier and use <a href=\"https://github.com/eloquentarduino/micromlgen\">micromlgen</a> to run it on your Arduino microcontroller.</p>\n<p>It works well, but we have a problem: you live in a noisy environment with many sounds, so not all of them will either be door bells or fire alarms. Since your classifier is binary, it <em>has to classify all of the sounds</em> as either A or B.</p>\n<p>The solution will be <strong>novelty detection</strong>: before running the binary SVM, you run the <strong>OneClassSVM</strong> to filter known sounds (bell and alarm) from unknown ones (eg. dog barking).<br />\nIf OneClassSVM predicts the sound as a novelty, you discard it since it's of no interest for you. If it predicts the sound as known, you run the binary SVM.</p>\n<!-- Begin Mailchimp Signup Form -->\r\n<div id=\"mc_embed_signup\">\r\n<form action=\"https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\r\n    <div id=\"mc_embed_signup_scroll\">\r\n\t<h2 style=\"margin: 0; text-align: center\">Finding this content useful?</h2>\r\n<div class=\"mc-field-group\">\r\n\t<input type=\"email\" value=\"\" name=\"EMAIL\" class=\"required email\" id=\"mce-EMAIL\" placeholder=\"join the monthly newsletter\">\r\n</div>\r\n\t<div id=\"mce-responses\" class=\"clear\">\r\n\t\t<div class=\"response\" id=\"mce-error-response\" style=\"display:none\"></div>\r\n\t\t<div class=\"response\" id=\"mce-success-response\" style=\"display:none\"></div>\r\n\t</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->\r\n    <div style=\"position: absolute; left: -5000px;\" aria-hidden=\"true\"><input type=\"text\" name=\"b_f0eaedd94d554cf2ee781742a_37d3496031\" tabindex=\"-1\" value=\"\"></div>\r\n    <div class=\"clear\" style=\"position: relative; top: 8px\"><input type=\"submit\" value=\"Subscribe\" name=\"subscribe\" id=\"mc-embedded-subscribe\" class=\"button\"></div>\r\n    </div>\r\n</form>\r\n</div>\r\n\r\n<!--End mc_embed_signup-->\n<h2>How to run anomaly / novelty detection on Arduino microcontroller via OneClassSVM</h2>\n<p>Porting a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html\">OneClassSVM</a> from Python to plain C++ is as easy as a single command in the <strong>micromlgen</strong> package:</p>\n<pre><code class=\"language-python\">from sklearn.svm import OneClassSVM\nfrom micromlgen import port\n\nclf = OneClassSVM(kernel=&quot;rbf&quot;, nu=0.5, gamma=0.1)\nclf.fit(X, y)\nprint(port(clf))</code></pre>\n<div class=\"watchout\">\nYou will need micromlgen version 1.0.2 to port OneClassSVM. If you have an outdated version, please run <code>pip install --upgrade micromlgen</code>\n</div>\n<p>If you read <a href=\"/tag/svm/\">my previous posts</a> about <strong>micromlgen</strong> and SVM the above snippet should be familiar: with the latest release, <code>port</code> is able to export either SVC, LinearSVC, OneClassSVC and <a href=\"/2020/02/even-smaller-machine-learning-models-for-your-mcu/\">RVC (Relevant Vector Machines)</a> to object oriented C++.</p>\n<p>Now you can embed the generated code in your Arduino sketch.</p>\n<pre><code class=\"language-cpp\">#include &quot;OneClassSVM.h&quot;\n\nEloquent::ML::Port::OneClassSVM clf;\n\nvoid setup() {\n  Serial.begin(115200);\n  delay(2000);\n\n  for (int i = 0; i &lt; DATASET_SIZE; i++)\n    clf.predict(X[i]);\n}\n\nvoid loop() {}</code></pre>\n<hr />\n<p>I created an example sketch from a synthetic dataset for anomaly detection (copied from a <a href=\"https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html#sphx-glr-auto-examples-svm-plot-oneclass-py\">scikit-learn example</a>) you can run to get a feel of how it performs.</p>\n<p>Go checkout the <a href=\"https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/OneClassSVMExample/OneClassSVMExample.ino\">Github repo</a></p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2020/05/anomaly-detection-on-your-arduino-microcontroller-via-one-class-svm/\">Anomaly detection on your Arduino microcontroller via One Class SVM</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "Support Vector Machines are very often used for classification tasks: but you may not know that they're so flexible they can be used for anomaly detection and novelty detection. Thanks to the micromlgen package, you can run One Class SVM on your Arduino microcontorller.\n\n\nWhat is anomaly / novelty detection useful for?\nDetect noise or anomalies\nAs the name implies, anomaly detection can be used to monitor a stream of data and alert you when something unexpected happens.\nThink of an Industrial IoT setup where you have a bunch of sensors monitoring the working state of a production plant: you want to know as soon as possible if something bad is gonna happen.\nIn this case, anomaly detection tells you if your machinery is acting in a different way from the normal state so you can take action.\nIgnore irrelevant data\n(This application was suggested from two of my readers)\nSay you're developing a super simple word classification project: you want to distinguish door bell from fire alarm (as per one of the two readers).\nSo you train your SVM classifier and use micromlgen to run it on your Arduino microcontroller.\nIt works well, but we have a problem: you live in a noisy environment with many sounds, so not all of them will either be door bells or fire alarms. Since your classifier is binary, it has to classify all of the sounds as either A or B.\nThe solution will be novelty detection: before running the binary SVM, you run the OneClassSVM to filter known sounds (bell and alarm) from unknown ones (eg. dog barking).\nIf OneClassSVM predicts the sound as a novelty, you discard it since it's of no interest for you. If it predicts the sound as known, you run the binary SVM.\n\r\n\r\n\r\n    \r\n\tFinding this content useful?\r\n\r\n\t\r\n\r\n\t\r\n\t\t\r\n\t\t\r\n\t    \r\n    \r\n    \r\n    \r\n\r\n\r\n\r\n\nHow to run anomaly / novelty detection on Arduino microcontroller via OneClassSVM\nPorting a OneClassSVM from Python to plain C++ is as easy as a single command in the micromlgen package:\nfrom sklearn.svm import OneClassSVM\nfrom micromlgen import port\n\nclf = OneClassSVM(kernel=&quot;rbf&quot;, nu=0.5, gamma=0.1)\nclf.fit(X, y)\nprint(port(clf))\n\nYou will need micromlgen version 1.0.2 to port OneClassSVM. If you have an outdated version, please run pip install --upgrade micromlgen\n\nIf you read my previous posts about micromlgen and SVM the above snippet should be familiar: with the latest release, port is able to export either SVC, LinearSVC, OneClassSVC and RVC (Relevant Vector Machines) to object oriented C++.\nNow you can embed the generated code in your Arduino sketch.\n#include &quot;OneClassSVM.h&quot;\n\nEloquent::ML::Port::OneClassSVM clf;\n\nvoid setup() {\n  Serial.begin(115200);\n  delay(2000);\n\n  for (int i = 0; i &lt; DATASET_SIZE; i++)\n    clf.predict(X[i]);\n}\n\nvoid loop() {}\n\nI created an example sketch from a synthetic dataset for anomaly detection (copied from a scikit-learn example) you can run to get a feel of how it performs.\nGo checkout the Github repo\nL'articolo Anomaly detection on your Arduino microcontroller via One Class SVM proviene da Eloquent Arduino Blog.",
            "date_published": "2020-05-31T18:44:36+02:00",
            "date_modified": "2020-05-31T19:44:50+02:00",
            "authors": [
                {
                    "name": "simone",
                    "url": "https://eloquentarduino.github.io/author/simone/",
                    "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "Arduino Machine learning"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/?p=1110",
            "url": "https://eloquentarduino.github.io/2020/05/easier-faster-pure-video-esp32-cam-motion-detection/",
            "title": "Easier, faster pure video ESP32 cam motion detection",
            "content_html": "<p>If you liked my post about <a href=\"/2020/01/motion-detection-with-esp32-cam-only-arduino-version/\">ESP32 cam motion detection</a>, you'll love this updated version: it's easier to use and blazing fast!</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/05/Faster-motion-detection.gif\" alt=\"Faster motion detection\" /></p>\n<p><span id=\"more-1110\"></span></p>\n<p>The post about <strong>pure video ESP32 cam motion detection</strong> without an external PIR is my most successful post at the moment. Many of you are interested about this topic.</p>\n<p>One of my readers, though, pointed out my implementation was quite slow and he only achieved bare 5 fps in his project. So he asked for a better alternative.</p>\n<p>Since the post was of great interest for many people, I took the time to revisit the code and make improvements.</p>\n<p>I came up with a 100% re-writing that is both easier to use and faster. Actually, it is <strong>blazing fast!</strong>.</p>\n<p>Let's see how it works.</p>\n<p><div class=\"toc\"><h6>Table of contents</h6><ol><li><a href=\"#tocdownsampling\">Downsampling</a><ol><li><a href=\"#tocnearest-neighbor\">Nearest neighbor</a><li><a href=\"#tocfull-block-average\">Full block average</a><li><a href=\"#toccore-block-average\">Core block average</a><li><a href=\"#toccross-block-average\">Cross block average</a><li><a href=\"#tocdiagonal-block-average\">Diagonal block average</a><li><a href=\"#tocimplement-your-own\">Implement your own</a></li></ol><li><a href=\"#tocbenchmarks\">Benchmarks</a><li><a href=\"#tocmotion-detection\">Motion detection</a><li><a href=\"#tocfull-code\">Full code</a></ol></div></p>\n<h2 id=\"tocdownsampling\">Downsampling</h2>\n<p>In the original post I introduced the idea of downsampling the image from the camera for a faster and more robust motion detection. I wrote the code in the main sketch to keep it self-contained.</p>\n<p>Looking back now it was a poor choice, since it cluttered the project and distracted from the main purpose, which is motion detection.</p>\n<p>Moreover, I thought that scanning the image buffer in sequential order would be the fastest approach.</p>\n<p>It turns out I was wrong.</p>\n<p>This time I scan the image buffer following the blocks that will compose the resulting image and the results are... much faster.</p>\n<p>Also, I decided to inject some more efficiency that will further speedup the computation: using different strategies for downsampling.</p>\n<p>The idea of downsampling is that you have to &quot;collapse&quot; a block of NxN from the original image to just one pixel of the resulting image.</p>\n<p>Now, there are a variety of ways you can accomplish this. The first two I present here are the most obvious, the other two are of my &quot;invention&quot;: nothing fancy nor new, but they're fast and serve the purpose well.</p>\n<h3 id=\"tocnearest-neighbor\">Nearest neighbor</h3>\n<p>You can just pick the center of the NxN block and use its value for the output.<br />\nOf course it is fast (possibly the fastest approach), but wouldn't be very accurate. One pixel out of NxN wouldn't be representative of the overall region and will heavily suffer from noise.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/05/Nearest-diagram.png\" alt=\"Nearest diagram\" /></p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/05/nn.jpg\" alt=\"Nearest neighbor block averaging\" /></p>\n<h3 id=\"tocfull-block-average\">Full block average</h3>\n<p>This is the most intuitive alternative: use the average of all the pixels in the block as the ouput value. This is arguabily the &quot;proper&quot; way to do it, since you're using all the pixels in the source image to compute the new one.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/05/Full-diagram.png\" alt=\"Full diagram\" /><br />\n<img src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/05/full.jpg\" alt=\"Full block averaging\" /></p>\n<h3 id=\"toccore-block-average\">Core block average</h3>\n<p>As a faster alternative, I thought that averaging only the &quot;core&quot; (the most internal part) of the block would have been a good-enough solution. It has no theoretical proof that this yields true, but our task here is to create a smaller <em>representation</em> of the original image, not producing an accurate smaller version.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/05/Core-diagram.png\" alt=\"Core diagram\" /><br />\n<img src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/05/core.jpg\" alt=\"Core block averaging\" /></p>\n<p><em>I'll stress this point: the only reason we do downsampling is to compare two sequential frame and detect if they differ above a certain threshold. This downsampling doesn't have to mimic the actual image: it can transform the source in any fancy way, as long as it stays consistent and captures the variations over time.</em></p>\n<h3 id=\"toccross-block-average\">Cross block average</h3>\n<p>This time we consider all the pixels along the vertical and horizontal central axes. The idea is that you will capture a good portion of the variation along both the axis, given quite accurate results.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/05/Cross-diagram.png\" alt=\"Cross diagram\" /><br />\n<img src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/05/cross.jpg\" alt=\"Cross block averaging\" /></p>\n<h3 id=\"tocdiagonal-block-average\">Diagonal block average</h3>\n<p>This alternative too came to my mind from nowhere, really. I just think it is a good alternative to capture all the block's variation, probably even better than vertical and horizontal directions.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/05/Diagonal-diagram.png\" alt=\"Diagonal diagram\" /><br />\n<img src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/05/diagonal.jpg\" alt=\"Diagonal block averaging\" /></p>\n<h3 id=\"tocimplement-your-own\">Implement your own</h3>\n<p>Not satisfied from the methods above? No problem, you can still implement your own.</p>\n<p>The ones presented above are just some algorithms that came to my mind: I'm not telling you they're the best.</p>\n<p>They worked for me, that's it.</p>\n<p>If you think you found a better solution, I encourage you implement it and even share it with me and the other readers, so we can all make progress on this together.</p>\n<!-- Begin Mailchimp Signup Form -->\r\n<div id=\"mc_embed_signup\">\r\n<form action=\"https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\r\n    <div id=\"mc_embed_signup_scroll\">\r\n\t<h2 style=\"margin: 0; text-align: center\">Finding this content useful?</h2>\r\n<div class=\"mc-field-group\">\r\n\t<input type=\"email\" value=\"\" name=\"EMAIL\" class=\"required email\" id=\"mce-EMAIL\" placeholder=\"join the monthly newsletter\">\r\n</div>\r\n\t<div id=\"mce-responses\" class=\"clear\">\r\n\t\t<div class=\"response\" id=\"mce-error-response\" style=\"display:none\"></div>\r\n\t\t<div class=\"response\" id=\"mce-success-response\" style=\"display:none\"></div>\r\n\t</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->\r\n    <div style=\"position: absolute; left: -5000px;\" aria-hidden=\"true\"><input type=\"text\" name=\"b_f0eaedd94d554cf2ee781742a_37d3496031\" tabindex=\"-1\" value=\"\"></div>\r\n    <div class=\"clear\" style=\"position: relative; top: 8px\"><input type=\"submit\" value=\"Subscribe\" name=\"subscribe\" id=\"mc-embedded-subscribe\" class=\"button\"></div>\r\n    </div>\r\n</form>\r\n</div>\r\n\r\n<!--End mc_embed_signup-->\n<h2 id=\"tocbenchmarks\">Benchmarks</h2>\n<p>So, at the very beginning I said this new implementation is blazingly fast. </p>\n<p>How much fast?</p>\n<p>As fast as it can be, arguably.</p>\n<p>I mean, so fast it won't alter your fps.</p>\n<p>Look at the results I got on my M5Stack camera.</p>\n<table>\n<thead>\n<tr>\n<th>Algorithm</th>\n<th style=\"text-align: center;\">Time to execute (micros)</th>\n<th style=\"text-align: right;\">FPS</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>None</td>\n<td style=\"text-align: center;\">0</td>\n<td style=\"text-align: right;\">25</td>\n</tr>\n<tr>\n<td>Nearest neighbor</td>\n<td style=\"text-align: center;\">160</td>\n<td style=\"text-align: right;\">25</td>\n</tr>\n<tr>\n<td>Cross block</td>\n<td style=\"text-align: center;\">700</td>\n<td style=\"text-align: right;\">25</td>\n</tr>\n<tr>\n<td>Core block</td>\n<td style=\"text-align: center;\">800</td>\n<td style=\"text-align: right;\">25</td>\n</tr>\n<tr>\n<td>Diagonal block</td>\n<td style=\"text-align: center;\">950</td>\n<td style=\"text-align: right;\">25</td>\n</tr>\n<tr>\n<td>Full block</td>\n<td style=\"text-align: center;\">4900</td>\n<td style=\"text-align: right;\">12</td>\n</tr>\n</tbody>\n</table>\n<p>As you can see, only the full block creates a delay in the process (quite a bit of delay even): the other  methods  won't slow down your program in any noticeable way.</p>\n<p>If you test Nearest neighbor and it works for you, then you'll be extremely light on computation resources with only <strong>160 microseconds</strong> of delay.</p>\n<p>This is what I mean by <em>blazing fast</em>.</p>\n<h2 id=\"tocmotion-detection\">Motion detection</h2>\n<p>The motion detection part hasn't changed, so I point you to <a href=\"/2020/01/motion-detection-with-esp32-cam-only-arduino-version#tocblocks-difference-threshold\">the original post</a> to read more about the Block difference threshold and the Image difference threshold.</p>\n<h2 id=\"tocfull-code\">Full code</h2>\n<pre><code class=\"language-cpp\">#define CAMERA_MODEL_M5STACK_WIDE\n#include &quot;EloquentVision.h&quot;\n\n#define FRAME_SIZE FRAMESIZE_QVGA\n#define SOURCE_WIDTH 320\n#define SOURCE_HEIGHT 240\n#define BLOCK_SIZE 10\n#define DEST_WIDTH (SOURCE_WIDTH / BLOCK_SIZE)\n#define DEST_HEIGHT (SOURCE_HEIGHT / BLOCK_SIZE)\n#define BLOCK_DIFF_THRESHOLD 0.2\n#define IMAGE_DIFF_THRESHOLD 0.1\n#define DEBUG 0\n\nusing namespace Eloquent::Vision;\n\nESP32Camera camera;\nuint8_t prevFrame[DEST_WIDTH * DEST_HEIGHT] = { 0 };\nuint8_t currentFrame[DEST_WIDTH * DEST_HEIGHT] = { 0 };\n\n// function prototypes\nbool motionDetect();\nvoid updateFrame();\n\n/**\n *\n */\nvoid setup() {\n    Serial.begin(115200);\n    camera.begin(FRAME_SIZE, PIXFORMAT_GRAYSCALE);\n}\n\n/**\n *\n */\nvoid loop() {\n    /**\n     * Algorithm:\n     *  1. grab frame\n     *  2. compare with previous to detect motion\n     *  3. update previous frame\n     */\n\n    time_t start = millis();\n    camera_fb_t *frame = camera.capture();\n\n    downscaleImage(frame-&gt;buf, currentFrame, nearest, SOURCE_WIDTH, SOURCE_HEIGHT, BLOCK_SIZE);\n\n    if (motionDetect()) {\n        Serial.print(&quot;Motion detected @ &quot;);\n        Serial.print(floor(1000.0f / (millis() - start)));\n        Serial.println(&quot; FPS&quot;);\n    }\n\n    updateFrame();\n}\n\n/**\n * Compute the number of different blocks\n * If there are enough, then motion happened\n */\nbool motionDetect() {\n    uint16_t changes = 0;\n    const uint16_t blocks = DEST_WIDTH * DEST_HEIGHT;\n\n    for (int y = 0; y &lt; DEST_HEIGHT; y++) {\n        for (int x = 0; x &lt; DEST_WIDTH; x++) {\n            float current = currentFrame[y * DEST_WIDTH + x];\n            float prev = prevFrame[y * DEST_WIDTH + x];\n            float delta = abs(current - prev) / prev;\n\n            if (delta &gt;= BLOCK_DIFF_THRESHOLD)\n                changes += 1;\n        }\n    }\n\n    return (1.0 * changes / blocks) &gt; IMAGE_DIFF_THRESHOLD;\n}\n\n/**\n * Copy current frame to previous\n */\nvoid updateFrame() {\n    memcpy(prevFrame, currentFrame, DEST_WIDTH * DEST_HEIGHT);\n}</code></pre>\n<hr />\n<p>Check the full project code on <a href=\"https://github.com/eloquentarduino/EloquentVision/blob/master/examples/FasterMotionDetection/FasterMotionDetection.ino\">Github</a> and remember to star!</p>\n<!-- Begin Mailchimp Signup Form -->\r\n<div id=\"mc_embed_signup\">\r\n<form action=\"https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\r\n    <div id=\"mc_embed_signup_scroll\">\r\n\t<h2 style=\"margin: 0; text-align: center\">Finding this content useful?</h2>\r\n<div class=\"mc-field-group\">\r\n\t<input type=\"email\" value=\"\" name=\"EMAIL\" class=\"required email\" id=\"mce-EMAIL\" placeholder=\"join the monthly newsletter\">\r\n</div>\r\n\t<div id=\"mce-responses\" class=\"clear\">\r\n\t\t<div class=\"response\" id=\"mce-error-response\" style=\"display:none\"></div>\r\n\t\t<div class=\"response\" id=\"mce-success-response\" style=\"display:none\"></div>\r\n\t</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->\r\n    <div style=\"position: absolute; left: -5000px;\" aria-hidden=\"true\"><input type=\"text\" name=\"b_f0eaedd94d554cf2ee781742a_37d3496031\" tabindex=\"-1\" value=\"\"></div>\r\n    <div class=\"clear\" style=\"position: relative; top: 8px\"><input type=\"submit\" value=\"Subscribe\" name=\"subscribe\" id=\"mc-embedded-subscribe\" class=\"button\"></div>\r\n    </div>\r\n</form>\r\n</div>\r\n\r\n<!--End mc_embed_signup-->\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2020/05/easier-faster-pure-video-esp32-cam-motion-detection/\">Easier, faster pure video ESP32 cam motion detection</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "If you liked my post about ESP32 cam motion detection, you'll love this updated version: it's easier to use and blazing fast!\n\n\nThe post about pure video ESP32 cam motion detection without an external PIR is my most successful post at the moment. Many of you are interested about this topic.\nOne of my readers, though, pointed out my implementation was quite slow and he only achieved bare 5 fps in his project. So he asked for a better alternative.\nSince the post was of great interest for many people, I took the time to revisit the code and make improvements.\nI came up with a 100% re-writing that is both easier to use and faster. Actually, it is blazing fast!.\nLet's see how it works.\nTable of contentsDownsamplingNearest neighborFull block averageCore block averageCross block averageDiagonal block averageImplement your ownBenchmarksMotion detectionFull code\nDownsampling\nIn the original post I introduced the idea of downsampling the image from the camera for a faster and more robust motion detection. I wrote the code in the main sketch to keep it self-contained.\nLooking back now it was a poor choice, since it cluttered the project and distracted from the main purpose, which is motion detection.\nMoreover, I thought that scanning the image buffer in sequential order would be the fastest approach.\nIt turns out I was wrong.\nThis time I scan the image buffer following the blocks that will compose the resulting image and the results are... much faster.\nAlso, I decided to inject some more efficiency that will further speedup the computation: using different strategies for downsampling.\nThe idea of downsampling is that you have to &quot;collapse&quot; a block of NxN from the original image to just one pixel of the resulting image.\nNow, there are a variety of ways you can accomplish this. The first two I present here are the most obvious, the other two are of my &quot;invention&quot;: nothing fancy nor new, but they're fast and serve the purpose well.\nNearest neighbor\nYou can just pick the center of the NxN block and use its value for the output.\nOf course it is fast (possibly the fastest approach), but wouldn't be very accurate. One pixel out of NxN wouldn't be representative of the overall region and will heavily suffer from noise.\n\n\nFull block average\nThis is the most intuitive alternative: use the average of all the pixels in the block as the ouput value. This is arguabily the &quot;proper&quot; way to do it, since you're using all the pixels in the source image to compute the new one.\n\n\nCore block average\nAs a faster alternative, I thought that averaging only the &quot;core&quot; (the most internal part) of the block would have been a good-enough solution. It has no theoretical proof that this yields true, but our task here is to create a smaller representation of the original image, not producing an accurate smaller version.\n\n\nI'll stress this point: the only reason we do downsampling is to compare two sequential frame and detect if they differ above a certain threshold. This downsampling doesn't have to mimic the actual image: it can transform the source in any fancy way, as long as it stays consistent and captures the variations over time.\nCross block average\nThis time we consider all the pixels along the vertical and horizontal central axes. The idea is that you will capture a good portion of the variation along both the axis, given quite accurate results.\n\n\nDiagonal block average\nThis alternative too came to my mind from nowhere, really. I just think it is a good alternative to capture all the block's variation, probably even better than vertical and horizontal directions.\n\n\nImplement your own\nNot satisfied from the methods above? No problem, you can still implement your own.\nThe ones presented above are just some algorithms that came to my mind: I'm not telling you they're the best.\nThey worked for me, that's it.\nIf you think you found a better solution, I encourage you implement it and even share it with me and the other readers, so we can all make progress on this together.\n\r\n\r\n\r\n    \r\n\tFinding this content useful?\r\n\r\n\t\r\n\r\n\t\r\n\t\t\r\n\t\t\r\n\t    \r\n    \r\n    \r\n    \r\n\r\n\r\n\r\n\nBenchmarks\nSo, at the very beginning I said this new implementation is blazingly fast. \nHow much fast?\nAs fast as it can be, arguably.\nI mean, so fast it won't alter your fps.\nLook at the results I got on my M5Stack camera.\n\n\n\nAlgorithm\nTime to execute (micros)\nFPS\n\n\n\n\nNone\n0\n25\n\n\nNearest neighbor\n160\n25\n\n\nCross block\n700\n25\n\n\nCore block\n800\n25\n\n\nDiagonal block\n950\n25\n\n\nFull block\n4900\n12\n\n\n\nAs you can see, only the full block creates a delay in the process (quite a bit of delay even): the other  methods  won't slow down your program in any noticeable way.\nIf you test Nearest neighbor and it works for you, then you'll be extremely light on computation resources with only 160 microseconds of delay.\nThis is what I mean by blazing fast.\nMotion detection\nThe motion detection part hasn't changed, so I point you to the original post to read more about the Block difference threshold and the Image difference threshold.\nFull code\n#define CAMERA_MODEL_M5STACK_WIDE\n#include &quot;EloquentVision.h&quot;\n\n#define FRAME_SIZE FRAMESIZE_QVGA\n#define SOURCE_WIDTH 320\n#define SOURCE_HEIGHT 240\n#define BLOCK_SIZE 10\n#define DEST_WIDTH (SOURCE_WIDTH / BLOCK_SIZE)\n#define DEST_HEIGHT (SOURCE_HEIGHT / BLOCK_SIZE)\n#define BLOCK_DIFF_THRESHOLD 0.2\n#define IMAGE_DIFF_THRESHOLD 0.1\n#define DEBUG 0\n\nusing namespace Eloquent::Vision;\n\nESP32Camera camera;\nuint8_t prevFrame[DEST_WIDTH * DEST_HEIGHT] = { 0 };\nuint8_t currentFrame[DEST_WIDTH * DEST_HEIGHT] = { 0 };\n\n// function prototypes\nbool motionDetect();\nvoid updateFrame();\n\n/**\n *\n */\nvoid setup() {\n    Serial.begin(115200);\n    camera.begin(FRAME_SIZE, PIXFORMAT_GRAYSCALE);\n}\n\n/**\n *\n */\nvoid loop() {\n    /**\n     * Algorithm:\n     *  1. grab frame\n     *  2. compare with previous to detect motion\n     *  3. update previous frame\n     */\n\n    time_t start = millis();\n    camera_fb_t *frame = camera.capture();\n\n    downscaleImage(frame-&gt;buf, currentFrame, nearest, SOURCE_WIDTH, SOURCE_HEIGHT, BLOCK_SIZE);\n\n    if (motionDetect()) {\n        Serial.print(&quot;Motion detected @ &quot;);\n        Serial.print(floor(1000.0f / (millis() - start)));\n        Serial.println(&quot; FPS&quot;);\n    }\n\n    updateFrame();\n}\n\n/**\n * Compute the number of different blocks\n * If there are enough, then motion happened\n */\nbool motionDetect() {\n    uint16_t changes = 0;\n    const uint16_t blocks = DEST_WIDTH * DEST_HEIGHT;\n\n    for (int y = 0; y &lt; DEST_HEIGHT; y++) {\n        for (int x = 0; x &lt; DEST_WIDTH; x++) {\n            float current = currentFrame[y * DEST_WIDTH + x];\n            float prev = prevFrame[y * DEST_WIDTH + x];\n            float delta = abs(current - prev) / prev;\n\n            if (delta &gt;= BLOCK_DIFF_THRESHOLD)\n                changes += 1;\n        }\n    }\n\n    return (1.0 * changes / blocks) &gt; IMAGE_DIFF_THRESHOLD;\n}\n\n/**\n * Copy current frame to previous\n */\nvoid updateFrame() {\n    memcpy(prevFrame, currentFrame, DEST_WIDTH * DEST_HEIGHT);\n}\n\nCheck the full project code on Github and remember to star!\n\r\n\r\n\r\n    \r\n\tFinding this content useful?\r\n\r\n\t\r\n\r\n\t\r\n\t\t\r\n\t\t\r\n\t    \r\n    \r\n    \r\n    \r\n\r\n\r\n\r\n\nL'articolo Easier, faster pure video ESP32 cam motion detection proviene da Eloquent Arduino Blog.",
            "date_published": "2020-05-10T21:26:08+02:00",
            "date_modified": "2020-05-13T21:19:35+02:00",
            "authors": [
                {
                    "name": "simone",
                    "url": "https://eloquentarduino.github.io/author/simone/",
                    "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "camera",
                "esp32",
                "Computer vision"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/?p=1079",
            "url": "https://eloquentarduino.github.io/2020/04/incremental-multiclass-classification-on-microcontrollers-one-vs-one/",
            "title": "Incremental multiclass classification on microcontrollers: One vs One",
            "content_html": "<p>In earlier posts I showed you can run incremental binary classification on your microcontroller with Stochastic Gradient Descent or Passive-Aggressive classifier. Now it is time to upgrade your toolbelt with a new item: One-vs-One multiclass classifier.</p>\n<p><span id=\"more-1079\"></span></p>\n<h2>One vs One</h2>\n<p>Many classifiers are, by nature, binary: they can only distinguish the positive class from the negative one. Many of real-world problems, however, are multiclass: you have 3 or more possible outcomes to distinguish from.</p>\n<p>There are a couple of ways to achieve this:</p>\n<ol>\n<li><strong>One vs All</strong>: if your classifier is able to output a confidence score of its prediction, for N classes you train N classifiers, each able to recognize a single class. During inference, you pick the &quot;most confident&quot; one.</li>\n<li><strong>One vs One</strong>: for N classes, you train N * (N-1) / 2 classifiers, one for each couple of classes. During inference, each classifier makes a prediction and you pick the class with the highest number of votes.</li>\n</ol>\n<p>Since SGD and Passive-Aggressive don't output a confidence score, I implemented the One vs One algorithm to tackle the multiclass classification problem on microcontrollers.</p>\n<p>Actually, One vs One is not a new type of classifier: it is really a &quot;coordinator&quot; class that sorts which samples go to which classifier. You can still choose your own classifier type to use.</p>\n<p>As SGD and Passive-Aggressive, OneVsOne implements the classifier interface, so you will use the well known <code>fitOne</code> and <code>predict</code> methods.</p>\n<!-- Begin Mailchimp Signup Form -->\r\n<div id=\"mc_embed_signup\">\r\n<form action=\"https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\r\n    <div id=\"mc_embed_signup_scroll\">\r\n\t<h2 style=\"margin: 0; text-align: center\">Finding this content useful?</h2>\r\n<div class=\"mc-field-group\">\r\n\t<input type=\"email\" value=\"\" name=\"EMAIL\" class=\"required email\" id=\"mce-EMAIL\" placeholder=\"join the monthly newsletter\">\r\n</div>\r\n\t<div id=\"mce-responses\" class=\"clear\">\r\n\t\t<div class=\"response\" id=\"mce-error-response\" style=\"display:none\"></div>\r\n\t\t<div class=\"response\" id=\"mce-success-response\" style=\"display:none\"></div>\r\n\t</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->\r\n    <div style=\"position: absolute; left: -5000px;\" aria-hidden=\"true\"><input type=\"text\" name=\"b_f0eaedd94d554cf2ee781742a_37d3496031\" tabindex=\"-1\" value=\"\"></div>\r\n    <div class=\"clear\" style=\"position: relative; top: 8px\"><input type=\"submit\" value=\"Subscribe\" name=\"subscribe\" id=\"mc-embedded-subscribe\" class=\"button\"></div>\r\n    </div>\r\n</form>\r\n</div>\r\n\r\n<!--End mc_embed_signup-->\n<h2>Example code</h2>\n<pre><code class=\"language-cpp\">// Esp32 has some problems with min/max\n#define min(a, b) (a) &lt; (b) ? (a) : (b)\n#define max(a, b) (a) &gt; (b) ? (a) : (b)\n// you will actually need only one of SGD or PassiveAggressive\n#include &quot;EloquentSGD.h&quot;\n#include &quot;EloquentPassiveAggressive.h&quot;\n#include &quot;EloquentOneVsOne.h&quot;\n#include &quot;EloquentAccuracyScorer.h&quot;\n// this file defines NUM_FEATURES, NUM_CLASSES, TRAIN_SAMPLES and TEST_SAMPLES\n#include &quot;dataset.h&quot;\n\nusing namespace Eloquent::ML;\n\nvoid setup() {\n  Serial.begin(115200);\n  delay(3000);\n}\n\nvoid loop() {\n  AccuracyScorer scorer;\n  // OneVsOne needs the actual classifier class, the number of features and the number of classes\n  OneVsOne&lt;SGD&lt;FEATURES_DIM&gt;, FEATURES_DIM, NUM_CLASSES&gt; clf;\n\n  // clf.set() propagates the configuration to the actual classifiers\n  // if a parameter does not exists on the classifier, it does nothing\n  // in this example, alpha and momentum refer to SGD, C to Passive-Aggressive\n  clf.set(&quot;alpha&quot;, 1);\n  clf.set(&quot;momentum&quot;, 0.7);\n  clf.set(&quot;C&quot;, 0.1);\n\n  // fit\n  // I noticed that repeating the training a few times over the same dataset increases performance  to a certain extent: if you re-train it too much, performance will decay\n  for (unsigned int i = 0; i &lt; TRAIN_SAMPLES * 5; i++) {\n      clf.fitOne(X_train[i % TRAIN_SAMPLES], y_train[i % TRAIN_SAMPLES]);\n  }\n\n  // predict\n  for (int i = 0; i &lt; TEST_SAMPLES; i++) {\n      int y_true = y_test[i];\n      int y_pred = clf.predict(X_test[i]);\n\n      Serial.print(&quot;Predicted &quot;);\n      Serial.print(y_pred);\n      Serial.print(&quot; vs &quot;);\n      Serial.println(y_true);\n      scorer.scoreOne(y_true, y_pred);\n  }\n\n  Serial.print(&quot;Accuracy = &quot;);\n  Serial.print(scorer.accuracy() * 100);\n  Serial.print(&quot; out of &quot;);\n  Serial.print(scorer.support());\n  Serial.println(&quot; samples&quot;);\n  delay(30000);\n}</code></pre>\n<p>If you refer to the previous posts on <a href=\"/2020/04/stochastic-gradient-descent-on-your-microcontroller/\">SGD</a> and <a href=\"/2020/04/passive-aggressive-classifier-for-embedded-devices/\">Passive-Aggressive</a>, you'll notice that you would be able to replace one with the other and your code will change by <strong>1 single line only</strong>. This let's you experiment to find the best configuration for your project without hassle.</p>\n<h2>Accuracy</h2>\n<p>Well, accuracy vary.</p>\n<p>In my tests, I couldn't get predictable accuracy on all datasets. I couldn't even get acceptable accuracy on the Iris dataset (60% max). But I got 90% accuracy on the Digits dataset from scikit-learn with 6 classes.</p>\n<p>You have to experiment. Try Passive-Aggressive with many <code>C</code> values. If it doesn't work, try SGD with varying <code>momentum</code> and <code>alpha</code>. Try to repeat the training over the dataset 5, 10 times.</p>\n<p>In a next post I'll report my benchmarks so you can see what works for you and what not.<br />\nThis is an emerging field for me, so I will need time to master it.</p>\n<hr />\n<p>As always, you can find the examle on <a href=\"https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/OvOExample/OvOExample.ino\">Github</a> with a the dataset to experiment with.</p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2020/04/incremental-multiclass-classification-on-microcontrollers-one-vs-one/\">Incremental multiclass classification on microcontrollers: One vs One</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "In earlier posts I showed you can run incremental binary classification on your microcontroller with Stochastic Gradient Descent or Passive-Aggressive classifier. Now it is time to upgrade your toolbelt with a new item: One-vs-One multiclass classifier.\n\nOne vs One\nMany classifiers are, by nature, binary: they can only distinguish the positive class from the negative one. Many of real-world problems, however, are multiclass: you have 3 or more possible outcomes to distinguish from.\nThere are a couple of ways to achieve this:\n\nOne vs All: if your classifier is able to output a confidence score of its prediction, for N classes you train N classifiers, each able to recognize a single class. During inference, you pick the &quot;most confident&quot; one.\nOne vs One: for N classes, you train N * (N-1) / 2 classifiers, one for each couple of classes. During inference, each classifier makes a prediction and you pick the class with the highest number of votes.\n\nSince SGD and Passive-Aggressive don't output a confidence score, I implemented the One vs One algorithm to tackle the multiclass classification problem on microcontrollers.\nActually, One vs One is not a new type of classifier: it is really a &quot;coordinator&quot; class that sorts which samples go to which classifier. You can still choose your own classifier type to use.\nAs SGD and Passive-Aggressive, OneVsOne implements the classifier interface, so you will use the well known fitOne and predict methods.\n\r\n\r\n\r\n    \r\n\tFinding this content useful?\r\n\r\n\t\r\n\r\n\t\r\n\t\t\r\n\t\t\r\n\t    \r\n    \r\n    \r\n    \r\n\r\n\r\n\r\n\nExample code\n// Esp32 has some problems with min/max\n#define min(a, b) (a) &lt; (b) ? (a) : (b)\n#define max(a, b) (a) &gt; (b) ? (a) : (b)\n// you will actually need only one of SGD or PassiveAggressive\n#include &quot;EloquentSGD.h&quot;\n#include &quot;EloquentPassiveAggressive.h&quot;\n#include &quot;EloquentOneVsOne.h&quot;\n#include &quot;EloquentAccuracyScorer.h&quot;\n// this file defines NUM_FEATURES, NUM_CLASSES, TRAIN_SAMPLES and TEST_SAMPLES\n#include &quot;dataset.h&quot;\n\nusing namespace Eloquent::ML;\n\nvoid setup() {\n  Serial.begin(115200);\n  delay(3000);\n}\n\nvoid loop() {\n  AccuracyScorer scorer;\n  // OneVsOne needs the actual classifier class, the number of features and the number of classes\n  OneVsOne&lt;SGD&lt;FEATURES_DIM&gt;, FEATURES_DIM, NUM_CLASSES&gt; clf;\n\n  // clf.set() propagates the configuration to the actual classifiers\n  // if a parameter does not exists on the classifier, it does nothing\n  // in this example, alpha and momentum refer to SGD, C to Passive-Aggressive\n  clf.set(&quot;alpha&quot;, 1);\n  clf.set(&quot;momentum&quot;, 0.7);\n  clf.set(&quot;C&quot;, 0.1);\n\n  // fit\n  // I noticed that repeating the training a few times over the same dataset increases performance  to a certain extent: if you re-train it too much, performance will decay\n  for (unsigned int i = 0; i &lt; TRAIN_SAMPLES * 5; i++) {\n      clf.fitOne(X_train[i % TRAIN_SAMPLES], y_train[i % TRAIN_SAMPLES]);\n  }\n\n  // predict\n  for (int i = 0; i &lt; TEST_SAMPLES; i++) {\n      int y_true = y_test[i];\n      int y_pred = clf.predict(X_test[i]);\n\n      Serial.print(&quot;Predicted &quot;);\n      Serial.print(y_pred);\n      Serial.print(&quot; vs &quot;);\n      Serial.println(y_true);\n      scorer.scoreOne(y_true, y_pred);\n  }\n\n  Serial.print(&quot;Accuracy = &quot;);\n  Serial.print(scorer.accuracy() * 100);\n  Serial.print(&quot; out of &quot;);\n  Serial.print(scorer.support());\n  Serial.println(&quot; samples&quot;);\n  delay(30000);\n}\nIf you refer to the previous posts on SGD and Passive-Aggressive, you'll notice that you would be able to replace one with the other and your code will change by 1 single line only. This let's you experiment to find the best configuration for your project without hassle.\nAccuracy\nWell, accuracy vary.\nIn my tests, I couldn't get predictable accuracy on all datasets. I couldn't even get acceptable accuracy on the Iris dataset (60% max). But I got 90% accuracy on the Digits dataset from scikit-learn with 6 classes.\nYou have to experiment. Try Passive-Aggressive with many C values. If it doesn't work, try SGD with varying momentum and alpha. Try to repeat the training over the dataset 5, 10 times.\nIn a next post I'll report my benchmarks so you can see what works for you and what not.\nThis is an emerging field for me, so I will need time to master it.\n\nAs always, you can find the examle on Github with a the dataset to experiment with.\nL'articolo Incremental multiclass classification on microcontrollers: One vs One proviene da Eloquent Arduino Blog.",
            "date_published": "2020-04-26T10:01:14+02:00",
            "date_modified": "2020-04-26T11:52:29+02:00",
            "authors": [
                {
                    "name": "simone",
                    "url": "https://eloquentarduino.github.io/author/simone/",
                    "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "incremental-learning",
                "microml",
                "ml",
                "Arduino Machine learning"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/?p=1062",
            "url": "https://eloquentarduino.github.io/2020/04/stochastic-gradient-descent-on-your-microcontroller/",
            "title": "Stochastic Gradient Descent on your microcontroller",
            "content_html": "<p>Stochastic gradient descent is a well know algorithm to train classifiers in an incremental fashion: that is, as training samples become available. This saves you critical memory on tiny devices while still achieving <strong>top performance</strong>! Now you can use it on your microcontroller with ease.</p>\n<p><span id=\"more-1062\"></span></p>\n<h2>A brief recap on Stochastic Gradient Descent</h2>\n<p>If you ever worked with Machine learning, you surely know about <a href=\"https://en.wikipedia.org/wiki/Gradient_descent\">Gradient descent</a>: it is an iterative algorithm to optimize a loss function. </p>\n<p>It is much general-purpose, in the sense that it is not bound to a particular application, but it has been heavily used in Neural networks in the recent years.</p>\n<p>Yet, it can be used as a classifier on its own if you set its loss function as the classification error.</p>\n<p><img src=\"https://mccormickml.com/assets/GradientDescent/GradientDescentOfMSETable.png\" alt=\"Update rule of Gradient descent\" /></p>\n<p>This is the core update rule of Gradient descent: quite simple.</p>\n<p>As you see, there's a summation in the formula: this means we need to cycle through the entire training set to compute the update to the weights.</p>\n<p>In case of large datasets, this can be slow or not possible at all.</p>\n<p>And requires a lot of memory.</p>\n<p>And we don't have memory on microcontrollers.</p>\n<p>So we need <a href=\"https://en.wikipedia.org/wiki/Stochastic_gradient_descent\">Stochastic gradient descent</a>.</p>\n<p>Stochastic gradient descent has the same exact update rule, but it is applied on the single training sample.</p>\n<p>Imagine the summation goes from 1 to 1, instead of m.</p>\n<p>That's it.</p>\n<div class=\"heateor_sss_sharing_container heateor_sss_horizontal_sharing\" ss-offset=\"0\" heateor-sss-data-href='https://eloquentarduino.github.io/2020/04/stochastic-gradient-descent-on-your-microcontroller/'><ul class=\"heateor_sss_sharing_ul\"><li class=\"heateorSssSharingRound\"><i style=\"width:35px;height:35px;border-radius:999px;\" alt=\"Facebook\" Title=\"Facebook\" class=\"heateorSssSharing heateorSssFacebookBackground\" onclick='heateorSssPopup(\"https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Feloquent.blog%2F2020%2F04%2Fstochastic-gradient-descent-on-your-microcontroller%2F\")'><ss style=\"display:block;border-radius:999px;\" class=\"heateorSssSharingSvg heateorSssFacebookSvg\"></ss></i></li><li class=\"heateorSssSharingRound\"><i style=\"width:35px;height:35px;border-radius:999px;\" alt=\"Twitter\" Title=\"Twitter\" class=\"heateorSssSharing heateorSssTwitterBackground\" onclick='heateorSssPopup(\"http://twitter.com/intent/tweet?via=ArduinoEloquent&text=Stochastic%20Gradient%20Descent%20on%20your%20microcontroller&url=http%3A%2F%2Feloquent.blog%2F2020%2F04%2Fstochastic-gradient-descent-on-your-microcontroller%2F\")'><ss style=\"display:block;border-radius:999px;\" class=\"heateorSssSharingSvg heateorSssTwitterSvg\"></ss></i></li><li class=\"heateorSssSharingRound\"><i style=\"width:35px;height:35px;border-radius:999px;\" alt=\"Linkedin\" Title=\"Linkedin\" class=\"heateorSssSharing heateorSssLinkedinBackground\" onclick='heateorSssPopup(\"http://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Feloquent.blog%2F2020%2F04%2Fstochastic-gradient-descent-on-your-microcontroller%2F&title=Stochastic%20Gradient%20Descent%20on%20your%20microcontroller\")'><ss style=\"display:block;border-radius:999px;\" class=\"heateorSssSharingSvg heateorSssLinkedinSvg\"></ss></i></li><li class=\"heateorSssSharingRound\"><i style=\"width:35px;height:35px;border-radius:999px;\" title=\"More\" alt=\"More\" class=\"heateorSssSharing heateorSssMoreBackground\" onclick=\"heateorSssMoreSharingPopup(this, 'https://eloquentarduino.github.io/2020/04/stochastic-gradient-descent-on-your-microcontroller/', 'Stochastic%20Gradient%20Descent%20on%20your%20microcontroller', '' )\" ><ss style=\"display:block\" class=\"heateorSssSharingSvg heateorSssMoreSvg\"></ss></i></li></ul><div class=\"heateorSssClear\"></div></div>\n<h2>How to use</h2>\n<p>The pattern of use is similar to that of the <a href=\"/2020/04/passive-aggressive-classifier-for-embedded-devices/\">Passive Aggressive classifier</a>: you have the <code>fitOne</code> and <code>predict</code> methods.</p>\n<p>First of all, <a href=\"https://github.com/eloquentarduino/EloquentMicroML\">download the library from Github</a>.</p>\n<pre><code class=\"language-c\">#include &lt;EloquentSGD.h&gt;\n#include &lt;EloquentAccuracyScorer.h&gt;\n#include &quot;iris.h&quot;\n\n#define VERBOSE\n\nusing namespace Eloquent::ML;\n\nvoid setup() {\n    Serial.begin(115200);\n    delay(3000);\n}\n\nvoid loop() {\n    int trainSamples;\n    int retrainingCycles;\n    SGD&lt;FEATURES_DIM&gt; clf;\n    AccuracyScorer scorer;\n\n    // ....\n\n    // train\n    for (uint16_t cycle = 0; cycle &lt; retrainingCycles; cycle++)\n        for (uint16_t i = 0; i &lt; trainSamples; i++)\n            clf.fitOne(X[i], y[i]);\n\n    // predict\n    for (uint16_t i = trainSamples; i &lt; DATASET_SIZE; i++) {\n        int predicted = clf.predict(X[i]);\n        int actual = y[i];\n\n        scorer.scoreOne(actual, predicted);\n    }\n\n    Serial.print(&quot;Accuracy: &quot;);\n    Serial.print(round(100 * scorer.accuracy()));\n    Serial.print(&quot;% out of &quot;);\n    Serial.print(scorer.support());\n    Serial.println(&quot; predictions&quot;);\n}</code></pre>\n<p>In this case we're working with known datasets, so we cycle through them for the training, but if you're learning &quot;on-line&quot;, from samples generated over time, it will work exactly the same.</p>\n<h2>A bit of momentum</h2>\n<p>Stochastic gradient descent works quite well out of the box in most cases.</p>\n<p>Sometimes, however, its updates can start &quot;oscillating&quot;.</p>\n<p><img src=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-1-4842-4470-8_33/MediaObjects/463852_1_En_33_Fig1_HTML.jpg\" alt=\"SGD with and without momentum\" /></p>\n<p>To solve this problem, it <a href=\"https://doi.org/10.1038%2F323533a0\">has been proposed</a> the <strong>momentum</strong> technique, which can both speed up learning and increase the accuracy.</p>\n<p>In my personal tests, I was able to achieve up to +5% in accuracy on the majority of datasets.</p>\n<p>To use it, you only need to set a <em>decay factor</em> between 0 and 1.</p>\n<pre><code class=\"language-c\">SGD clf;\n\nclf.momentum(0.5);</code></pre>\n<h2>Run on your own</h2>\n<p>On <a href=\"https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/SGDExample/SGDExample.ino\">Github</a> you can find the full example with some benchmark datasets to try on your own.</p>\n<!-- Begin Mailchimp Signup Form -->\r\n<div id=\"mc_embed_signup\">\r\n<form action=\"https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\r\n    <div id=\"mc_embed_signup_scroll\">\r\n\t<h2 style=\"margin: 0; text-align: center\">Finding this content useful?</h2>\r\n<div class=\"mc-field-group\">\r\n\t<input type=\"email\" value=\"\" name=\"EMAIL\" class=\"required email\" id=\"mce-EMAIL\" placeholder=\"join the monthly newsletter\">\r\n</div>\r\n\t<div id=\"mce-responses\" class=\"clear\">\r\n\t\t<div class=\"response\" id=\"mce-error-response\" style=\"display:none\"></div>\r\n\t\t<div class=\"response\" id=\"mce-success-response\" style=\"display:none\"></div>\r\n\t</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->\r\n    <div style=\"position: absolute; left: -5000px;\" aria-hidden=\"true\"><input type=\"text\" name=\"b_f0eaedd94d554cf2ee781742a_37d3496031\" tabindex=\"-1\" value=\"\"></div>\r\n    <div class=\"clear\" style=\"position: relative; top: 8px\"><input type=\"submit\" value=\"Subscribe\" name=\"subscribe\" id=\"mc-embedded-subscribe\" class=\"button\"></div>\r\n    </div>\r\n</form>\r\n</div>\r\n\r\n<!--End mc_embed_signup-->\n<p>The example is interactive an will ask you how many samples to use for the training and how many times to cycle through them.</p>\n<p>This is something you should consider: if you have a training set and can store it somehow (in memory or on Flash for example), re-presenting the same samples to the SGD classifier could (and probably will) increase its performance if done correctly.</p>\n<p>This happens because the algorithm needs some time to converge and if it doesn't receive enough samples it won't learn properly.</p>\n<p>Of course, if you re-use the same samples over and over again, you're likely to overfit.</p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2020/04/stochastic-gradient-descent-on-your-microcontroller/\">Stochastic Gradient Descent on your microcontroller</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "Stochastic gradient descent is a well know algorithm to train classifiers in an incremental fashion: that is, as training samples become available. This saves you critical memory on tiny devices while still achieving top performance! Now you can use it on your microcontroller with ease.\n\nA brief recap on Stochastic Gradient Descent\nIf you ever worked with Machine learning, you surely know about Gradient descent: it is an iterative algorithm to optimize a loss function. \nIt is much general-purpose, in the sense that it is not bound to a particular application, but it has been heavily used in Neural networks in the recent years.\nYet, it can be used as a classifier on its own if you set its loss function as the classification error.\n\nThis is the core update rule of Gradient descent: quite simple.\nAs you see, there's a summation in the formula: this means we need to cycle through the entire training set to compute the update to the weights.\nIn case of large datasets, this can be slow or not possible at all.\nAnd requires a lot of memory.\nAnd we don't have memory on microcontrollers.\nSo we need Stochastic gradient descent.\nStochastic gradient descent has the same exact update rule, but it is applied on the single training sample.\nImagine the summation goes from 1 to 1, instead of m.\nThat's it.\n\nHow to use\nThe pattern of use is similar to that of the Passive Aggressive classifier: you have the fitOne and predict methods.\nFirst of all, download the library from Github.\n#include &lt;EloquentSGD.h&gt;\n#include &lt;EloquentAccuracyScorer.h&gt;\n#include &quot;iris.h&quot;\n\n#define VERBOSE\n\nusing namespace Eloquent::ML;\n\nvoid setup() {\n    Serial.begin(115200);\n    delay(3000);\n}\n\nvoid loop() {\n    int trainSamples;\n    int retrainingCycles;\n    SGD&lt;FEATURES_DIM&gt; clf;\n    AccuracyScorer scorer;\n\n    // ....\n\n    // train\n    for (uint16_t cycle = 0; cycle &lt; retrainingCycles; cycle++)\n        for (uint16_t i = 0; i &lt; trainSamples; i++)\n            clf.fitOne(X[i], y[i]);\n\n    // predict\n    for (uint16_t i = trainSamples; i &lt; DATASET_SIZE; i++) {\n        int predicted = clf.predict(X[i]);\n        int actual = y[i];\n\n        scorer.scoreOne(actual, predicted);\n    }\n\n    Serial.print(&quot;Accuracy: &quot;);\n    Serial.print(round(100 * scorer.accuracy()));\n    Serial.print(&quot;% out of &quot;);\n    Serial.print(scorer.support());\n    Serial.println(&quot; predictions&quot;);\n}\nIn this case we're working with known datasets, so we cycle through them for the training, but if you're learning &quot;on-line&quot;, from samples generated over time, it will work exactly the same.\nA bit of momentum\nStochastic gradient descent works quite well out of the box in most cases.\nSometimes, however, its updates can start &quot;oscillating&quot;.\n\nTo solve this problem, it has been proposed the momentum technique, which can both speed up learning and increase the accuracy.\nIn my personal tests, I was able to achieve up to +5% in accuracy on the majority of datasets.\nTo use it, you only need to set a decay factor between 0 and 1.\nSGD clf;\n\nclf.momentum(0.5);\nRun on your own\nOn Github you can find the full example with some benchmark datasets to try on your own.\n\r\n\r\n\r\n    \r\n\tFinding this content useful?\r\n\r\n\t\r\n\r\n\t\r\n\t\t\r\n\t\t\r\n\t    \r\n    \r\n    \r\n    \r\n\r\n\r\n\r\n\nThe example is interactive an will ask you how many samples to use for the training and how many times to cycle through them.\nThis is something you should consider: if you have a training set and can store it somehow (in memory or on Flash for example), re-presenting the same samples to the SGD classifier could (and probably will) increase its performance if done correctly.\nThis happens because the algorithm needs some time to converge and if it doesn't receive enough samples it won't learn properly.\nOf course, if you re-use the same samples over and over again, you're likely to overfit.\nL'articolo Stochastic Gradient Descent on your microcontroller proviene da Eloquent Arduino Blog.",
            "date_published": "2020-04-10T19:43:45+02:00",
            "date_modified": "2020-04-12T19:31:52+02:00",
            "authors": [
                {
                    "name": "simone",
                    "url": "https://eloquentarduino.github.io/author/simone/",
                    "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "online-learning",
                "Arduino Machine learning"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/?p=1050",
            "url": "https://eloquentarduino.github.io/2020/04/passive-aggressive-classifier-for-embedded-devices/",
            "title": "Passive-aggressive classifier for embedded devices",
            "content_html": "<p>When working with memory constrained devices you may not able to keep all the training data in memory: passive-aggressive classifiers may help solve your memory problems.</p>\n<p><span id=\"more-1050\"></span></p>\n<h2>Batch learning</h2>\n<p>A couple weeks ago I started exploring the possibility to train a machine learning classifier directly on a microcontroller. Since I like SVM, <a href=\"/2020/03/so-you-want-to-train-an-ml-classifier-directly-on-an-arduino-board\">I ported the simplified SVM SMO (Sequential Minimal Optimization) algorithm</a> to plain C, ready to be deployed to embedded devices.</p>\n<p>Now, that kind of algorithm works in the so-called &quot;batch-mode&quot;: it needs all the training data to be available in memory to learn.</p>\n<p>This may be a limiting factor on resource-constrained devices, since it poses an upper bound to the number of samples you can train on. And when working with high-dimensional datasets, the number of samples could be not enough to achieve good accuracy.</p>\n<h2>Enter incremental learning</h2>\n<p>To solve this limitation, you need a totally different kind of learning algorithms: you need incremental (a.k.a online a.k.a out of core) learning.</p>\n<p>Incremental learning works by inspecting one training sample at a time, instead of all at once.</p>\n<p>The clear advantage is that you have a tiny memory footprint. And this is a <strong>huge</strong> advantage.</p>\n<p>The clear disadvantage is that you don't have the &quot;big picture&quot; of your data, so:</p>\n<ul>\n<li>the end result will probably be affected by the order of presentation of the samples</li>\n<li>you may not be able to achieve top accuracy</li>\n</ul>\n<h2>Passive-aggressive classifier</h2>\n<p>Passive-aggressive classification is one of the available incremental learning algorithms and it is very simple to implement, since it has a closed-form update rule.</p>\n<p>Please refer to this <a href=\"https://www.bonaccorso.eu/2017/10/06/ml-algorithms-addendum-passive-aggressive-algorithms/\">short explanation on Passive-aggressive classifiers</a> for a nice description with images.</p>\n<p>The core concept is that the classifier adjusts it weight vector for each mis-classified training sample it receives, trying to get it correct.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2020/04/passive-aggressive-classifier.png\" alt=\"Passive aggressive classifier\" /></p>\n<h2>Benchmarks</h2>\n<p>I run a couple benchmark on my Esp32 to assess both accuracy and training time.</p>\n<p>First of all: <strong>it is fast!</strong>. When I say it is fast I mean it takes ~1ms to train on 400 samples x 30 features each.</p>\n<p>Talking about accuracy instead... Uhm...</p>\n<p>Accuracy vary. <strong>Greatly</strong>. </p>\n<p>You can achieve 100% on some datasets. </p>\n<p>And 40% on others. But on those same datasets you can achieve &gt;85% if training on a different number of samples. Or in a different order.</p>\n<p>I guess this is the tradeoff for such a simple and space-efficient algorithm.</p>\n<p>I report my results in the following table. It is not meant to be an exhaustive benchmark of the classifier, since those number will vary based on the order of presentation, but still you can get an idea of what it is able to achieve.</p>\n<table>\n<thead>\n<tr>\n<th>Dataset size</th>\n<th style=\"text-align: center;\">Train samples</th>\n<th style=\"text-align: right;\">Accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>BREAST CANCER</td>\n<td style=\"text-align: center;\"></td>\n<td style=\"text-align: right;\"></td>\n</tr>\n<tr>\n<td>567 samples</td>\n<td style=\"text-align: center;\">20</td>\n<td style=\"text-align: right;\">62</td>\n</tr>\n<tr>\n<td>30 features</td>\n<td style=\"text-align: center;\">40</td>\n<td style=\"text-align: right;\">37</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">60</td>\n<td style=\"text-align: right;\">63</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">100</td>\n<td style=\"text-align: right;\">39</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">150</td>\n<td style=\"text-align: right;\">38</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">200</td>\n<td style=\"text-align: right;\">64</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">250</td>\n<td style=\"text-align: right;\">61</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">300</td>\n<td style=\"text-align: right;\">69</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">350</td>\n<td style=\"text-align: right;\">73</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">400</td>\n<td style=\"text-align: right;\">85</td>\n</tr>\n<tr>\n<td>IRIS</td>\n<td style=\"text-align: center;\"></td>\n<td style=\"text-align: right;\"></td>\n</tr>\n<tr>\n<td>100 samples</td>\n<td style=\"text-align: center;\">10</td>\n<td style=\"text-align: right;\">50</td>\n</tr>\n<tr>\n<td>4 features</td>\n<td style=\"text-align: center;\">20</td>\n<td style=\"text-align: right;\">51</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">40</td>\n<td style=\"text-align: right;\">100</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">60</td>\n<td style=\"text-align: right;\">100</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">80</td>\n<td style=\"text-align: right;\">100</td>\n</tr>\n<tr>\n<td>DIGITS</td>\n<td style=\"text-align: center;\"></td>\n<td style=\"text-align: right;\"></td>\n</tr>\n<tr>\n<td>358 samples</td>\n<td style=\"text-align: center;\">20</td>\n<td style=\"text-align: right;\">98</td>\n</tr>\n<tr>\n<td>64 features</td>\n<td style=\"text-align: center;\">40</td>\n<td style=\"text-align: right;\">98</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">60</td>\n<td style=\"text-align: right;\">99</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">100</td>\n<td style=\"text-align: right;\">100</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">150</td>\n<td style=\"text-align: right;\">100</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">200</td>\n<td style=\"text-align: right;\">99</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">250</td>\n<td style=\"text-align: right;\">98</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">300</td>\n<td style=\"text-align: right;\">95</td>\n</tr>\n<tr>\n<td>CLEVELAND HEART DISEASE</td>\n<td style=\"text-align: center;\"></td>\n<td style=\"text-align: right;\"></td>\n</tr>\n<tr>\n<td>212 samples</td>\n<td style=\"text-align: center;\">20</td>\n<td style=\"text-align: right;\">76</td>\n</tr>\n<tr>\n<td>13 features</td>\n<td style=\"text-align: center;\">40</td>\n<td style=\"text-align: right;\">24</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">60</td>\n<td style=\"text-align: right;\">77</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">100</td>\n<td style=\"text-align: right;\">19</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">120</td>\n<td style=\"text-align: right;\">82</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">140</td>\n<td style=\"text-align: right;\">78</td>\n</tr>\n<tr>\n<td></td>\n<td style=\"text-align: center;\">180</td>\n<td style=\"text-align: right;\">88</td>\n</tr>\n</tbody>\n</table>\n<h2>Time to code</h2>\n<p>Here I'll report an extract of the example code you can find on <a href=\"https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/PassiveAggressiveExample/PassiveAggressiveExample.ino\">Github</a> for this classifier.</p>\n<pre><code class=\"language-c\">#include &quot;EloquentPassiveAggressiveClassifier.h&quot;\n#include &quot;EloquentAccuracyScorer.h&quot;\n#include &quot;iris.h&quot;\n\nusing namespace Eloquent::ML;\n\nvoid loop() {\n    int trainSamples;\n    PassiveAggressiveClassifier&lt;FEATURES_DIM&gt; clf;\n    AccuracyScorer scorer;\n\n    trainSamples = readSerialNumber(&quot;How many samples will you use as training?&quot;, DATASET_SIZE - 2);\n\n    if (trainSamples == 0)\n        return;\n\n    clf.setC(1);\n\n    // train\n    for (uint16_t i = 0; i &lt; trainSamples; i++)\n        clf.fitOne(X[i], y[i]);\n\n    // predict\n    for (uint16_t i = trainSamples; i &lt; DATASET_SIZE; i++) {\n        int predicted = clf.predict(X[i]);\n        int actual = y[i] &gt; 0 ? 1 : -1;\n\n        scorer.scoreOne(actual, predicted);\n    }\n\n    Serial.print(&quot;Accuracy: &quot;);\n    Serial.print(round(100 * scorer.accuracy()));\n    Serial.print(&quot;% out of &quot;);\n    Serial.print(scorer.support());\n    Serial.println(&quot; predictions&quot;);\n}</code></pre>\n<hr />\n<p>On the <a href=\"https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/PassiveAggressiveExample/PassiveAggressiveExample.ino\">project page</a> you will find the code to reproduce these numbers.</p>\n<hr />\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2020/04/passive-aggressive-classifier-for-embedded-devices/\">Passive-aggressive classifier for embedded devices</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "When working with memory constrained devices you may not able to keep all the training data in memory: passive-aggressive classifiers may help solve your memory problems.\n\nBatch learning\nA couple weeks ago I started exploring the possibility to train a machine learning classifier directly on a microcontroller. Since I like SVM, I ported the simplified SVM SMO (Sequential Minimal Optimization) algorithm to plain C, ready to be deployed to embedded devices.\nNow, that kind of algorithm works in the so-called &quot;batch-mode&quot;: it needs all the training data to be available in memory to learn.\nThis may be a limiting factor on resource-constrained devices, since it poses an upper bound to the number of samples you can train on. And when working with high-dimensional datasets, the number of samples could be not enough to achieve good accuracy.\nEnter incremental learning\nTo solve this limitation, you need a totally different kind of learning algorithms: you need incremental (a.k.a online a.k.a out of core) learning.\nIncremental learning works by inspecting one training sample at a time, instead of all at once.\nThe clear advantage is that you have a tiny memory footprint. And this is a huge advantage.\nThe clear disadvantage is that you don't have the &quot;big picture&quot; of your data, so:\n\nthe end result will probably be affected by the order of presentation of the samples\nyou may not be able to achieve top accuracy\n\nPassive-aggressive classifier\nPassive-aggressive classification is one of the available incremental learning algorithms and it is very simple to implement, since it has a closed-form update rule.\nPlease refer to this short explanation on Passive-aggressive classifiers for a nice description with images.\nThe core concept is that the classifier adjusts it weight vector for each mis-classified training sample it receives, trying to get it correct.\n\nBenchmarks\nI run a couple benchmark on my Esp32 to assess both accuracy and training time.\nFirst of all: it is fast!. When I say it is fast I mean it takes ~1ms to train on 400 samples x 30 features each.\nTalking about accuracy instead... Uhm...\nAccuracy vary. Greatly. \nYou can achieve 100% on some datasets. \nAnd 40% on others. But on those same datasets you can achieve &gt;85% if training on a different number of samples. Or in a different order.\nI guess this is the tradeoff for such a simple and space-efficient algorithm.\nI report my results in the following table. It is not meant to be an exhaustive benchmark of the classifier, since those number will vary based on the order of presentation, but still you can get an idea of what it is able to achieve.\n\n\n\nDataset size\nTrain samples\nAccuracy\n\n\n\n\nBREAST CANCER\n\n\n\n\n567 samples\n20\n62\n\n\n30 features\n40\n37\n\n\n\n60\n63\n\n\n\n100\n39\n\n\n\n150\n38\n\n\n\n200\n64\n\n\n\n250\n61\n\n\n\n300\n69\n\n\n\n350\n73\n\n\n\n400\n85\n\n\nIRIS\n\n\n\n\n100 samples\n10\n50\n\n\n4 features\n20\n51\n\n\n\n40\n100\n\n\n\n60\n100\n\n\n\n80\n100\n\n\nDIGITS\n\n\n\n\n358 samples\n20\n98\n\n\n64 features\n40\n98\n\n\n\n60\n99\n\n\n\n100\n100\n\n\n\n150\n100\n\n\n\n200\n99\n\n\n\n250\n98\n\n\n\n300\n95\n\n\nCLEVELAND HEART DISEASE\n\n\n\n\n212 samples\n20\n76\n\n\n13 features\n40\n24\n\n\n\n60\n77\n\n\n\n100\n19\n\n\n\n120\n82\n\n\n\n140\n78\n\n\n\n180\n88\n\n\n\nTime to code\nHere I'll report an extract of the example code you can find on Github for this classifier.\n#include &quot;EloquentPassiveAggressiveClassifier.h&quot;\n#include &quot;EloquentAccuracyScorer.h&quot;\n#include &quot;iris.h&quot;\n\nusing namespace Eloquent::ML;\n\nvoid loop() {\n    int trainSamples;\n    PassiveAggressiveClassifier&lt;FEATURES_DIM&gt; clf;\n    AccuracyScorer scorer;\n\n    trainSamples = readSerialNumber(&quot;How many samples will you use as training?&quot;, DATASET_SIZE - 2);\n\n    if (trainSamples == 0)\n        return;\n\n    clf.setC(1);\n\n    // train\n    for (uint16_t i = 0; i &lt; trainSamples; i++)\n        clf.fitOne(X[i], y[i]);\n\n    // predict\n    for (uint16_t i = trainSamples; i &lt; DATASET_SIZE; i++) {\n        int predicted = clf.predict(X[i]);\n        int actual = y[i] &gt; 0 ? 1 : -1;\n\n        scorer.scoreOne(actual, predicted);\n    }\n\n    Serial.print(&quot;Accuracy: &quot;);\n    Serial.print(round(100 * scorer.accuracy()));\n    Serial.print(&quot;% out of &quot;);\n    Serial.print(scorer.support());\n    Serial.println(&quot; predictions&quot;);\n}\n\nOn the project page you will find the code to reproduce these numbers.\n\nL'articolo Passive-aggressive classifier for embedded devices proviene da Eloquent Arduino Blog.",
            "date_published": "2020-04-05T19:04:10+02:00",
            "date_modified": "2020-05-01T10:34:15+02:00",
            "authors": [
                {
                    "name": "simone",
                    "url": "https://eloquentarduino.github.io/author/simone/",
                    "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "online-learning",
                "Arduino Machine learning"
            ]
        }
    ]
}