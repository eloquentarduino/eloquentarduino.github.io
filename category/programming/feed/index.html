<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Programming &#8211; Eloquent Arduino Blog</title>
	<atom:link href="https://eloquentarduino.github.io/category/programming/feed/" rel="self" type="application/rss+xml" />
	<link>http://eloquentarduino.github.io/</link>
	<description>Machine learning on Arduino, programming &#38; electronics</description>
	<lastBuildDate>Sun, 07 Jun 2020 09:26:25 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.3.3</generator>
	<item>
		<title>Arduino dimensionality reduction (PCA) for Machine Learning projects</title>
		<link>https://eloquentarduino.github.io/2020/06/arduino-dimensionality-reduction-pca-for-machine-learning-projects/</link>
		
		<dc:creator><![CDATA[simone]]></dc:creator>
		<pubDate>Sun, 07 Jun 2020 07:24:20 +0000</pubDate>
				<category><![CDATA[Arduino Machine learning]]></category>
		<category><![CDATA[microml]]></category>
		<category><![CDATA[pca]]></category>
		<guid isPermaLink="false">https://eloquentarduino.github.io/?p=1174</guid>

					<description><![CDATA[<p>When working with Machine Learning projects on microcontrollers and embedded devices the dimension of features can become a limiting factor due to the lack of RAM: dimensionality reduction (eg. PCA) will help you shrink your models and even achieve higher prediction accuracy. Why dimensionality reduction on Arduino microcontrollers? Dimensionality reduction is a tecnique you see [&#8230;]</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/06/arduino-dimensionality-reduction-pca-for-machine-learning-projects/">Arduino dimensionality reduction (PCA) for Machine Learning projects</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>When working with <strong>Machine Learning projects</strong> on microcontrollers and embedded devices the dimension of features can become a limiting factor due to the lack of RAM: <strong>dimensionality reduction</strong> (eg. PCA) will help you shrink your models and even achieve higher prediction accuracy.</p>
<p><a href="https://setosa.io/ev/principal-component-analysis"><img src="https://setosa.io/ev/principal-component-analysis/fb-thumb.png" alt="PCA application example" /></a></p>
<p><span id="more-1174"></span></p>
<h2>Why dimensionality reduction on Arduino microcontrollers?</h2>
<p><a href="https://en.wikipedia.org/wiki/Dimensionality_reduction">Dimensionality reduction</a> is a tecnique you see often in Machine Learning projects. By stripping away &quot;unimportant&quot; or redundant information, it generally helps speeding up the training process and achieving higher classification performances.</p>
<p>Since we now know we can run Machine Learning on Arduino boards and embedded microcontrollers, it can become a key tool at our disposal to squeeze out the most out of our boards.</p>
<p>In the specific case of resource-constrained devices as old Arduino boards (the UNO for example, with only 2 kb of RAM), it can become a decisive turn in unlocking even more application scenarios where the high dimensionality of the input features would not allow any model to fit.</p>
<p>Let's take the <a href="/2019/12/how-to-do-gesture-identification-on-arduino/">Gesture classification project</a> as an example: among the different classifiers we trained, only one fitted on the Arduino UNO, since most of them required too much flash memory due to the high dimension of features (90) and support vectors (25 to 61).</p>
<p>In this post I will resume that example and see if dimensionality reduction can help reduce this gap.</p>
<p>If you are working on a project with many features, let me know in the comments so I can create a detailed list of real world examples.</p>
<h2>How to export PCA (Principal Component Analysis) to plain C</h2>
<p>Among the many algorithms available for dimensionality reduction, I decided to start with <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">PCA (Principal Component Analysis)</a> because it's one of the most widespread. In the next weeks I will probably work on porting other alternatives.</p>
<p>If you never used my Python package <a href="https://github.com/eloquentarduino/micromlgen">micromlgen</a> I first invite you to read <a href="/2019/11/you-can-run-machine-learning-on-arduino/">the introduction post</a> to get familiar with it.</p>
<p>Always remember to install the latest version, since I publish frequent updates.</p>
<pre><code class="language-bash">pip install --upgrade micromlgen</code></pre>
<p>Now it is pretty straight-forward to convert a sklearn PCA transformer to plain C: you use the magic method <code>port</code>. In addition to converting SVM/RVM classifiers, it is now able to export PCA too.</p>
<pre><code class="language-python">from sklearn.decomposition import PCA
from sklearn.datasets import load_iris
from micromlgen import port

if __name__ == &#039;__main__&#039;:
    X = load_iris().data
    pca = PCA(n_components=2, whiten=False).fit(X)

    print(port(pca))</code></pre>
<h2>How to deploy PCA to Arduino</h2>
<p>To use the exported code, we first have to include it in our sketch. Save the contents to a file (I named it <code>pca.h</code>) in the same folder of your <code>.ino</code> project and include it.</p>
<pre><code class="language-cpp">#include &quot;pca.h&quot;

// this was trained on the IRIS dataset, with 2 principal components
Eloquent::ML::Port::PCA pca;</code></pre>
<p>The <code>pca</code> object is now able to take an array of size N as input and return an array of size K as output, with K &lt; N usually.</p>
<pre><code class="language-cpp">void setup() {
    float x_input[4] = {5.1, 3.5, 1.4, 0.2};
    float x_output[2];

    pca.transform(x_input, x_output);
}</code></pre>
<p>That's it: now you can run your classifier on <code>x_output</code>.</p>
<pre><code class="language-cpp">#include &quot;pca.h&quot;
#include &quot;svm.h&quot;

Eloquent::ML::Port::PCA pca;
Eloquent::ML::Port::SVM clf;

void setup() {
    float x_input[4] = {5.1, 3.5, 1.4, 0.2};
    float x_output[2];
    int y_pred;

    pca.transform(x_input, x_output);

    y_pred = clf.predict(x_output);
}</code></pre>
<!-- Begin Mailchimp Signup Form -->
<div id="mc_embed_signup">
<form action="https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	<h2 style="margin: 0; text-align: center">Finding this content useful?</h2>
<div class="mc-field-group">
	<input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="join the monthly newsletter">
</div>
	<div id="mce-responses" class="clear">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_f0eaedd94d554cf2ee781742a_37d3496031" tabindex="-1" value=""></div>
    <div class="clear" style="position: relative; top: 8px"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->
<h2>A real world example</h2>
<p>As I anticipated, let's take a look at how PCA dimensionality reduction can help in fitting classifiers that would otherwise be too large to fit on our microcontrollers.</p>
<p>This is the exact table from the <a href="/2019/12/how-to-do-gesture-identification-on-arduino/">Gesture classification project</a>.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Kernel</th>
<th style="text-align: center;">C</th>
<th style="text-align: center;">Gamma</th>
<th style="text-align: center;">Degree</th>
<th style="text-align: center;">Vectors</th>
<th style="text-align: center;">Flash size</th>
<th style="text-align: center;">RAM (b)</th>
<th style="text-align: center;">Avg accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">RBF</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">37</td>
<td style="text-align: center;">53 Kb</td>
<td style="text-align: center;">1228</td>
<td style="text-align: center;">99%</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Poly</strong></td>
<td style="text-align: center;"><strong>100</strong></td>
<td style="text-align: center;"><strong>0.001</strong></td>
<td style="text-align: center;"><strong>2</strong></td>
<td style="text-align: center;"><strong>12</strong></td>
<td style="text-align: center;"><strong>25 Kb</strong></td>
<td style="text-align: center;"><strong>1228</strong></td>
<td style="text-align: center;"><strong>99%</strong></td>
</tr>
<tr>
<td style="text-align: left;">Poly</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">40 Kb</td>
<td style="text-align: center;">1228</td>
<td style="text-align: center;">97%</td>
</tr>
<tr>
<td style="text-align: left;">Linear</td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">55 Kb</td>
<td style="text-align: center;">1228</td>
<td style="text-align: center;">95%</td>
</tr>
<tr>
<td style="text-align: left;">RBF</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">61</td>
<td style="text-align: center;">80 Kb</td>
<td style="text-align: center;">1228</td>
<td style="text-align: center;">95%</td>
</tr>
</tbody>
</table>
<p>The dataset has 90 features (30 samples x 3 axes) and achieves 99% accuracy. </p>
<p>Let's pick the <code>poly</code> kernel with degree <code>2</code> and see how much we can decrease the number of components while still achieving a good accuracy.</p>
<table>
<thead>
<tr>
<th>PCA components</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">Support vectors</th>
</tr>
</thead>
<tbody>
<tr>
<td>90</td>
<td style="text-align: center;">99%</td>
<td style="text-align: center;">31</td>
</tr>
<tr>
<td>50</td>
<td style="text-align: center;">99%</td>
<td style="text-align: center;">31</td>
</tr>
<tr>
<td>40</td>
<td style="text-align: center;">99%</td>
<td style="text-align: center;">31</td>
</tr>
<tr>
<td>30</td>
<td style="text-align: center;">90%</td>
<td style="text-align: center;">30</td>
</tr>
<tr>
<td>20</td>
<td style="text-align: center;">90%</td>
<td style="text-align: center;">28</td>
</tr>
<tr>
<td>15</td>
<td style="text-align: center;">90%</td>
<td style="text-align: center;">24</td>
</tr>
<tr>
<td><strong>10</strong></td>
<td style="text-align: center;"><strong>99%</strong></td>
<td style="text-align: center;"><strong>18</strong></td>
</tr>
<tr>
<td>5</td>
<td style="text-align: center;">76%</td>
<td style="text-align: center;">28</td>
</tr>
</tbody>
</table>
<p>We clearly see a couple of things:</p>
<ol>
<li>we still achieve 99% accuracy even with only 40 out of 90 principal components</li>
<li>we get a satisfactory 90% accuracy even <strong>with only 15 components</strong></li>
<li>(this is a bit unexpected) it looks like there's a sweet spot at 10 components where the accuracy skyrockets to 99% again. <em>This could be just a contingency of this particular dataset, don't expect to replicate this results on your own dataset</em></li>
</ol>
<p>What do these numbers mean to you? It means your board has to do many less computations to give you a prediction and will probably be able to host a more complex model.</p>
<p>Let's check out the figures with <code>n_components = 10</code> compared with the ones without PCA.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Kernel</th>
<th style="text-align: center;">PCA support vectors</th>
<th style="text-align: center;">PCA flash size</th>
<th style="text-align: center;">Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">RBF C=10</td>
<td style="text-align: center;">46 (+24%)</td>
<td style="text-align: center;">32 Kb (-40%)</td>
<td style="text-align: center;">99%</td>
</tr>
<tr>
<td style="text-align: left;">RBF C=100</td>
<td style="text-align: center;">28 (-54%)</td>
<td style="text-align: center;">32 Kb (-60%)</td>
<td style="text-align: center;">99%</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Poly 2</strong></td>
<td style="text-align: center;">13 (-48%)</td>
<td style="text-align: center;">28 Kb (+12%)</td>
<td style="text-align: center;">99%</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Poly 3</strong></td>
<td style="text-align: center;">24 (-4%)</td>
<td style="text-align: center;">32 Kb (-20%)</td>
<td style="text-align: center;">99%</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Linear</strong></td>
<td style="text-align: center;">18 (-64%)</td>
<td style="text-align: center;">29 Kb (-47%)</td>
<td style="text-align: center;">99%</td>
</tr>
</tbody>
</table>
<p>A couple notes:</p>
<ol>
<li>accuracy increased (on stayed the same) for all kernels</li>
<li>with one exception, flash size decreased in the range 20 - 50%</li>
<li>now we can fit 3 classifiers on our Arduino UNO instead of only one</li>
</ol>
<p>I will probably spend some more time investingating the usefulness of PCA for Arduino Machine Learning projects, but for now that's it: it's a good starting point in my opinion.</p>
<hr />
<p>There's a little example sketch on <a href="https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/PCAExample/PCAExample.ino">Github</a> that applies PCA to the IRIS dataset.</p>
<p>Tell me what you think may be a clever application of dimensionality reduction in the world of microcontrollers and see if we can build something great together.</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/06/arduino-dimensionality-reduction-pca-for-machine-learning-projects/">Arduino dimensionality reduction (PCA) for Machine Learning projects</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Anomaly detection on your Arduino microcontroller via One Class SVM</title>
		<link>https://eloquentarduino.github.io/2020/05/anomaly-detection-on-your-arduino-microcontroller-via-one-class-svm/</link>
		
		<dc:creator><![CDATA[simone]]></dc:creator>
		<pubDate>Sun, 31 May 2020 16:44:36 +0000</pubDate>
				<category><![CDATA[Arduino Machine learning]]></category>
		<guid isPermaLink="false">https://eloquentarduino.github.io/?p=1156</guid>

					<description><![CDATA[<p>Support Vector Machines are very often used for classification tasks: but you may not know that they're so flexible they can be used for anomaly detection and novelty detection. Thanks to the micromlgen package, you can run One Class SVM on your Arduino microcontorller. What is anomaly / novelty detection useful for? Detect noise or [&#8230;]</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/05/anomaly-detection-on-your-arduino-microcontroller-via-one-class-svm/">Anomaly detection on your Arduino microcontroller via One Class SVM</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p><a href="/tag/svm/">Support Vector Machines</a> are very often used for classification tasks: but you may not know that they're so flexible they can be used for <a href="https://scikit-learn.org/stable/modules/outlier_detection.html" target="_blank" rel="noopener noreferrer"><strong>anomaly detection and novelty detection</strong></a>. Thanks to the <a href="https://github.com/eloquentarduino/micromlgen">micromlgen</a> package, you can run One Class SVM on your Arduino microcontorller.</p>
<p><img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_oneclass_001.png" alt="Novelty detection from sklearn documentation" title="Novelty detection from sklearn documentation" /><br />
<span id="more-1156"></span></p>
<h2>What is anomaly / novelty detection useful for?</h2>
<h3>Detect noise or anomalies</h3>
<p>As the name implies, anomaly detection can be used to monitor a stream of data and alert you when something unexpected happens.<br />
Think of an Industrial IoT setup where you have a bunch of sensors monitoring the working state of a production plant: you want to know as soon as possible if something bad is gonna happen.</p>
<p>In this case, anomaly detection tells you if your machinery is acting in a different way from the normal state so you can take action.</p>
<h3>Ignore irrelevant data</h3>
<p><em>(This application was suggested from two of my readers)</em><br />
Say you're developing a super simple word classification project: you want to distinguish door bell from fire alarm (as per one of the two readers).<br />
So you train your SVM classifier and use <a href="https://github.com/eloquentarduino/micromlgen">micromlgen</a> to run it on your Arduino microcontroller.</p>
<p>It works well, but we have a problem: you live in a noisy environment with many sounds, so not all of them will either be door bells or fire alarms. Since your classifier is binary, it <em>has to classify all of the sounds</em> as either A or B.</p>
<p>The solution will be <strong>novelty detection</strong>: before running the binary SVM, you run the <strong>OneClassSVM</strong> to filter known sounds (bell and alarm) from unknown ones (eg. dog barking).<br />
If OneClassSVM predicts the sound as a novelty, you discard it since it's of no interest for you. If it predicts the sound as known, you run the binary SVM.</p>
<!-- Begin Mailchimp Signup Form -->
<div id="mc_embed_signup">
<form action="https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	<h2 style="margin: 0; text-align: center">Finding this content useful?</h2>
<div class="mc-field-group">
	<input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="join the monthly newsletter">
</div>
	<div id="mce-responses" class="clear">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_f0eaedd94d554cf2ee781742a_37d3496031" tabindex="-1" value=""></div>
    <div class="clear" style="position: relative; top: 8px"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->
<h2>How to run anomaly / novelty detection on Arduino microcontroller via OneClassSVM</h2>
<p>Porting a <a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html">OneClassSVM</a> from Python to plain C++ is as easy as a single command in the <strong>micromlgen</strong> package:</p>
<pre><code class="language-python">from sklearn.svm import OneClassSVM
from micromlgen import port

clf = OneClassSVM(kernel=&quot;rbf&quot;, nu=0.5, gamma=0.1)
clf.fit(X, y)
print(port(clf))</code></pre>
<div class="watchout">
You will need micromlgen version 1.0.2 to port OneClassSVM. If you have an outdated version, please run <code>pip install --upgrade micromlgen</code>
</div>
<p>If you read <a href="/tag/svm/">my previous posts</a> about <strong>micromlgen</strong> and SVM the above snippet should be familiar: with the latest release, <code>port</code> is able to export either SVC, LinearSVC, OneClassSVC and <a href="/2020/02/even-smaller-machine-learning-models-for-your-mcu/">RVC (Relevant Vector Machines)</a> to object oriented C++.</p>
<p>Now you can embed the generated code in your Arduino sketch.</p>
<pre><code class="language-cpp">#include &quot;OneClassSVM.h&quot;

Eloquent::ML::Port::OneClassSVM clf;

void setup() {
  Serial.begin(115200);
  delay(2000);

  for (int i = 0; i &lt; DATASET_SIZE; i++)
    clf.predict(X[i]);
}

void loop() {}</code></pre>
<hr />
<p>I created an example sketch from a synthetic dataset for anomaly detection (copied from a <a href="https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html#sphx-glr-auto-examples-svm-plot-oneclass-py">scikit-learn example</a>) you can run to get a feel of how it performs.</p>
<p>Go checkout the <a href="https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/OneClassSVMExample/OneClassSVMExample.ino">Github repo</a></p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/05/anomaly-detection-on-your-arduino-microcontroller-via-one-class-svm/">Anomaly detection on your Arduino microcontroller via One Class SVM</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Easier, faster pure video ESP32 cam motion detection</title>
		<link>https://eloquentarduino.github.io/2020/05/easier-faster-pure-video-esp32-cam-motion-detection/</link>
		
		<dc:creator><![CDATA[simone]]></dc:creator>
		<pubDate>Sun, 10 May 2020 19:26:08 +0000</pubDate>
				<category><![CDATA[Computer vision]]></category>
		<category><![CDATA[camera]]></category>
		<category><![CDATA[esp32]]></category>
		<guid isPermaLink="false">https://eloquentarduino.github.io/?p=1110</guid>

					<description><![CDATA[<p>If you liked my post about ESP32 cam motion detection, you'll love this updated version: it's easier to use and blazing fast! The post about pure video ESP32 cam motion detection without an external PIR is my most successful post at the moment. Many of you are interested about this topic. One of my readers, [&#8230;]</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/05/easier-faster-pure-video-esp32-cam-motion-detection/">Easier, faster pure video ESP32 cam motion detection</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>If you liked my post about <a href="/2020/01/motion-detection-with-esp32-cam-only-arduino-version/">ESP32 cam motion detection</a>, you'll love this updated version: it's easier to use and blazing fast!</p>
<p><img src="https://eloquentarduino.github.io/wp-content/uploads/2020/05/Faster-motion-detection.gif" alt="Faster motion detection" /></p>
<p><span id="more-1110"></span></p>
<p>The post about <strong>pure video ESP32 cam motion detection</strong> without an external PIR is my most successful post at the moment. Many of you are interested about this topic.</p>
<p>One of my readers, though, pointed out my implementation was quite slow and he only achieved bare 5 fps in his project. So he asked for a better alternative.</p>
<p>Since the post was of great interest for many people, I took the time to revisit the code and make improvements.</p>
<p>I came up with a 100% re-writing that is both easier to use and faster. Actually, it is <strong>blazing fast!</strong>.</p>
<p>Let's see how it works.</p>
<p><div class="toc"><h6>Table of contents</h6><ol><li><a href="#tocdownsampling">Downsampling</a><ol><li><a href="#tocnearest-neighbor">Nearest neighbor</a><li><a href="#tocfull-block-average">Full block average</a><li><a href="#toccore-block-average">Core block average</a><li><a href="#toccross-block-average">Cross block average</a><li><a href="#tocdiagonal-block-average">Diagonal block average</a><li><a href="#tocimplement-your-own">Implement your own</a></li></ol><li><a href="#tocbenchmarks">Benchmarks</a><li><a href="#tocmotion-detection">Motion detection</a><li><a href="#tocfull-code">Full code</a></ol></div></p>
<h2 id="tocdownsampling">Downsampling</h2>
<p>In the original post I introduced the idea of downsampling the image from the camera for a faster and more robust motion detection. I wrote the code in the main sketch to keep it self-contained.</p>
<p>Looking back now it was a poor choice, since it cluttered the project and distracted from the main purpose, which is motion detection.</p>
<p>Moreover, I thought that scanning the image buffer in sequential order would be the fastest approach.</p>
<p>It turns out I was wrong.</p>
<p>This time I scan the image buffer following the blocks that will compose the resulting image and the results are... much faster.</p>
<p>Also, I decided to inject some more efficiency that will further speedup the computation: using different strategies for downsampling.</p>
<p>The idea of downsampling is that you have to &quot;collapse&quot; a block of NxN from the original image to just one pixel of the resulting image.</p>
<p>Now, there are a variety of ways you can accomplish this. The first two I present here are the most obvious, the other two are of my &quot;invention&quot;: nothing fancy nor new, but they're fast and serve the purpose well.</p>
<h3 id="tocnearest-neighbor">Nearest neighbor</h3>
<p>You can just pick the center of the NxN block and use its value for the output.<br />
Of course it is fast (possibly the fastest approach), but wouldn't be very accurate. One pixel out of NxN wouldn't be representative of the overall region and will heavily suffer from noise.</p>
<p><img src="https://eloquentarduino.github.io/wp-content/uploads/2020/05/Nearest-diagram.png" alt="Nearest diagram" /></p>
<p><img src="https://eloquentarduino.github.io/wp-content/uploads/2020/05/nn.jpg" alt="Nearest neighbor block averaging" /></p>
<h3 id="tocfull-block-average">Full block average</h3>
<p>This is the most intuitive alternative: use the average of all the pixels in the block as the ouput value. This is arguabily the &quot;proper&quot; way to do it, since you're using all the pixels in the source image to compute the new one.</p>
<p><img src="https://eloquentarduino.github.io/wp-content/uploads/2020/05/Full-diagram.png" alt="Full diagram" /><br />
<img src="https://eloquentarduino.github.io/wp-content/uploads/2020/05/full.jpg" alt="Full block averaging" /></p>
<h3 id="toccore-block-average">Core block average</h3>
<p>As a faster alternative, I thought that averaging only the &quot;core&quot; (the most internal part) of the block would have been a good-enough solution. It has no theoretical proof that this yields true, but our task here is to create a smaller <em>representation</em> of the original image, not producing an accurate smaller version.</p>
<p><img src="https://eloquentarduino.github.io/wp-content/uploads/2020/05/Core-diagram.png" alt="Core diagram" /><br />
<img src="https://eloquentarduino.github.io/wp-content/uploads/2020/05/core.jpg" alt="Core block averaging" /></p>
<p><em>I'll stress this point: the only reason we do downsampling is to compare two sequential frame and detect if they differ above a certain threshold. This downsampling doesn't have to mimic the actual image: it can transform the source in any fancy way, as long as it stays consistent and captures the variations over time.</em></p>
<h3 id="toccross-block-average">Cross block average</h3>
<p>This time we consider all the pixels along the vertical and horizontal central axes. The idea is that you will capture a good portion of the variation along both the axis, given quite accurate results.</p>
<p><img src="https://eloquentarduino.github.io/wp-content/uploads/2020/05/Cross-diagram.png" alt="Cross diagram" /><br />
<img src="https://eloquentarduino.github.io/wp-content/uploads/2020/05/cross.jpg" alt="Cross block averaging" /></p>
<h3 id="tocdiagonal-block-average">Diagonal block average</h3>
<p>This alternative too came to my mind from nowhere, really. I just think it is a good alternative to capture all the block's variation, probably even better than vertical and horizontal directions.</p>
<p><img src="https://eloquentarduino.github.io/wp-content/uploads/2020/05/Diagonal-diagram.png" alt="Diagonal diagram" /><br />
<img src="https://eloquentarduino.github.io/wp-content/uploads/2020/05/diagonal.jpg" alt="Diagonal block averaging" /></p>
<h3 id="tocimplement-your-own">Implement your own</h3>
<p>Not satisfied from the methods above? No problem, you can still implement your own.</p>
<p>The ones presented above are just some algorithms that came to my mind: I'm not telling you they're the best.</p>
<p>They worked for me, that's it.</p>
<p>If you think you found a better solution, I encourage you implement it and even share it with me and the other readers, so we can all make progress on this together.</p>
<!-- Begin Mailchimp Signup Form -->
<div id="mc_embed_signup">
<form action="https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	<h2 style="margin: 0; text-align: center">Finding this content useful?</h2>
<div class="mc-field-group">
	<input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="join the monthly newsletter">
</div>
	<div id="mce-responses" class="clear">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_f0eaedd94d554cf2ee781742a_37d3496031" tabindex="-1" value=""></div>
    <div class="clear" style="position: relative; top: 8px"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->
<h2 id="tocbenchmarks">Benchmarks</h2>
<p>So, at the very beginning I said this new implementation is blazingly fast. </p>
<p>How much fast?</p>
<p>As fast as it can be, arguably.</p>
<p>I mean, so fast it won't alter your fps.</p>
<p>Look at the results I got on my M5Stack camera.</p>
<table>
<thead>
<tr>
<th>Algorithm</th>
<th style="text-align: center;">Time to execute (micros)</th>
<th style="text-align: right;">FPS</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td style="text-align: center;">0</td>
<td style="text-align: right;">25</td>
</tr>
<tr>
<td>Nearest neighbor</td>
<td style="text-align: center;">160</td>
<td style="text-align: right;">25</td>
</tr>
<tr>
<td>Cross block</td>
<td style="text-align: center;">700</td>
<td style="text-align: right;">25</td>
</tr>
<tr>
<td>Core block</td>
<td style="text-align: center;">800</td>
<td style="text-align: right;">25</td>
</tr>
<tr>
<td>Diagonal block</td>
<td style="text-align: center;">950</td>
<td style="text-align: right;">25</td>
</tr>
<tr>
<td>Full block</td>
<td style="text-align: center;">4900</td>
<td style="text-align: right;">12</td>
</tr>
</tbody>
</table>
<p>As you can see, only the full block creates a delay in the process (quite a bit of delay even): the other  methods  won't slow down your program in any noticeable way.</p>
<p>If you test Nearest neighbor and it works for you, then you'll be extremely light on computation resources with only <strong>160 microseconds</strong> of delay.</p>
<p>This is what I mean by <em>blazing fast</em>.</p>
<h2 id="tocmotion-detection">Motion detection</h2>
<p>The motion detection part hasn't changed, so I point you to <a href="/2020/01/motion-detection-with-esp32-cam-only-arduino-version#tocblocks-difference-threshold">the original post</a> to read more about the Block difference threshold and the Image difference threshold.</p>
<h2 id="tocfull-code">Full code</h2>
<pre><code class="language-cpp">#define CAMERA_MODEL_M5STACK_WIDE
#include &quot;EloquentVision.h&quot;

#define FRAME_SIZE FRAMESIZE_QVGA
#define SOURCE_WIDTH 320
#define SOURCE_HEIGHT 240
#define BLOCK_SIZE 10
#define DEST_WIDTH (SOURCE_WIDTH / BLOCK_SIZE)
#define DEST_HEIGHT (SOURCE_HEIGHT / BLOCK_SIZE)
#define BLOCK_DIFF_THRESHOLD 0.2
#define IMAGE_DIFF_THRESHOLD 0.1
#define DEBUG 0

using namespace Eloquent::Vision;

ESP32Camera camera;
uint8_t prevFrame[DEST_WIDTH * DEST_HEIGHT] = { 0 };
uint8_t currentFrame[DEST_WIDTH * DEST_HEIGHT] = { 0 };

// function prototypes
bool motionDetect();
void updateFrame();

/**
 *
 */
void setup() {
    Serial.begin(115200);
    camera.begin(FRAME_SIZE, PIXFORMAT_GRAYSCALE);
}

/**
 *
 */
void loop() {
    /**
     * Algorithm:
     *  1. grab frame
     *  2. compare with previous to detect motion
     *  3. update previous frame
     */

    time_t start = millis();
    camera_fb_t *frame = camera.capture();

    downscaleImage(frame-&gt;buf, currentFrame, nearest, SOURCE_WIDTH, SOURCE_HEIGHT, BLOCK_SIZE);

    if (motionDetect()) {
        Serial.print(&quot;Motion detected @ &quot;);
        Serial.print(floor(1000.0f / (millis() - start)));
        Serial.println(&quot; FPS&quot;);
    }

    updateFrame();
}

/**
 * Compute the number of different blocks
 * If there are enough, then motion happened
 */
bool motionDetect() {
    uint16_t changes = 0;
    const uint16_t blocks = DEST_WIDTH * DEST_HEIGHT;

    for (int y = 0; y &lt; DEST_HEIGHT; y++) {
        for (int x = 0; x &lt; DEST_WIDTH; x++) {
            float current = currentFrame[y * DEST_WIDTH + x];
            float prev = prevFrame[y * DEST_WIDTH + x];
            float delta = abs(current - prev) / prev;

            if (delta &gt;= BLOCK_DIFF_THRESHOLD)
                changes += 1;
        }
    }

    return (1.0 * changes / blocks) &gt; IMAGE_DIFF_THRESHOLD;
}

/**
 * Copy current frame to previous
 */
void updateFrame() {
    memcpy(prevFrame, currentFrame, DEST_WIDTH * DEST_HEIGHT);
}</code></pre>
<hr />
<p>Check the full project code on <a href="https://github.com/eloquentarduino/EloquentVision/blob/master/examples/FasterMotionDetection/FasterMotionDetection.ino">Github</a> and remember to star!</p>
<!-- Begin Mailchimp Signup Form -->
<div id="mc_embed_signup">
<form action="https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	<h2 style="margin: 0; text-align: center">Finding this content useful?</h2>
<div class="mc-field-group">
	<input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="join the monthly newsletter">
</div>
	<div id="mce-responses" class="clear">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_f0eaedd94d554cf2ee781742a_37d3496031" tabindex="-1" value=""></div>
    <div class="clear" style="position: relative; top: 8px"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/05/easier-faster-pure-video-esp32-cam-motion-detection/">Easier, faster pure video ESP32 cam motion detection</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Incremental multiclass classification on microcontrollers: One vs One</title>
		<link>https://eloquentarduino.github.io/2020/04/incremental-multiclass-classification-on-microcontrollers-one-vs-one/</link>
		
		<dc:creator><![CDATA[simone]]></dc:creator>
		<pubDate>Sun, 26 Apr 2020 08:01:14 +0000</pubDate>
				<category><![CDATA[Arduino Machine learning]]></category>
		<category><![CDATA[incremental-learning]]></category>
		<category><![CDATA[microml]]></category>
		<category><![CDATA[ml]]></category>
		<guid isPermaLink="false">https://eloquentarduino.github.io/?p=1079</guid>

					<description><![CDATA[<p>In earlier posts I showed you can run incremental binary classification on your microcontroller with Stochastic Gradient Descent or Passive-Aggressive classifier. Now it is time to upgrade your toolbelt with a new item: One-vs-One multiclass classifier. One vs One Many classifiers are, by nature, binary: they can only distinguish the positive class from the negative [&#8230;]</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/04/incremental-multiclass-classification-on-microcontrollers-one-vs-one/">Incremental multiclass classification on microcontrollers: One vs One</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>In earlier posts I showed you can run incremental binary classification on your microcontroller with Stochastic Gradient Descent or Passive-Aggressive classifier. Now it is time to upgrade your toolbelt with a new item: One-vs-One multiclass classifier.</p>
<p><span id="more-1079"></span></p>
<h2>One vs One</h2>
<p>Many classifiers are, by nature, binary: they can only distinguish the positive class from the negative one. Many of real-world problems, however, are multiclass: you have 3 or more possible outcomes to distinguish from.</p>
<p>There are a couple of ways to achieve this:</p>
<ol>
<li><strong>One vs All</strong>: if your classifier is able to output a confidence score of its prediction, for N classes you train N classifiers, each able to recognize a single class. During inference, you pick the &quot;most confident&quot; one.</li>
<li><strong>One vs One</strong>: for N classes, you train N * (N-1) / 2 classifiers, one for each couple of classes. During inference, each classifier makes a prediction and you pick the class with the highest number of votes.</li>
</ol>
<p>Since SGD and Passive-Aggressive don't output a confidence score, I implemented the One vs One algorithm to tackle the multiclass classification problem on microcontrollers.</p>
<p>Actually, One vs One is not a new type of classifier: it is really a &quot;coordinator&quot; class that sorts which samples go to which classifier. You can still choose your own classifier type to use.</p>
<p>As SGD and Passive-Aggressive, OneVsOne implements the classifier interface, so you will use the well known <code>fitOne</code> and <code>predict</code> methods.</p>
<!-- Begin Mailchimp Signup Form -->
<div id="mc_embed_signup">
<form action="https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	<h2 style="margin: 0; text-align: center">Finding this content useful?</h2>
<div class="mc-field-group">
	<input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="join the monthly newsletter">
</div>
	<div id="mce-responses" class="clear">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_f0eaedd94d554cf2ee781742a_37d3496031" tabindex="-1" value=""></div>
    <div class="clear" style="position: relative; top: 8px"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->
<h2>Example code</h2>
<pre><code class="language-cpp">// Esp32 has some problems with min/max
#define min(a, b) (a) &lt; (b) ? (a) : (b)
#define max(a, b) (a) &gt; (b) ? (a) : (b)
// you will actually need only one of SGD or PassiveAggressive
#include &quot;EloquentSGD.h&quot;
#include &quot;EloquentPassiveAggressive.h&quot;
#include &quot;EloquentOneVsOne.h&quot;
#include &quot;EloquentAccuracyScorer.h&quot;
// this file defines NUM_FEATURES, NUM_CLASSES, TRAIN_SAMPLES and TEST_SAMPLES
#include &quot;dataset.h&quot;

using namespace Eloquent::ML;

void setup() {
  Serial.begin(115200);
  delay(3000);
}

void loop() {
  AccuracyScorer scorer;
  // OneVsOne needs the actual classifier class, the number of features and the number of classes
  OneVsOne&lt;SGD&lt;FEATURES_DIM&gt;, FEATURES_DIM, NUM_CLASSES&gt; clf;

  // clf.set() propagates the configuration to the actual classifiers
  // if a parameter does not exists on the classifier, it does nothing
  // in this example, alpha and momentum refer to SGD, C to Passive-Aggressive
  clf.set(&quot;alpha&quot;, 1);
  clf.set(&quot;momentum&quot;, 0.7);
  clf.set(&quot;C&quot;, 0.1);

  // fit
  // I noticed that repeating the training a few times over the same dataset increases performance  to a certain extent: if you re-train it too much, performance will decay
  for (unsigned int i = 0; i &lt; TRAIN_SAMPLES * 5; i++) {
      clf.fitOne(X_train[i % TRAIN_SAMPLES], y_train[i % TRAIN_SAMPLES]);
  }

  // predict
  for (int i = 0; i &lt; TEST_SAMPLES; i++) {
      int y_true = y_test[i];
      int y_pred = clf.predict(X_test[i]);

      Serial.print(&quot;Predicted &quot;);
      Serial.print(y_pred);
      Serial.print(&quot; vs &quot;);
      Serial.println(y_true);
      scorer.scoreOne(y_true, y_pred);
  }

  Serial.print(&quot;Accuracy = &quot;);
  Serial.print(scorer.accuracy() * 100);
  Serial.print(&quot; out of &quot;);
  Serial.print(scorer.support());
  Serial.println(&quot; samples&quot;);
  delay(30000);
}</code></pre>
<p>If you refer to the previous posts on <a href="/2020/04/stochastic-gradient-descent-on-your-microcontroller/">SGD</a> and <a href="/2020/04/passive-aggressive-classifier-for-embedded-devices/">Passive-Aggressive</a>, you'll notice that you would be able to replace one with the other and your code will change by <strong>1 single line only</strong>. This let's you experiment to find the best configuration for your project without hassle.</p>
<h2>Accuracy</h2>
<p>Well, accuracy vary.</p>
<p>In my tests, I couldn't get predictable accuracy on all datasets. I couldn't even get acceptable accuracy on the Iris dataset (60% max). But I got 90% accuracy on the Digits dataset from scikit-learn with 6 classes.</p>
<p>You have to experiment. Try Passive-Aggressive with many <code>C</code> values. If it doesn't work, try SGD with varying <code>momentum</code> and <code>alpha</code>. Try to repeat the training over the dataset 5, 10 times.</p>
<p>In a next post I'll report my benchmarks so you can see what works for you and what not.<br />
This is an emerging field for me, so I will need time to master it.</p>
<hr />
<p>As always, you can find the examle on <a href="https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/OvOExample/OvOExample.ino">Github</a> with a the dataset to experiment with.</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/04/incremental-multiclass-classification-on-microcontrollers-one-vs-one/">Incremental multiclass classification on microcontrollers: One vs One</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Stochastic Gradient Descent on your microcontroller</title>
		<link>https://eloquentarduino.github.io/2020/04/stochastic-gradient-descent-on-your-microcontroller/</link>
		
		<dc:creator><![CDATA[simone]]></dc:creator>
		<pubDate>Fri, 10 Apr 2020 17:43:45 +0000</pubDate>
				<category><![CDATA[Arduino Machine learning]]></category>
		<category><![CDATA[microml]]></category>
		<category><![CDATA[online-learning]]></category>
		<guid isPermaLink="false">https://eloquentarduino.github.io/?p=1062</guid>

					<description><![CDATA[<p>Stochastic gradient descent is a well know algorithm to train classifiers in an incremental fashion: that is, as training samples become available. This saves you critical memory on tiny devices while still achieving top performance! Now you can use it on your microcontroller with ease. A brief recap on Stochastic Gradient Descent If you ever [&#8230;]</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/04/stochastic-gradient-descent-on-your-microcontroller/">Stochastic Gradient Descent on your microcontroller</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>Stochastic gradient descent is a well know algorithm to train classifiers in an incremental fashion: that is, as training samples become available. This saves you critical memory on tiny devices while still achieving <strong>top performance</strong>! Now you can use it on your microcontroller with ease.</p>
<p><span id="more-1062"></span></p>
<h2>A brief recap on Stochastic Gradient Descent</h2>
<p>If you ever worked with Machine learning, you surely know about <a href="https://en.wikipedia.org/wiki/Gradient_descent">Gradient descent</a>: it is an iterative algorithm to optimize a loss function. </p>
<p>It is much general-purpose, in the sense that it is not bound to a particular application, but it has been heavily used in Neural networks in the recent years.</p>
<p>Yet, it can be used as a classifier on its own if you set its loss function as the classification error.</p>
<p><img src="https://mccormickml.com/assets/GradientDescent/GradientDescentOfMSETable.png" alt="Update rule of Gradient descent" /></p>
<p>This is the core update rule of Gradient descent: quite simple.</p>
<p>As you see, there's a summation in the formula: this means we need to cycle through the entire training set to compute the update to the weights.</p>
<p>In case of large datasets, this can be slow or not possible at all.</p>
<p>And requires a lot of memory.</p>
<p>And we don't have memory on microcontrollers.</p>
<p>So we need <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic gradient descent</a>.</p>
<p>Stochastic gradient descent has the same exact update rule, but it is applied on the single training sample.</p>
<p>Imagine the summation goes from 1 to 1, instead of m.</p>
<p>That's it.</p>
<div class="heateor_sss_sharing_container heateor_sss_horizontal_sharing" ss-offset="0" heateor-sss-data-href='https://eloquentarduino.github.io/2020/04/stochastic-gradient-descent-on-your-microcontroller/'><ul class="heateor_sss_sharing_ul"><li class="heateorSssSharingRound"><i style="width:35px;height:35px;border-radius:999px;" alt="Facebook" Title="Facebook" class="heateorSssSharing heateorSssFacebookBackground" onclick='heateorSssPopup("https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Feloquent.blog%2F2020%2F04%2Fstochastic-gradient-descent-on-your-microcontroller%2F")'><ss style="display:block;border-radius:999px;" class="heateorSssSharingSvg heateorSssFacebookSvg"></ss></i></li><li class="heateorSssSharingRound"><i style="width:35px;height:35px;border-radius:999px;" alt="Twitter" Title="Twitter" class="heateorSssSharing heateorSssTwitterBackground" onclick='heateorSssPopup("http://twitter.com/intent/tweet?via=ArduinoEloquent&text=Stochastic%20Gradient%20Descent%20on%20your%20microcontroller&url=http%3A%2F%2Feloquent.blog%2F2020%2F04%2Fstochastic-gradient-descent-on-your-microcontroller%2F")'><ss style="display:block;border-radius:999px;" class="heateorSssSharingSvg heateorSssTwitterSvg"></ss></i></li><li class="heateorSssSharingRound"><i style="width:35px;height:35px;border-radius:999px;" alt="Linkedin" Title="Linkedin" class="heateorSssSharing heateorSssLinkedinBackground" onclick='heateorSssPopup("http://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Feloquent.blog%2F2020%2F04%2Fstochastic-gradient-descent-on-your-microcontroller%2F&title=Stochastic%20Gradient%20Descent%20on%20your%20microcontroller")'><ss style="display:block;border-radius:999px;" class="heateorSssSharingSvg heateorSssLinkedinSvg"></ss></i></li><li class="heateorSssSharingRound"><i style="width:35px;height:35px;border-radius:999px;" title="More" alt="More" class="heateorSssSharing heateorSssMoreBackground" onclick="heateorSssMoreSharingPopup(this, 'https://eloquentarduino.github.io/2020/04/stochastic-gradient-descent-on-your-microcontroller/', 'Stochastic%20Gradient%20Descent%20on%20your%20microcontroller', '' )" ><ss style="display:block" class="heateorSssSharingSvg heateorSssMoreSvg"></ss></i></li></ul><div class="heateorSssClear"></div></div>
<h2>How to use</h2>
<p>The pattern of use is similar to that of the <a href="/2020/04/passive-aggressive-classifier-for-embedded-devices/">Passive Aggressive classifier</a>: you have the <code>fitOne</code> and <code>predict</code> methods.</p>
<p>First of all, <a href="https://github.com/eloquentarduino/EloquentMicroML">download the library from Github</a>.</p>
<pre><code class="language-c">#include &lt;EloquentSGD.h&gt;
#include &lt;EloquentAccuracyScorer.h&gt;
#include &quot;iris.h&quot;

#define VERBOSE

using namespace Eloquent::ML;

void setup() {
    Serial.begin(115200);
    delay(3000);
}

void loop() {
    int trainSamples;
    int retrainingCycles;
    SGD&lt;FEATURES_DIM&gt; clf;
    AccuracyScorer scorer;

    // ....

    // train
    for (uint16_t cycle = 0; cycle &lt; retrainingCycles; cycle++)
        for (uint16_t i = 0; i &lt; trainSamples; i++)
            clf.fitOne(X[i], y[i]);

    // predict
    for (uint16_t i = trainSamples; i &lt; DATASET_SIZE; i++) {
        int predicted = clf.predict(X[i]);
        int actual = y[i];

        scorer.scoreOne(actual, predicted);
    }

    Serial.print(&quot;Accuracy: &quot;);
    Serial.print(round(100 * scorer.accuracy()));
    Serial.print(&quot;% out of &quot;);
    Serial.print(scorer.support());
    Serial.println(&quot; predictions&quot;);
}</code></pre>
<p>In this case we're working with known datasets, so we cycle through them for the training, but if you're learning &quot;on-line&quot;, from samples generated over time, it will work exactly the same.</p>
<h2>A bit of momentum</h2>
<p>Stochastic gradient descent works quite well out of the box in most cases.</p>
<p>Sometimes, however, its updates can start &quot;oscillating&quot;.</p>
<p><img src="https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-1-4842-4470-8_33/MediaObjects/463852_1_En_33_Fig1_HTML.jpg" alt="SGD with and without momentum" /></p>
<p>To solve this problem, it <a href="https://doi.org/10.1038%2F323533a0">has been proposed</a> the <strong>momentum</strong> technique, which can both speed up learning and increase the accuracy.</p>
<p>In my personal tests, I was able to achieve up to +5% in accuracy on the majority of datasets.</p>
<p>To use it, you only need to set a <em>decay factor</em> between 0 and 1.</p>
<pre><code class="language-c">SGD clf;

clf.momentum(0.5);</code></pre>
<h2>Run on your own</h2>
<p>On <a href="https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/SGDExample/SGDExample.ino">Github</a> you can find the full example with some benchmark datasets to try on your own.</p>
<!-- Begin Mailchimp Signup Form -->
<div id="mc_embed_signup">
<form action="https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	<h2 style="margin: 0; text-align: center">Finding this content useful?</h2>
<div class="mc-field-group">
	<input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="join the monthly newsletter">
</div>
	<div id="mce-responses" class="clear">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_f0eaedd94d554cf2ee781742a_37d3496031" tabindex="-1" value=""></div>
    <div class="clear" style="position: relative; top: 8px"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->
<p>The example is interactive an will ask you how many samples to use for the training and how many times to cycle through them.</p>
<p>This is something you should consider: if you have a training set and can store it somehow (in memory or on Flash for example), re-presenting the same samples to the SGD classifier could (and probably will) increase its performance if done correctly.</p>
<p>This happens because the algorithm needs some time to converge and if it doesn't receive enough samples it won't learn properly.</p>
<p>Of course, if you re-use the same samples over and over again, you're likely to overfit.</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/04/stochastic-gradient-descent-on-your-microcontroller/">Stochastic Gradient Descent on your microcontroller</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Passive-aggressive classifier for embedded devices</title>
		<link>https://eloquentarduino.github.io/2020/04/passive-aggressive-classifier-for-embedded-devices/</link>
		
		<dc:creator><![CDATA[simone]]></dc:creator>
		<pubDate>Sun, 05 Apr 2020 17:04:10 +0000</pubDate>
				<category><![CDATA[Arduino Machine learning]]></category>
		<category><![CDATA[microml]]></category>
		<category><![CDATA[online-learning]]></category>
		<guid isPermaLink="false">https://eloquentarduino.github.io/?p=1050</guid>

					<description><![CDATA[<p>When working with memory constrained devices you may not able to keep all the training data in memory: passive-aggressive classifiers may help solve your memory problems. Batch learning A couple weeks ago I started exploring the possibility to train a machine learning classifier directly on a microcontroller. Since I like SVM, I ported the simplified [&#8230;]</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/04/passive-aggressive-classifier-for-embedded-devices/">Passive-aggressive classifier for embedded devices</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>When working with memory constrained devices you may not able to keep all the training data in memory: passive-aggressive classifiers may help solve your memory problems.</p>
<p><span id="more-1050"></span></p>
<h2>Batch learning</h2>
<p>A couple weeks ago I started exploring the possibility to train a machine learning classifier directly on a microcontroller. Since I like SVM, <a href="/2020/03/so-you-want-to-train-an-ml-classifier-directly-on-an-arduino-board">I ported the simplified SVM SMO (Sequential Minimal Optimization) algorithm</a> to plain C, ready to be deployed to embedded devices.</p>
<p>Now, that kind of algorithm works in the so-called &quot;batch-mode&quot;: it needs all the training data to be available in memory to learn.</p>
<p>This may be a limiting factor on resource-constrained devices, since it poses an upper bound to the number of samples you can train on. And when working with high-dimensional datasets, the number of samples could be not enough to achieve good accuracy.</p>
<h2>Enter incremental learning</h2>
<p>To solve this limitation, you need a totally different kind of learning algorithms: you need incremental (a.k.a online a.k.a out of core) learning.</p>
<p>Incremental learning works by inspecting one training sample at a time, instead of all at once.</p>
<p>The clear advantage is that you have a tiny memory footprint. And this is a <strong>huge</strong> advantage.</p>
<p>The clear disadvantage is that you don't have the &quot;big picture&quot; of your data, so:</p>
<ul>
<li>the end result will probably be affected by the order of presentation of the samples</li>
<li>you may not be able to achieve top accuracy</li>
</ul>
<h2>Passive-aggressive classifier</h2>
<p>Passive-aggressive classification is one of the available incremental learning algorithms and it is very simple to implement, since it has a closed-form update rule.</p>
<p>Please refer to this <a href="https://www.bonaccorso.eu/2017/10/06/ml-algorithms-addendum-passive-aggressive-algorithms/">short explanation on Passive-aggressive classifiers</a> for a nice description with images.</p>
<p>The core concept is that the classifier adjusts it weight vector for each mis-classified training sample it receives, trying to get it correct.</p>
<p><img src="https://eloquentarduino.github.io/wp-content/uploads/2020/04/passive-aggressive-classifier.png" alt="Passive aggressive classifier" /></p>
<h2>Benchmarks</h2>
<p>I run a couple benchmark on my Esp32 to assess both accuracy and training time.</p>
<p>First of all: <strong>it is fast!</strong>. When I say it is fast I mean it takes ~1ms to train on 400 samples x 30 features each.</p>
<p>Talking about accuracy instead... Uhm...</p>
<p>Accuracy vary. <strong>Greatly</strong>. </p>
<p>You can achieve 100% on some datasets. </p>
<p>And 40% on others. But on those same datasets you can achieve &gt;85% if training on a different number of samples. Or in a different order.</p>
<p>I guess this is the tradeoff for such a simple and space-efficient algorithm.</p>
<p>I report my results in the following table. It is not meant to be an exhaustive benchmark of the classifier, since those number will vary based on the order of presentation, but still you can get an idea of what it is able to achieve.</p>
<table>
<thead>
<tr>
<th>Dataset size</th>
<th style="text-align: center;">Train samples</th>
<th style="text-align: right;">Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td>BREAST CANCER</td>
<td style="text-align: center;"></td>
<td style="text-align: right;"></td>
</tr>
<tr>
<td>567 samples</td>
<td style="text-align: center;">20</td>
<td style="text-align: right;">62</td>
</tr>
<tr>
<td>30 features</td>
<td style="text-align: center;">40</td>
<td style="text-align: right;">37</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">60</td>
<td style="text-align: right;">63</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">100</td>
<td style="text-align: right;">39</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">150</td>
<td style="text-align: right;">38</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">200</td>
<td style="text-align: right;">64</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">250</td>
<td style="text-align: right;">61</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">300</td>
<td style="text-align: right;">69</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">350</td>
<td style="text-align: right;">73</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">400</td>
<td style="text-align: right;">85</td>
</tr>
<tr>
<td>IRIS</td>
<td style="text-align: center;"></td>
<td style="text-align: right;"></td>
</tr>
<tr>
<td>100 samples</td>
<td style="text-align: center;">10</td>
<td style="text-align: right;">50</td>
</tr>
<tr>
<td>4 features</td>
<td style="text-align: center;">20</td>
<td style="text-align: right;">51</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">40</td>
<td style="text-align: right;">100</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">60</td>
<td style="text-align: right;">100</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">80</td>
<td style="text-align: right;">100</td>
</tr>
<tr>
<td>DIGITS</td>
<td style="text-align: center;"></td>
<td style="text-align: right;"></td>
</tr>
<tr>
<td>358 samples</td>
<td style="text-align: center;">20</td>
<td style="text-align: right;">98</td>
</tr>
<tr>
<td>64 features</td>
<td style="text-align: center;">40</td>
<td style="text-align: right;">98</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">60</td>
<td style="text-align: right;">99</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">100</td>
<td style="text-align: right;">100</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">150</td>
<td style="text-align: right;">100</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">200</td>
<td style="text-align: right;">99</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">250</td>
<td style="text-align: right;">98</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">300</td>
<td style="text-align: right;">95</td>
</tr>
<tr>
<td>CLEVELAND HEART DISEASE</td>
<td style="text-align: center;"></td>
<td style="text-align: right;"></td>
</tr>
<tr>
<td>212 samples</td>
<td style="text-align: center;">20</td>
<td style="text-align: right;">76</td>
</tr>
<tr>
<td>13 features</td>
<td style="text-align: center;">40</td>
<td style="text-align: right;">24</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">60</td>
<td style="text-align: right;">77</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">100</td>
<td style="text-align: right;">19</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">120</td>
<td style="text-align: right;">82</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">140</td>
<td style="text-align: right;">78</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">180</td>
<td style="text-align: right;">88</td>
</tr>
</tbody>
</table>
<h2>Time to code</h2>
<p>Here I'll report an extract of the example code you can find on <a href="https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/PassiveAggressiveExample/PassiveAggressiveExample.ino">Github</a> for this classifier.</p>
<pre><code class="language-c">#include &quot;EloquentPassiveAggressiveClassifier.h&quot;
#include &quot;EloquentAccuracyScorer.h&quot;
#include &quot;iris.h&quot;

using namespace Eloquent::ML;

void loop() {
    int trainSamples;
    PassiveAggressiveClassifier&lt;FEATURES_DIM&gt; clf;
    AccuracyScorer scorer;

    trainSamples = readSerialNumber(&quot;How many samples will you use as training?&quot;, DATASET_SIZE - 2);

    if (trainSamples == 0)
        return;

    clf.setC(1);

    // train
    for (uint16_t i = 0; i &lt; trainSamples; i++)
        clf.fitOne(X[i], y[i]);

    // predict
    for (uint16_t i = trainSamples; i &lt; DATASET_SIZE; i++) {
        int predicted = clf.predict(X[i]);
        int actual = y[i] &gt; 0 ? 1 : -1;

        scorer.scoreOne(actual, predicted);
    }

    Serial.print(&quot;Accuracy: &quot;);
    Serial.print(round(100 * scorer.accuracy()));
    Serial.print(&quot;% out of &quot;);
    Serial.print(scorer.support());
    Serial.println(&quot; predictions&quot;);
}</code></pre>
<hr />
<p>On the <a href="https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/PassiveAggressiveExample/PassiveAggressiveExample.ino">project page</a> you will find the code to reproduce these numbers.</p>
<hr />
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/04/passive-aggressive-classifier-for-embedded-devices/">Passive-aggressive classifier for embedded devices</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>How to train a color classification Machine learning classifier directly on your Arduino board</title>
		<link>https://eloquentarduino.github.io/2020/03/how-to-train-a-color-classification-machine-learning-classifier-directly-on-your-arduino-board/</link>
		
		<dc:creator><![CDATA[simone]]></dc:creator>
		<pubDate>Sat, 28 Mar 2020 19:02:53 +0000</pubDate>
				<category><![CDATA[Arduino Machine learning]]></category>
		<category><![CDATA[Programming]]></category>
		<category><![CDATA[microml]]></category>
		<guid isPermaLink="false">https://eloquentarduino.github.io/?p=988</guid>

					<description><![CDATA[<p>In the previous post we learnt it is possible to train a Machine learning classifier directly on a microcontroller. In this post we'll look into how to do it to classify colors. This will be an hands-on guide, so let's walk throughout each step you need to complete to run the example. I setup this [&#8230;]</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/03/how-to-train-a-color-classification-machine-learning-classifier-directly-on-your-arduino-board/">How to train a color classification Machine learning classifier directly on your Arduino board</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>In the <a href="/2020/03/so-you-want-to-train-an-ml-classifier-directly-on-an-arduino-board">previous post</a> we learnt it is possible to train a Machine learning classifier directly on a microcontroller. In this post we'll look into how to do it to classify colors.</p>
<p><span id="more-988"></span></p>
<p>This will be an hands-on guide, so let's walk throughout each step you need to complete to run the example. </p>
<p>I setup this very example as a basis for your future projects, so you can easily swap the color classification task for any other one you could think of.</p>
<h2>Definitions</h2>
<pre><code class="language-c">#ifdef ESP32
#define min(a, b) (a) &lt; (b) ? (a) : (b)
#define max(a, b) (a) &gt; (b) ? (a) : (b)
#define abs(x) ((x) &gt; 0 ? (x) : -(x))
#endif

#include &lt;EloquentSVMSMO.h&gt;
#include &quot;RGB.h&quot;

#define MAX_TRAINING_SAMPLES 20
#define FEATURES_DIM 3

using namespace Eloquent::ML;

int numSamples;
RGB rgb(2, 3, 4);
float X_train[MAX_TRAINING_SAMPLES][FEATURES_DIM];
int y_train[MAX_TRAINING_SAMPLES];
SVMSMO&lt;FEATURES_DIM&gt; classifier(linearKernel);</code></pre>
<p>When training a classifier on your microcontroller there are some things that are mandatory:</p>
<ol>
<li><code>#include &lt;EloquentSVMSMO.h&gt;</code>: this is the library that implements the SVM learning algorithm</li>
<li><code>X_train</code>: this is a matrix where each row represents a training sample. You will need to keep this data always with you, since it's required also during the inference</li>
<li><code>y_train</code>: this array contains, for each training sample, the class it belongs to: 1 or -1</li>
<li><code>linearKernel</code>: this is the kernel function for the SVM classifier (you can read more <a href="#">here</a>). You can pass your own kernel other than linear (for example <code>poly</code> or <code>rbf</code>)</li>
</ol>
<p>In this specific example, we're using the <code>RGB</code> class to handle the TCS3200 sensor reading, but this will change based on the dataset you want to train on. Also, since our features are going to be the R, G and B components of a color, <code>FEATURES_DIM</code> is set to 3.</p>
<h2>Setup</h2>
<pre><code class="language-c">void setup() {
    Serial.begin(115200);
    rgb.begin();

    classifier.setC(5);
    classifier.setTol(1e-5);
    classifier.setMaxIter(10000);
}</code></pre>
<p>The setup does not contain any logic really. You can use this part to configure the parameters of the classifier:</p>
<ul>
<li><code>C</code>: &quot;The C parameter tells the SVM optimization how much you want to avoid misclassifying each training example. For large values of C, the optimization will choose a smaller-margin hyperplane if that hyperplane does a better job of getting all the training points classified correctly. Conversely, a very small value of C will cause the optimizer to look for a larger-margin separating hyperplane, even if that hyperplane misclassifies more points&quot; (quoted from <a href="https://stats.stackexchange.com/questions/31066/what-is-the-influence-of-c-in-svms-with-linear-kernel">stackexchange</a>)</li>
<li><code>tol</code>: &quot;The tol parameter is a setting for the SVM's tolerance in optimization. Recall that <code>yi(xi.w+b)-1 &gt;= 0</code>. For an SVM to be valid, all values must be greater than or equal to 0, and at least one value on each side needs to be &quot;equal&quot; to 0, which will be your support vectors. Since it is highly unlikely that you will actually get values equal perfectly to 0, you set tolerance to allow a bit of wiggle room.&quot; (quoted from <a href="https://pythonprogramming.net/support-vector-machine-parameters-machine-learning-tutorial/">pythonprogramming</a>)</li>
<li><code>maxIter</code>: set an upper bound to the number of iterations the algorithm can take to converge</li>
<li><code>passes</code>: max # of times to iterate over α’s without changing</li>
<li><code>alphaTol</code>: alfpha coefficients determine which samples from the training set are to be considered support vectors and so be included during the inference procedure. This value discards support vectors with an alpha too small to be noticeable.</li>
</ul>
<h2>Fit</h2>
<pre><code class="language-c">else if (command == &quot;fit&quot;) {
        Serial.print(&quot;How many samples will you record? &quot;);
        numSamples = readSerialNumber();

        for (int i = 0; i &lt; numSamples; i++) {
            Serial.print(i + 1);
            Serial.print(&quot;/&quot;);
            Serial.print(numSamples);
            Serial.println(&quot; Which class does the sample belongs to, 1 or -1?&quot;);
            y_train[i] = readSerialNumber() &gt; 0 ? 1 : -1;
            getFeatures(X_train[i]);
        }

        Serial.print(&quot;Start training... &quot;);
        classifier.fit(X_train, y_train, numSamples);
        Serial.println(&quot;Done&quot;);
    }</code></pre>
<p>This is the core of the project. Here we are loading the samples to train our classifier &quot;live&quot; on the board.</p>
<p>Since this is an interactive demo, the program prompts us to define how many samples we'll load and, one by one, which class they belong to.</p>
<p>Now there are a few important things to keep in mind:</p>
<ul>
<li><code>numSamples</code>: sadly, C has no easy way to know the size of an array, so we have to be explicit about it. To train the classifier, it is mandatory that you do know I many samples you're passing to it</li>
<li><code>getFeatures()</code> is the function that reads the training sample. It is actually a &quot;proxy&quot; to your own custom logic: in this example it reads the TCS3200, in your project it could read an accelerometer or the like.</li>
<li><code>fit()</code>: this is where the magic happens. With this single line of code you're training the SVM on the training data; when the functions ends, the classifier will have updated its internal state with the coefficients it needs to classify new samples</li>
</ul>
<h2>Predict</h2>
<p>ColorClassificationTrainingExample.ino</p>
<pre><code class="language-c">else if (command == &quot;predict&quot;) {
        int label;
        float x[FEATURES_DIM];

        getFeatures(x);
        Serial.print(&quot;Predicted label is &quot;);
        Serial.println(classifier.predict(X_train, x));
    }</code></pre>
<p>Now that our classifier has been trained, we can finally make use of it to classify new samples.</p>
<p>As easy as it can be, you just call its <code>predict</code> method.</p>
<div class="infobox">As you can see, the <code>predict</code> method requires the <code>X_train</code> matrix other than the new sample vector</div>
<p>And that's it: you can now complete your Machine learning task on your microcontroller from start to end, without the need of a PC.</p>
<!-- Begin Mailchimp Signup Form -->
<div id="mc_embed_signup">
<form action="https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	<h2 style="margin: 0; text-align: center">Finding this content useful?</h2>
<div class="mc-field-group">
	<input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="join the monthly newsletter">
</div>
	<div id="mce-responses" class="clear">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_f0eaedd94d554cf2ee781742a_37d3496031" tabindex="-1" value=""></div>
    <div class="clear" style="position: relative; top: 8px"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->
<hr />
<p>Check the full project code on <a href="https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/ColorClassificationTrainingExample/ColorClassificationTrainingExample.ino">Github</a></p>
<hr />
<h2>Full example</h2>
<p>ColorClassificationTrainingExample.ino</p>
<pre><code class="language-c">#include &lt;EloquentSVMSMO.h&gt;
#include &quot;RGB.h&quot;

#define MAX_TRAINING_SAMPLES 20
#define FEATURES_DIM 3

using namespace Eloquent::ML;

int numSamples;
RGB rgb(2, 3, 4);
float X_train[MAX_TRAINING_SAMPLES][FEATURES_DIM];
int y_train[MAX_TRAINING_SAMPLES];
SVMSMO&lt;FEATURES_DIM&gt; classifier(linearKernel);

void setup() {
    Serial.begin(115200);
    rgb.begin();

    classifier.setC(5);
    classifier.setTol(1e-5);
    classifier.setMaxIter(10000);
}

void loop() {
    if (!Serial.available()) {
        delay(100);
        return;
    }

    String command = Serial.readStringUntil(&#039;\n&#039;);

    if (command == &quot;help&quot;) {
        Serial.println(&quot;Available commands:&quot;);
        Serial.println(&quot;\tfit: train the classifier on a new set of samples&quot;);
        Serial.println(&quot;\tpredict: classify a new sample&quot;);
        Serial.println(&quot;\tinspect: print X_train and y_train&quot;);
    }
    else if (command == &quot;fit&quot;) {
        Serial.print(&quot;How many samples will you record? &quot;);
        numSamples = readSerialNumber();

        for (int i = 0; i &lt; numSamples; i++) {
            Serial.print(i + 1);
            Serial.print(&quot;/&quot;);
            Serial.print(numSamples);
            Serial.println(&quot; Which class does the sample belongs to, 1 or -1?&quot;);
            y_train[i] = readSerialNumber() &gt; 0 ? 1 : -1;
            getFeatures(X_train[i]);
        }

        Serial.print(&quot;Start training... &quot;);
        classifier.fit(X_train, y_train, numSamples);
        Serial.println(&quot;Done&quot;);
    }
    else if (command == &quot;predict&quot;) {
        int label;
        float x[FEATURES_DIM];

        getFeatures(x);
        Serial.print(&quot;Predicted label is &quot;);
        Serial.println(classifier.predict(X_train, x));
    }
    else if (command == &quot;inspect&quot;) {
        for (int i = 0; i &lt; numSamples; i++) {
            Serial.print(&quot;[&quot;);
            Serial.print(y_train[i]);
            Serial.print(&quot;] &quot;);

            for (int j = 0; j &lt; FEATURES_DIM; j++) {
                Serial.print(X_train[i][j]);
                Serial.print(&quot;, &quot;);
            }

            Serial.println();
        }
    }
}

/**
 *
 * @return
 */
int readSerialNumber() {
    while (!Serial.available()) delay(1);

    return Serial.readStringUntil(&#039;\n&#039;).toInt();
}

/**
 * Get features for new sample
 * @param x
 */
void getFeatures(float x[FEATURES_DIM]) {
    rgb.read(x);

    for (int i = 0; i &lt; FEATURES_DIM; i++) {
        Serial.print(x[i]);
        Serial.print(&quot;, &quot;);
    }

    Serial.println();
}</code></pre>
<p>RGB.h</p>
<pre><code class="language-c">#pragma once

/**
 * Wrapper for RGB color sensor
 */
class RGB {
    public:
        RGB(uint8_t s2, uint8_t s3, uint8_t out) :
            _s2(s2),
            _s3(s3),
            _out(out) {

        }

        /**
         *
         */
        void begin() {
            pinMode(_s2, OUTPUT);
            pinMode(_s3, OUTPUT);
            pinMode(_out, INPUT);
        }

        /**
         *
         * @param x
         */
        void read(float x[3]) {
            x[0] = readComponent(LOW, LOW);
            x[1] = readComponent(HIGH, HIGH);
            x[2] = readComponent(LOW, HIGH);
        }

    protected:
        uint8_t _s2;
        uint8_t _s3;
        uint8_t _out;

        /**
         *
         * @param s2
         * @param s3
         * @return
         */
        int readComponent(bool s2, bool s3) {
            delay(10);
            digitalWrite(_s2, s2);
            digitalWrite(_s3, s3);

            return pulseIn(_out, LOW);
        }
};</code></pre>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/03/how-to-train-a-color-classification-machine-learning-classifier-directly-on-your-arduino-board/">How to train a color classification Machine learning classifier directly on your Arduino board</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>How to train a IRIS classification Machine learning classifier directly on your Arduino board</title>
		<link>https://eloquentarduino.github.io/2020/03/how-to-train-a-iris-classification-machine-learning-classifier-directly-on-your-arduino-board/</link>
		
		<dc:creator><![CDATA[simone]]></dc:creator>
		<pubDate>Sat, 28 Mar 2020 18:02:09 +0000</pubDate>
				<category><![CDATA[Arduino Machine learning]]></category>
		<category><![CDATA[microml]]></category>
		<category><![CDATA[svm]]></category>
		<guid isPermaLink="false">https://eloquentarduino.github.io/?p=1008</guid>

					<description><![CDATA[<p>In this hands-on guide about on-board SVM training we're going to see a classifier in action, training it on the Iris dataset and evaluating its performance. What we'll make In this demo project we're going to take a know dataset (iris flowers) and interactively train an SVM classifier on it, adjusting the number of samples [&#8230;]</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/03/how-to-train-a-iris-classification-machine-learning-classifier-directly-on-your-arduino-board/">How to train a IRIS classification Machine learning classifier directly on your Arduino board</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>In this hands-on guide about <a href="/2020/03/so-you-want-to-train-an-ml-classifier-directly-on-an-arduino-board">on-board SVM training</a> we're going to see a classifier in action, training it on the Iris dataset and evaluating its performance.</p>
<p><span id="more-1008"></span></p>
<h2>What we'll make</h2>
<p>In this demo project we're going to take a know dataset (<a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">iris flowers</a>) and interactively train an SVM classifier on it, adjusting the number of samples to see the effects on both training time, inference time and accuracy.</p>
<h2>Definitions</h2>
<pre><code class="language-c">#ifdef ESP32
#define min(a, b) (a) &lt; (b) ? (a) : (b)
#define max(a, b) (a) &gt; (b) ? (a) : (b)
#define abs(x) ((x) &gt; 0 ? (x) : -(x))
#endif

#include &lt;EloquentSVMSMO.h&gt;
#include &quot;iris.h&quot;

#define TOTAL_SAMPLES (POSITIVE_SAMPLES + NEGATIVE_SAMPLES)

using namespace Eloquent::ML;

float X_train[TOTAL_SAMPLES][FEATURES_DIM];
float X_test[TOTAL_SAMPLES][FEATURES_DIM];
int y_train[TOTAL_SAMPLES];
int y_test[TOTAL_SAMPLES];
SVMSMO&lt;FEATURES_DIM&gt; classifier(linearKernel);</code></pre>
<p>First of all we need to include a couple files, namely <code>EloquentSVMSMO.h</code> for the SVM classifier and <code>iris.h</code> for the dataset.</p>
<p><code>iris.h</code> defines a couple constants:</p>
<ul>
<li><code>FEATURES_DIM</code>: the number of features each sample has (4 in this case)</li>
<li><code>POSITIVE_SAMPLES</code>: the number of samples that belong to the positive class (50)</li>
<li><code>NEGATIVE_SAMPLES</code>: the number of samples that belong to the negative class (50)</li>
</ul>
<p>The we declare the array that hold the data: <code>X_train</code> and <code>y_train</code> for the training process, <code>X_test</code> and <code>y_test</code> for the inference process.</p>
<h2>Setup</h2>
<pre><code class="language-c">void setup() {
    Serial.begin(115200);
    delay(5000);

    // configure classifier
    classifier.setC(5);
    classifier.setTol(1e-5);
    classifier.setMaxIter(10000);
}</code></pre>
<p>Here we just set a few parameters for the classifier. You could actually skip this step in this demo, since the defaults will work well. Those lines are there so you know you can tweak them, if needed.</p>
<p>Please refer to the <a href="/2020/03/how-to-train-a-color-classification-machine-learning-classifier-directly-on-your-arduino-board">demo for color classification</a> for an explanation of each parameter.</p>
<h2>Interactivity</h2>
<pre><code class="language-c">void loop() {
    int positiveSamples = readSerialNumber(&quot;How many positive samples will you use for training? &quot;, POSITIVE_SAMPLES);

    if (positiveSamples &gt; POSITIVE_SAMPLES - 1) {
        Serial.println(&quot;Too many positive samples entered. All but one will be used instead&quot;);
        positiveSamples = POSITIVE_SAMPLES - 1;
    }

    int negativeSamples = readSerialNumber(&quot;How many negative samples will you use for training? &quot;, NEGATIVE_SAMPLES);

    if (negativeSamples &gt; NEGATIVE_SAMPLES - 1) {
        Serial.println(&quot;Too many negative samples entered. All but one will be used instead&quot;);
        negativeSamples = NEGATIVE_SAMPLES - 1;
    }

    loadDataset(positiveSamples, negativeSamples);

    // ...
}

/**
 * Ask the user to enter a numeric value
 */
int readSerialNumber(String prompt, int maxAllowed) {
    Serial.print(prompt);
    Serial.print(&quot; (&quot;);
    Serial.print(maxAllowed);
    Serial.print(&quot; max) &quot;);

    while (!Serial.available()) delay(1);

    int n = Serial.readStringUntil(&#039;\n&#039;).toInt();

    Serial.println(n);

    return n;
}

/**
 * Divide training and test data
 */
void loadDataset(int positiveSamples, int negativeSamples) {
    int positiveTestSamples = POSITIVE_SAMPLES - positiveSamples;

    for (int i = 0; i &lt; positiveSamples; i++) {
        memcpy(X_train[i], X_positive[i], FEATURES_DIM);
        y_train[i] = 1;
    }

    for (int i = 0; i &lt; negativeSamples; i++) {
        memcpy(X_train[i + positiveSamples], X_negative[i], FEATURES_DIM);
        y_train[i + positiveSamples] = -1;
    }

    for (int i = 0; i &lt; positiveTestSamples; i++) {
        memcpy(X_test[i], X_positive[i + positiveSamples], FEATURES_DIM);
        y_test[i] = 1;
    }

    for (int i = 0; i &lt; NEGATIVE_SAMPLES - negativeSamples; i++) {
        memcpy(X_test[i + positiveTestSamples], X_negative[i + negativeSamples], FEATURES_DIM);
        y_test[i + positiveTestSamples] = -1;
    }
}</code></pre>
<p>The code above is a preliminary step where you're asked to enter how many samples you will use for training of both positive and negative classes.</p>
<p>This way you can have multiple run of benchmarking without the need to re-compile and re-upload the sketch.</p>
<p>It also shows that the training process can be &quot;dynamic&quot;, in the sense that you can tweak it at runtime as per your need.</p>
<h2>Training</h2>
<pre><code class="language-c">time_t start = millis();
classifier.fit(X_train, y_train, positiveSamples + negativeSamples);
Serial.print(&quot;It took &quot;);
Serial.print(millis() - start);
Serial.print(&quot;ms to train on &quot;);
Serial.print(positiveSamples + negativeSamples);
Serial.println(&quot; samples&quot;);</code></pre>
<p>Training is actually a one line operation. Here we'll also logging how much time it takes to train.</p>
<h3>Predicting</h3>
<pre><code class="language-c">void loop() {
    // ...

    int tp = 0;
    int tn = 0;
    int fp = 0;
    int fn = 0;

    start = millis();

    for (int i = 0; i &lt; TOTAL_SAMPLES - positiveSamples - negativeSamples; i++) {
        int y_pred = classifier.predict(X_train, X_test[i]);
        int y_true = y_test[i];

        if (y_pred == y_true &amp;&amp; y_pred ==  1) tp += 1;
        if (y_pred == y_true &amp;&amp; y_pred == -1) tn += 1;
        if (y_pred != y_true &amp;&amp; y_pred ==  1) fp += 1;
        if (y_pred != y_true &amp;&amp; y_pred == -1) fn += 1;
    }

    Serial.print(&quot;It took &quot;);
    Serial.print(millis() - start);
    Serial.print(&quot;ms to test on &quot;);
    Serial.print(TOTAL_SAMPLES - positiveSamples - negativeSamples);
    Serial.println(&quot; samples&quot;);

    printConfusionMatrix(tp, tn, fp, fn);
}

/**
 * Dump confusion matrix to Serial monitor
 */
void printConfusionMatrix(int tp, int tn, int fp, int fn) {
    Serial.print(&quot;Overall accuracy &quot;);
    Serial.print(100.0 * (tp + tn) / (tp + tn + fp + fn));
    Serial.println(&quot;%&quot;);
    Serial.println(&quot;Confusion matrix&quot;);
    Serial.print(&quot;          | Predicted 1 | Predicted -1 |\n&quot;);
    Serial.print(&quot;----------------------------------------\n&quot;);
    Serial.print(&quot;Actual  1 |      &quot;);
    Serial.print(tp);
    Serial.print(&quot;     |      &quot;);
    Serial.print(fn);
    Serial.print(&quot;       |\n&quot;);
    Serial.print(&quot;----------------------------------------\n&quot;);
    Serial.print(&quot;Actual -1 |      &quot;);
    Serial.print(fp);
    Serial.print(&quot;      |      &quot;);
    Serial.print(tn);
    Serial.print(&quot;       |\n&quot;);
    Serial.print(&quot;----------------------------------------\n\n\n&quot;);
}</code></pre>
<p>Finally we can run the classification on our test set and get the overall accuracy.</p>
<p>We also print the <a href="https://en.wikipedia.org/wiki/Confusion_matrix">confusion matrix</a> to double-check each class accuracy.</p>
<!-- Begin Mailchimp Signup Form -->
<div id="mc_embed_signup">
<form action="https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	<h2 style="margin: 0; text-align: center">Finding this content useful?</h2>
<div class="mc-field-group">
	<input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="join the monthly newsletter">
</div>
	<div id="mce-responses" class="clear">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_f0eaedd94d554cf2ee781742a_37d3496031" tabindex="-1" value=""></div>
    <div class="clear" style="position: relative; top: 8px"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->
<hr />
<p>Check the full project code on <a href="https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/IrisClassificationTrainingExample/IrisClassificationTrainingExample.ino">Github</a> where you'll also find another dataset to test, which is characterized by a number of features much higher (30 instead of 4).</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/03/how-to-train-a-iris-classification-machine-learning-classifier-directly-on-your-arduino-board/">How to train a IRIS classification Machine learning classifier directly on your Arduino board</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>So you want to train an ML classifier directly on an Arduino board?</title>
		<link>https://eloquentarduino.github.io/2020/03/so-you-want-to-train-an-ml-classifier-directly-on-an-arduino-board/</link>
		
		<dc:creator><![CDATA[simone]]></dc:creator>
		<pubDate>Sat, 28 Mar 2020 17:03:35 +0000</pubDate>
				<category><![CDATA[Arduino Machine learning]]></category>
		<category><![CDATA[Programming]]></category>
		<category><![CDATA[microml]]></category>
		<guid isPermaLink="false">https://eloquentarduino.github.io/?p=982</guid>

					<description><![CDATA[<p>As of now, we know it is possible to run Machine learning inference on tiny microcontrollers thanks to Tensorflow for Micro and my very own library MicroML. What if you could train a classifier directly on the microcontroller, too? When I first started this journey in the world of Machine learning on microcontrollers, one fact [&#8230;]</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/03/so-you-want-to-train-an-ml-classifier-directly-on-an-arduino-board/">So you want to train an ML classifier directly on an Arduino board?</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>As of now, we know it is possible to run Machine learning inference on tiny microcontrollers thanks to <a href="https://www.tensorflow.org/lite/microcontrollers">Tensorflow for Micro</a> and my very own library <a href="https://github.com/eloquentarduino/micromlgen">MicroML</a>. What if you could <strong>train</strong> a classifier directly on the microcontroller, too?</p>
<p><img src="https://eloquentarduino.github.io/wp-content/uploads/2020/03/Onboard-IRIS-dataset-training-time.png" alt="Onboard IRIS dataset training time" /></p>
<p><span id="more-982"></span></p>
<p>When I first started this journey in the world of Machine learning on microcontrollers, one fact was set in stone for me: you train your classifier once and for all on a PC, then deploy it to your microcontroller.</p>
<p>As simple as this.</p>
<p>Training is a heavy process, requires lots of computations and memory. You just want a machine as powerful as possible to carry out this task as fast as possible.</p>
<p>Moreover, it is a one-time task: once your classifier has been trained, it needs not to be updated anymore.</p>
<p>And this yield true until now.</p>
<p>Until my reader <a href="https://github.com/joaocarvalhoopen">Joao Carvalho</a>, in the comments on the post about <a href="/2020/02/even-smaller-machine-learning-models-for-your-mcu/">an alternative to SVM which produces much smaller models</a> that I strongly invite you to read, challenged me with this idea of running the SVM training directly on the microcontroller. </p>
<p>In the past I replied <em>&quot;No way&quot;</em> to people asking about this topic on forums, but Joao was so kind to link me a <a href="https://github.com/karpathy/svmjs/blob/master/lib/svm.js">Javascript implementation</a> of the <a href="https://github.com/karpathy/svmjs/blob/master/test/smo.pdf">simplified SVM SMO (Sequential Minimal Optimization) algorithm</a>.</p>
<p>At a first glance it looked quite easy to port from Javascript to C, so I gave it a try.</p>
<p>And in fact it only took me 30 minutes to get it working on my PC.</p>
<p>Then I deployed it to my ESP32 and... <strong>it worked</strong>!</p>
<p>My first try was with 10 samples from the the IRIS dataset: it only took almost no time to train.</p>
<p>But I know SVM training and inferencing time grows rapidly with the number of training samples.</p>
<p>Execution time will be the most limiting factor for this kind of task, so I created a benchmarking setup to evaluate the performance of the algorithm on different dataset sizes and features dimensions.<br />
The results are summarized in the following table and plots.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Features size</th>
<th style="text-align: center;">Training size</th>
<th style="text-align: center;">Training time (ms)</th>
<th style="text-align: center;">Unit inference time (ms)</th>
<th style="text-align: center;">Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0,011</td>
<td style="text-align: center;">80</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">0,013</td>
<td style="text-align: center;">85</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">0,014</td>
<td style="text-align: center;">90</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">38</td>
<td style="text-align: center;">0,017</td>
<td style="text-align: center;">91</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">47</td>
<td style="text-align: center;">0,020</td>
<td style="text-align: center;">86</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">60</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">0,025</td>
<td style="text-align: center;">87</td>
</tr>
<tr>
<td style="text-align: center;">30</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">0,014</td>
<td style="text-align: center;">71</td>
</tr>
<tr>
<td style="text-align: center;">30</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">0,017</td>
<td style="text-align: center;">61</td>
</tr>
<tr>
<td style="text-align: center;">30</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">3500</td>
<td style="text-align: center;">0,020</td>
<td style="text-align: center;">66</td>
</tr>
<tr>
<td style="text-align: center;">30</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">20000</td>
<td style="text-align: center;">0,025</td>
<td style="text-align: center;">85</td>
</tr>
<tr>
<td style="text-align: center;">30</td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">32800</td>
<td style="text-align: center;">0,033</td>
<td style="text-align: center;">83</td>
</tr>
<tr>
<td style="text-align: center;">30</td>
<td style="text-align: center;">60</td>
<td style="text-align: center;">71400</td>
<td style="text-align: center;">0,050</td>
<td style="text-align: center;">80</td>
</tr>
</tbody>
</table>
<p><small>* all benchmark are obtained on an ESP32 board</small><br />
<small>** the inference took actually sometimes less than 1ms to run for all the test samples, so it was rounded to 1ms and divided by the number of samples</small></p>
<p><img src="https://eloquentarduino.github.io/wp-content/uploads/2020/03/Onboard-IRIS-dataset-training-time.png" alt="Onboard IRIS dataset training time. Features dim = 4" /></p>
<p><img src="https://eloquentarduino.github.io/wp-content/uploads/2020/03/Onboard-Breast-cancer-dataset-training-time.png" alt="Onboard Breast cancer dataset training time. Features dim = 30" /></p>
<p>We can see from the table that for the Iris dataset, which has 4-dimensional features, the training process is quite fast: 80ms to train on 60 samples.</p>
<p>Things become much different when training on the Breast cancer dataset, with its 30 features per sample. Now we're talking abouts <em>seconds</em> to train and even minutes when increasing the number of samples to 60.</p>
<p>Fortunately the inference time stays almost flat, so you will have real-time predictions.</p>
<div class="watchout">I run the Iris benchmark on a Seeedstudio Xiao M0 board (32bit 48MHz processor), too. It took 7s to train on 60 samples vs 80ms it took on the ESP32. It is clear some boards are better than others for this task</div>
<!-- Begin Mailchimp Signup Form -->
<div id="mc_embed_signup">
<form action="https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	<h2 style="margin: 0; text-align: center">Finding this content useful?</h2>
<div class="mc-field-group">
	<input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="join the monthly newsletter">
</div>
	<div id="mce-responses" class="clear">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_f0eaedd94d554cf2ee781742a_37d3496031" tabindex="-1" value=""></div>
    <div class="clear" style="position: relative; top: 8px"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->
<h2>Downsides</h2>
<p>Of course there're downsides: it's not a perfect world.</p>
<h3>Convergence</h3>
<div class="watchout">
As <a href="http://cs229.stanford.edu/materials/smo.pdf" target="_blank" rel="noopener noreferrer">the paper</a> reported: "there is one thing to note, <b>the algorithm (the simplified version) is not guaranteed to converge".</b>
</div>
<p>I actually don't know, in practice, what this means. But it sounds like a bad thing.</p>
<h3>Binary classification only</h3>
<p>As of now this algorithm can only do binary classification.</p>
<p>I hope to implement multi-class classification in the future with the one-vs-all approach, but I don't really know if it would be too inefficient for a microcontroller to run.</p>
<h3>Declining accuracy</h3>
<p>If you look at the benchmark table above, also, you'll notice the accuracy does not always increase linearly with the training samples size. It seems it reaches an optimum and then starts decreasing.</p>
<p>If you're going to deploy your device in an autonomous scenario, you'll need to monitor your accucary every time you re-train it, or your results are going to go poor.</p>
<p>You should keep track of the optimum you achieved and roll-back to its training set when you register a declining accuracy.</p>
<h3>Memory</h3>
<p>You will need to keep all your training set in memory for the classifier to both learn and predict. This means RAM will be a limiting factor and we know RAM is an expensive resource on microcontrollers.</p>
<p>You will have to find a good enough compromise between the number of features, the number of samples and the accuracy.</p>
<h2>Time to get your hands on</h2>
<p>I created a sample project for you to <a href="/2020/03/how-to-train-a-color-classification-machine-learning-classifier-directly-on-your-arduino-board">train a color classifier</a> with a super simple setup: you will only need a TCS3200 (color sensor) to follow along.</p>
<p>Dont' have a TCS3200? No problem, you can <a href="/2020/03/how-to-train-a-iris-classification-machine-learning-classifier-directly-on-your-arduino-board">train a classifier on the IRIS dataset</a></p>
<p>If you've read so far, please consider letting me know in the comments some useful applications you can think about this new tool. It's a brand new topic for me and I'll appreciate any of your suggestion.</p>
<hr />
<p>Check the project repo on <a href="https://github.com/eloquentarduino/EloquentMicroML">Github</a></p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/03/so-you-want-to-train-an-ml-classifier-directly-on-an-arduino-board/">So you want to train an ML classifier directly on an Arduino board?</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Easy Arduino thermal camera with (ASCII) video streaming</title>
		<link>https://eloquentarduino.github.io/2020/02/easy-arduino-thermal-camera-with-ascii-video-streaming/</link>
		
		<dc:creator><![CDATA[simone]]></dc:creator>
		<pubDate>Sat, 29 Feb 2020 16:20:15 +0000</pubDate>
				<category><![CDATA[Computer vision]]></category>
		<category><![CDATA[Electronics]]></category>
		<category><![CDATA[Eloquent library]]></category>
		<guid isPermaLink="false">https://eloquentarduino.github.io/?p=956</guid>

					<description><![CDATA[<p>Ever wanted to use your thermal camera with Arduino but found it difficult to go beyond the tutorials code? Let's see the easiest possible way to view your thermal camera streaming without an LCD display! MLX90640 thermal camera For Arduino there are essentially two thermal camera available: the AMG8833 and the MLX90640. The AMG8833 is [&#8230;]</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/02/easy-arduino-thermal-camera-with-ascii-video-streaming/">Easy Arduino thermal camera with (ASCII) video streaming</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>Ever wanted to use your thermal camera with Arduino but found it difficult to go beyond the tutorials code? Let's see the easiest possible way to view your thermal camera streaming without an LCD display!</p>
<p><img src="https://eloquentarduino.github.io/wp-content/uploads/2020/02/thermal-image-rgb-vs-ascii.jpg" alt="Arduino thermal image rgb vs ascii" /></p>
<p><span id="more-956"></span></p>
<h2>MLX90640 thermal camera</h2>
<p>For Arduino there are essentially two thermal camera available: the AMG8833 and the MLX90640.</p>
<p>The AMG8833 is 8x8 and the MLX90640 is 32x24.</p>
<p>They're not cheap, it is true.</p>
<p>But if you have to spend money, I strongly advise you to buy the MLX90640: I have one and it's not that accurate. I can't imagine how low definition would be the AMG8833.</p>
<p>If you want to actually get something meaningful from the camera, the AMG8833 won't give you any good results.</p>
<p>Sure, you can do interpolation: interpolation would give you <em>the impression</em> you have a better definition, but you're just &quot;inventing&quot; values you don't actually have.</p>
<p>For demo projects it could be enough. But for any serious application, spend 20$ more and buy an MLX90640.</p>
<h2>MLX90640 eloquent library</h2>
<p>As you may know if you read <a href="/2019/11/how-to-write-clean-arduino-code/">my previous posts</a>, I strongly believe in &quot;eloquent&quot; code, that is code that's as easy as possible to read.</p>
<p>How many lines do you think you need to read a MLX90640 camera? Well, not that much in fact.</p>
<pre><code class="language-cpp">#include &quot;EloquentMLX90640.h&quot;

using namespace Eloquent::Sensors;

float buffer[768];
MLX90640 camera;

void setup() {
  Serial.begin(115200);

  if (!camera.begin()) {
    Serial.println(&quot;Init error&quot;);
    delay(50000);
  }
}

void loop() {
  camera.read(buffer);
  delay(3000);
}</code></pre>
<p>If you skip the declaration lines, you only need a <code>begin()</code> and <code>read()</code> call.</p>
<p>That's it.</p>
<p>What <code>begin()</code> does is to run all of the boilerplate code I mentioned earlier (checking the connection and initializing the parameters).</p>
<p><code>read()</code> populates the buffer you pass as argument with the temperature readings.</p>
<p>From now on, you're free to handle that array as you may like: this is the most flexible way for the library to handle any use-case. It simply does not pose any restriction.</p>
<p>You can find the camera code <a href="#anchor-camera-code">at the end of the page</a> or <a href="https://github.com/eloquentarduino/EloquentArduino/blob/master/examples/ThermalCameraToAsciiArtExample/EloquentMLX90640.h">on Github</a>.</p>
<h2>Printing as ASCII Art</h2>
<p>Now that you have this data, you may want to actually &quot;view&quot; it. Well, that's not an easy task as one may hope.</p>
<p>You will need an LCD if you want to create a standalone product. If you have one, it'll be the best, it's a really cute project to build.</p>
<p>Here's a video from Adafruit that showcases even a 3D-printed case.</p>
<p><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/ZjQEykbvb5w" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>
<p>If you don't have an LCD, though, it is less practical to access your image.</p>
<p>I did this in the past, and it meant creating a Python script reading the serial port every second and updating a plot.<br />
It works, sure, but it's not the most convenient way to handle it.</p>
<p>This is the reason I thought about ASCII art: it is used to draw images in plain text, so you can view them directly in the serial monitor.</p>
<p>Of course they will not be as accurate or representative as RGB images, but can give you an idea of what you're framing in realtime.</p>
<p>I wrote a class to do this. Once imported in your sketch, it is super easy to get it working.</p>
<pre><code class="language-cpp">#include &quot;EloquentAsciiArt.h&quot;

using namespace Eloquent::ImageProcessing;

float buffer[768];
uint8_t bufferBytes[768];
MLX90640 camera;
// we need to specify width and height of the image
AsciiArt&lt;32, 24&gt; art(bufferBytes);

void loop() {
  camera.read(buffer);

  // convert float image to uint8
  for (size_t i = 0; i &lt; 768; i++) {
    // assumes readings are in the range 0-40 degrees
    // change as per your need
    bufferBytes[i] = map(buffer[i], 0, 40, 0, 255);
  }

  // print to Serial with a border of 2 characters, to distinguish one image from the next
  art.print(&amp;Serial, 2);
  delay(2000);
}</code></pre>
<p>As you can see, you need to create an <code>AsciiArt</code> object, map the image pixels in the range <code>0-255</code> and call the <code>print()</code> method: easy peasy!</p>
<p>You can find the ASCII art generator code <a href="#anchor-ascii-art-code">at the end of the page</a> or <a href="https://github.com/eloquentarduino/EloquentArduino/blob/master/examples/ThermalCameraToAsciiArtExample/EloquentAsciiArt.h">on Github</a>.</p>
<p>Here's the result of the sketch. It's a video of me putting my arms at the top of my head, once at a time, then standing up.</p>
<div class="watchout">Resize the Serial Monitor as only a single frame at a time is visble to have a "video streaming" effect</div>
<div style="width: 342px;" class="wp-video"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video class="wp-video-shortcode" id="video-956-1" width="342" height="636" preload="metadata" controls="controls"><source type="video/mp4" src="https://eloquentarduino.github.io/wp-content/uploads/2020/02/Thermal-ascii-speedup.mp4?_=1" /><a href="https://eloquentarduino.github.io/wp-content/uploads/2020/02/Thermal-ascii-speedup.mp4">https://eloquentarduino.github.io/wp-content/uploads/2020/02/Thermal-ascii-speedup.mp4</a></video></div>
<p>Of course the visual effect won't be as impressive as an RGB image, but you can clearly see my figure moving.</p>
<p>The real bad part is the &quot;glitch&quot; you see between each frame when the scrolling happens: this is something I don't know if it's possible to mitigate.</p>
<hr>
<p>Check the full project code on <a href="https://github.com/eloquentarduino/EloquentArduino/blob/master/examples/ThermalCameraToAsciiArtExample" target="_blank" rel="noopener noreferrer">Github</a></p>
<hr />
<div id="anchor-camera-code"></div>
<pre><code class="language-cpp">#pragma once

#include &quot;Wire.h&quot;
#include &quot;MLX90640_API.h&quot;
#include &quot;MLX90640_I2C_Driver.h&quot;

#ifndef TA_SHIFT
//Default shift for MLX90640 in open air
#define TA_SHIFT 8
#endif

namespace Eloquent {
    namespace Sensors {

        enum class MLX90640Status {
            OK,
            NOT_CONNECTED,
            DUMP_ERROR,
            PARAMETER_ERROR,
            FRAME_ERROR
        };

        class MLX90640 {
        public:
            /**
             *
             * @param address
             */
            MLX90640(uint8_t address = 0x33) :
                _address(address),
                _status(MLX90640Status::OK) {

            }

            /**
             *
             * @return
             */
            bool begin() {
                Wire.begin();
                Wire.setClock(400000);

                return isConnected() &amp;&amp; loadParams();
            }

            /**
             *
             * @return
             */
            bool read(float result[768]) {
                for (byte x = 0 ; x &lt; 2 ; x++) {
                    uint16_t frame[834];
                    int status = MLX90640_GetFrameData(_address, frame);

                    if (status &lt; 0)
                        return fail(MLX90640Status::FRAME_ERROR);

                    float vdd = MLX90640_GetVdd(frame, &amp;_params);
                    float Ta = MLX90640_GetTa(frame, &amp;_params);
                    float tr = Ta - TA_SHIFT;
                    float emissivity = 0.95;

                    MLX90640_CalculateTo(frame, &amp;_params, emissivity, tr, result);
                }
            }

        protected:
            uint8_t _address;
            paramsMLX90640 _params;
            MLX90640Status _status;

            /**
             * Test if device is connected
             * @return
             */
            bool isConnected() {
                Wire.beginTransmission(_address);

                if (Wire.endTransmission() == 0) {
                    return true;
                }

                return fail(MLX90640Status::NOT_CONNECTED);
            }

            /**
             *
             * @return
             */
            bool loadParams() {
                uint16_t ee[832];
                int status = MLX90640_DumpEE(_address, ee);

                if (status != 0)
                    return fail(MLX90640Status::DUMP_ERROR);

                status = MLX90640_ExtractParameters(ee, &amp;_params);

                if (status != 0)
                    return fail(MLX90640Status::PARAMETER_ERROR);

                return true;
            }

            /**
             * Mark a failure
             * @param status
             * @return
             */
            bool fail(MLX90640Status status) {
                _status = status;

                return false;
            }
        };
    }
}</code></pre>
<div id="anchor-ascii-art-code"></div>
<pre><code class="language-cpp">#pragma once

#include &quot;Stream.h&quot;

namespace Eloquent {
    namespace ImageProcessing {

        /**
         *
         * @tparam width
         * @tparam height
         */
        template&lt;size_t width, size_t height&gt;
        class AsciiArt {
        public:
            AsciiArt(const uint8_t *data) {
                _data = data;
            }

            /**
             * Get pixel at given coordinates
             * @param x
             * @param y
             * @return
             */
            uint8_t at(size_t x, size_t y) {
                return _data[y * width + x];
            }

            /**
             * Print as ASCII art picture
             * @param stream
             */
            void print(Stream *stream, uint8_t frameSize = 0) {
                const char glyphs[] = &quot; .,:;xyYX&quot;;
                const uint8_t glyphsCount = 9;

                printAsciiArtHorizontalFrame(stream, frameSize);

                for (size_t y = 0; y &lt; height; y++) {
                    // vertical frame
                    for (uint8_t k = 0; k &lt; frameSize; k++)
                        Serial.print(&#039;|&#039;);

                    for (size_t x = 0; x &lt; width; x++) {
                        const uint8_t glyph = floor(((uint16_t) at(x, y)) * glyphsCount / 256);

                        stream-&gt;print(glyphs[glyph]);
                    }

                    // vertical frame
                    for (uint8_t k = 0; k &lt; frameSize; k++)
                        Serial.print(&#039;|&#039;);

                    stream-&gt;print(&#039;\n&#039;);
                }

                printAsciiArtHorizontalFrame(stream, frameSize);
                stream-&gt;flush();
            }

        protected:
            const uint8_t *_data;

            /**
             *
             * @param stream
             * @param frameSize
             */
            void printAsciiArtHorizontalFrame(Stream *stream, uint8_t frameSize) {
                for (uint8_t i = 0; i &lt; frameSize; i++) {
                    for (size_t j = 0; j &lt; width + 2 * frameSize; j++)
                        stream-&gt;print(&#039;-&#039;);
                    stream-&gt;print(&#039;\n&#039;);
                }
            }
        };
    }
}</code></pre>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/02/easy-arduino-thermal-camera-with-ascii-video-streaming/">Easy Arduino thermal camera with (ASCII) video streaming</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></content:encoded>
					
		
		<enclosure url="https://eloquentarduino.github.io/wp-content/uploads/2020/02/Thermal-ascii-speedup.mp4" length="479591" type="video/mp4" />

			</item>
	</channel>
</rss>
