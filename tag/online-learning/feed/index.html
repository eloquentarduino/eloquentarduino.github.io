<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>online-learning &#8211; Eloquent Arduino Blog</title>
	<atom:link href="https://eloquentarduino.github.io/tag/online-learning/feed/" rel="self" type="application/rss+xml" />
	<link>http://eloquentarduino.github.io/</link>
	<description>Machine learning on Arduino, programming &#38; electronics</description>
	<lastBuildDate>Sun, 12 Apr 2020 17:31:52 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.3.2</generator>
	<item>
		<title>Stochastic Gradient Descent on your microcontroller</title>
		<link>https://eloquentarduino.github.io/2020/04/stochastic-gradient-descent-on-your-microcontroller/</link>
		
		<dc:creator><![CDATA[simone]]></dc:creator>
		<pubDate>Fri, 10 Apr 2020 17:43:45 +0000</pubDate>
				<category><![CDATA[Arduino Machine learning]]></category>
		<category><![CDATA[microml]]></category>
		<category><![CDATA[online-learning]]></category>
		<guid isPermaLink="false">https://eloquentarduino.github.io/?p=1062</guid>

					<description><![CDATA[<p>Stochastic gradient descent is a well know algorithm to train classifiers in an incremental fashion: that is, as training samples become available. This saves you critical memory on tiny devices while still achieving top performance! Now you can use it on your microcontroller with ease. A brief recap on Stochastic Gradient Descent If you ever [&#8230;]</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/04/stochastic-gradient-descent-on-your-microcontroller/">Stochastic Gradient Descent on your microcontroller</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>Stochastic gradient descent is a well know algorithm to train classifiers in an incremental fashion: that is, as training samples become available. This saves you critical memory on tiny devices while still achieving <strong>top performance</strong>! Now you can use it on your microcontroller with ease.</p>
<p><span id="more-1062"></span></p>
<h2>A brief recap on Stochastic Gradient Descent</h2>
<p>If you ever worked with Machine learning, you surely know about <a href="https://en.wikipedia.org/wiki/Gradient_descent">Gradient descent</a>: it is an iterative algorithm to optimize a loss function. </p>
<p>It is much general-purpose, in the sense that it is not bound to a particular application, but it has been heavily used in Neural networks in the recent years.</p>
<p>Yet, it can be used as a classifier on its own if you set its loss function as the classification error.</p>
<p><img src="https://mccormickml.com/assets/GradientDescent/GradientDescentOfMSETable.png" alt="Update rule of Gradient descent" /></p>
<p>This is the core update rule of Gradient descent: quite simple.</p>
<p>As you see, there's a summation in the formula: this means we need to cycle through the entire training set to compute the update to the weights.</p>
<p>In case of large datasets, this can be slow or not possible at all.</p>
<p>And requires a lot of memory.</p>
<p>And we don't have memory on microcontrollers.</p>
<p>So we need <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic gradient descent</a>.</p>
<p>Stochastic gradient descent has the same exact update rule, but it is applied on the single training sample.</p>
<p>Imagine the summation goes from 1 to 1, instead of m.</p>
<p>That's it.</p>
<div class="heateor_sss_sharing_container heateor_sss_horizontal_sharing" ss-offset="0" heateor-sss-data-href='https://eloquentarduino.github.io/2020/04/stochastic-gradient-descent-on-your-microcontroller/'><ul class="heateor_sss_sharing_ul"><li class="heateorSssSharingRound"><i style="width:35px;height:35px;border-radius:999px;" alt="Facebook" Title="Facebook" class="heateorSssSharing heateorSssFacebookBackground" onclick='heateorSssPopup("https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Feloquent.blog%2F2020%2F04%2Fstochastic-gradient-descent-on-your-microcontroller%2F")'><ss style="display:block;border-radius:999px;" class="heateorSssSharingSvg heateorSssFacebookSvg"></ss></i></li><li class="heateorSssSharingRound"><i style="width:35px;height:35px;border-radius:999px;" alt="Twitter" Title="Twitter" class="heateorSssSharing heateorSssTwitterBackground" onclick='heateorSssPopup("http://twitter.com/intent/tweet?via=ArduinoEloquent&text=Stochastic%20Gradient%20Descent%20on%20your%20microcontroller&url=http%3A%2F%2Feloquent.blog%2F2020%2F04%2Fstochastic-gradient-descent-on-your-microcontroller%2F")'><ss style="display:block;border-radius:999px;" class="heateorSssSharingSvg heateorSssTwitterSvg"></ss></i></li><li class="heateorSssSharingRound"><i style="width:35px;height:35px;border-radius:999px;" alt="Linkedin" Title="Linkedin" class="heateorSssSharing heateorSssLinkedinBackground" onclick='heateorSssPopup("http://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Feloquent.blog%2F2020%2F04%2Fstochastic-gradient-descent-on-your-microcontroller%2F&title=Stochastic%20Gradient%20Descent%20on%20your%20microcontroller")'><ss style="display:block;border-radius:999px;" class="heateorSssSharingSvg heateorSssLinkedinSvg"></ss></i></li><li class="heateorSssSharingRound"><i style="width:35px;height:35px;border-radius:999px;" title="More" alt="More" class="heateorSssSharing heateorSssMoreBackground" onclick="heateorSssMoreSharingPopup(this, 'https://eloquentarduino.github.io/2020/04/stochastic-gradient-descent-on-your-microcontroller/', 'Stochastic%20Gradient%20Descent%20on%20your%20microcontroller', '' )" ><ss style="display:block" class="heateorSssSharingSvg heateorSssMoreSvg"></ss></i></li></ul><div class="heateorSssClear"></div></div>
<h2>How to use</h2>
<p>The pattern of use is similar to that of the <a href="/2020/04/passive-aggressive-classifier-for-embedded-devices/">Passive Aggressive classifier</a>: you have the <code>fitOne</code> and <code>predict</code> methods.</p>
<p>First of all, <a href="https://github.com/eloquentarduino/EloquentMicroML">download the library from Github</a>.</p>
<pre><code class="language-c">#include &lt;EloquentSGD.h&gt;
#include &lt;EloquentAccuracyScorer.h&gt;
#include &quot;iris.h&quot;

#define VERBOSE

using namespace Eloquent::ML;

void setup() {
    Serial.begin(115200);
    delay(3000);
}

void loop() {
    int trainSamples;
    int retrainingCycles;
    SGD&lt;FEATURES_DIM&gt; clf;
    AccuracyScorer scorer;

    // ....

    // train
    for (uint16_t cycle = 0; cycle &lt; retrainingCycles; cycle++)
        for (uint16_t i = 0; i &lt; trainSamples; i++)
            clf.fitOne(X[i], y[i]);

    // predict
    for (uint16_t i = trainSamples; i &lt; DATASET_SIZE; i++) {
        int predicted = clf.predict(X[i]);
        int actual = y[i];

        scorer.scoreOne(actual, predicted);
    }

    Serial.print(&quot;Accuracy: &quot;);
    Serial.print(round(100 * scorer.accuracy()));
    Serial.print(&quot;% out of &quot;);
    Serial.print(scorer.support());
    Serial.println(&quot; predictions&quot;);
}</code></pre>
<p>In this case we're working with known datasets, so we cycle through them for the training, but if you're learning &quot;on-line&quot;, from samples generated over time, it will work exactly the same.</p>
<h2>A bit of momentum</h2>
<p>Stochastic gradient descent works quite well out of the box in most cases.</p>
<p>Sometimes, however, its updates can start &quot;oscillating&quot;.</p>
<p><img src="https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-1-4842-4470-8_33/MediaObjects/463852_1_En_33_Fig1_HTML.jpg" alt="SGD with and without momentum" /></p>
<p>To solve this problem, it <a href="https://doi.org/10.1038%2F323533a0">has been proposed</a> the <strong>momentum</strong> technique, which can both speed up learning and increase the accuracy.</p>
<p>In my personal tests, I was able to achieve up to +5% in accuracy on the majority of datasets.</p>
<p>To use it, you only need to set a <em>decay factor</em> between 0 and 1.</p>
<pre><code class="language-c">SGD clf;

clf.momentum(0.5);</code></pre>
<h2>Run on your own</h2>
<p>On <a href="https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/SGDExample/SGDExample.ino">Github</a> you can find the full example with some benchmark datasets to try on your own.</p>
<!-- Begin Mailchimp Signup Form -->
<div id="mc_embed_signup">
<form action="https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	<h2 style="margin: 0; text-align: center">Finding this content useful?</h2>
<div class="mc-field-group">
	<input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="join the monthly newsletter">
</div>
	<div id="mce-responses" class="clear">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_f0eaedd94d554cf2ee781742a_37d3496031" tabindex="-1" value=""></div>
    <div class="clear" style="position: relative; top: 8px"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->
<p>The example is interactive an will ask you how many samples to use for the training and how many times to cycle through them.</p>
<p>This is something you should consider: if you have a training set and can store it somehow (in memory or on Flash for example), re-presenting the same samples to the SGD classifier could (and probably will) increase its performance if done correctly.</p>
<p>This happens because the algorithm needs some time to converge and if it doesn't receive enough samples it won't learn properly.</p>
<p>Of course, if you re-use the same samples over and over again, you're likely to overfit.</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/04/stochastic-gradient-descent-on-your-microcontroller/">Stochastic Gradient Descent on your microcontroller</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Passive-aggressive classifier for embedded devices</title>
		<link>https://eloquentarduino.github.io/2020/04/passive-aggressive-classifier-for-embedded-devices/</link>
		
		<dc:creator><![CDATA[simone]]></dc:creator>
		<pubDate>Sun, 05 Apr 2020 17:04:10 +0000</pubDate>
				<category><![CDATA[Arduino Machine learning]]></category>
		<category><![CDATA[microml]]></category>
		<category><![CDATA[online-learning]]></category>
		<guid isPermaLink="false">https://eloquentarduino.github.io/?p=1050</guid>

					<description><![CDATA[<p>When working with memory constrained devices you may not able to keep all the training data in memory: passive-aggressive classifiers may help solve your memory problems. Batch learning A couple weeks ago I started exploring the possibility to train a machine learning classifier directly on a microcontroller. Since I like SVM, I ported the simplified [&#8230;]</p>
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/04/passive-aggressive-classifier-for-embedded-devices/">Passive-aggressive classifier for embedded devices</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>When working with memory constrained devices you may not able to keep all the training data in memory: passive-aggressive classifiers may help solve your memory problems.</p>
<p><span id="more-1050"></span></p>
<h2>Batch learning</h2>
<p>A couple weeks ago I started exploring the possibility to train a machine learning classifier directly on a microcontroller. Since I like SVM, <a href="/2020/03/so-you-want-to-train-an-ml-classifier-directly-on-an-arduino-board">I ported the simplified SVM SMO (Sequential Minimal Optimization) algorithm</a> to plain C, ready to be deployed to embedded devices.</p>
<p>Now, that kind of algorithm works in the so-called &quot;batch-mode&quot;: it needs all the training data to be available in memory to learn.</p>
<p>This may be a limiting factor on resource-constrained devices, since it poses an upper bound to the number of samples you can train on. And when working with high-dimensional datasets, the number of samples could be not enough to achieve good accuracy.</p>
<h2>Enter incremental learning</h2>
<p>To solve this limitation, you need a totally different kind of learning algorithms: you need incremental (a.k.a online a.k.a out of core) learning.</p>
<p>Incremental learning works by inspecting one training sample at a time, instead of all at once.</p>
<p>The clear advantage is that you have a tiny memory footprint. And this is a <strong>huge</strong> advantage.</p>
<p>The clear disadvantage is that you don't have the &quot;big picture&quot; of your data, so:</p>
<ul>
<li>the end result will probably be affected by the order of presentation of the samples</li>
<li>you may not be able to achieve top accuracy</li>
</ul>
<h2>Passive-aggressive classifier</h2>
<p>Passive-aggressive classification is one of the available incremental learning algorithms and it is very simple to implement, since it has a closed-form update rule.</p>
<p>Please refer to this <a href="https://www.bonaccorso.eu/2017/10/06/ml-algorithms-addendum-passive-aggressive-algorithms/">short explanation on Passive-aggressive classifiers</a> for a nice description with images.</p>
<p>The core concept is that the classifier adjusts it weight vector for each mis-classified training sample it receives, trying to get it correct.</p>
<p><img src="https://eloquentarduino.github.io/wp-content/uploads/2020/04/passive-aggressive-classifier.png" alt="Passive aggressive classifier" /></p>
<h2>Benchmarks</h2>
<p>I run a couple benchmark on my Esp32 to assess both accuracy and training time.</p>
<p>First of all: <strong>it is fast!</strong>. When I say it is fast I mean it takes ~1ms to train on 400 samples x 30 features each.</p>
<p>Talking about accuracy instead... Uhm...</p>
<p>Accuracy vary. <strong>Greatly</strong>. </p>
<p>You can achieve 100% on some datasets. </p>
<p>And 40% on others. But on those same datasets you can achieve &gt;85% if training on a different number of samples. Or in a different order.</p>
<p>I guess this is the tradeoff for such a simple and space-efficient algorithm.</p>
<p>I report my results in the following table. It is not meant to be an exhaustive benchmark of the classifier, since those number will vary based on the order of presentation, but still you can get an idea of what it is able to achieve.</p>
<table>
<thead>
<tr>
<th>Dataset size</th>
<th style="text-align: center;">Train samples</th>
<th style="text-align: right;">Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td>BREAST CANCER</td>
<td style="text-align: center;"></td>
<td style="text-align: right;"></td>
</tr>
<tr>
<td>567 samples</td>
<td style="text-align: center;">20</td>
<td style="text-align: right;">62</td>
</tr>
<tr>
<td>30 features</td>
<td style="text-align: center;">40</td>
<td style="text-align: right;">37</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">60</td>
<td style="text-align: right;">63</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">100</td>
<td style="text-align: right;">39</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">150</td>
<td style="text-align: right;">38</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">200</td>
<td style="text-align: right;">64</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">250</td>
<td style="text-align: right;">61</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">300</td>
<td style="text-align: right;">69</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">350</td>
<td style="text-align: right;">73</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">400</td>
<td style="text-align: right;">85</td>
</tr>
<tr>
<td>IRIS</td>
<td style="text-align: center;"></td>
<td style="text-align: right;"></td>
</tr>
<tr>
<td>100 samples</td>
<td style="text-align: center;">10</td>
<td style="text-align: right;">50</td>
</tr>
<tr>
<td>4 features</td>
<td style="text-align: center;">20</td>
<td style="text-align: right;">51</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">40</td>
<td style="text-align: right;">100</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">60</td>
<td style="text-align: right;">100</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">80</td>
<td style="text-align: right;">100</td>
</tr>
<tr>
<td>DIGITS</td>
<td style="text-align: center;"></td>
<td style="text-align: right;"></td>
</tr>
<tr>
<td>358 samples</td>
<td style="text-align: center;">20</td>
<td style="text-align: right;">98</td>
</tr>
<tr>
<td>64 features</td>
<td style="text-align: center;">40</td>
<td style="text-align: right;">98</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">60</td>
<td style="text-align: right;">99</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">100</td>
<td style="text-align: right;">100</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">150</td>
<td style="text-align: right;">100</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">200</td>
<td style="text-align: right;">99</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">250</td>
<td style="text-align: right;">98</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">300</td>
<td style="text-align: right;">95</td>
</tr>
<tr>
<td>CLEVELAND HEART DISEASE</td>
<td style="text-align: center;"></td>
<td style="text-align: right;"></td>
</tr>
<tr>
<td>212 samples</td>
<td style="text-align: center;">20</td>
<td style="text-align: right;">76</td>
</tr>
<tr>
<td>13 features</td>
<td style="text-align: center;">40</td>
<td style="text-align: right;">24</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">60</td>
<td style="text-align: right;">77</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">100</td>
<td style="text-align: right;">19</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">120</td>
<td style="text-align: right;">82</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">140</td>
<td style="text-align: right;">78</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;">180</td>
<td style="text-align: right;">88</td>
</tr>
</tbody>
</table>
<h2>Time to code</h2>
<p>Here I'll report an extract of the example code you can find on <a href="https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/PassiveAggressiveExample/PassiveAggressiveExample.ino">Github</a> for this classifier.</p>
<pre><code class="language-c">#include &lt;EloquentPassiveAggressiveClassifier.h&gt;
#include &lt;EloquentAccuracyScorer.h&gt;
#include &quot;iris.h&quot;

using namespace Eloquent::ML;

void loop() {
    int trainSamples;
    PassiveAggressiveClassifier&lt;FEATURES_DIM&gt; clf;
    AccuracyScorer scorer;

    trainSamples = readSerialNumber(&quot;How many samples will you use as training?&quot;, DATASET_SIZE - 2);

    if (trainSamples == 0)
        return;

    clf.setC(1);

    // train
    for (uint16_t i = 0; i &lt; trainSamples; i++)
        clf.fitOne(X[i], y[i]);

    // predict
    for (uint16_t i = trainSamples; i &lt; DATASET_SIZE; i++) {
        int predicted = clf.predict(X[i]);
        int actual = y[i] &gt; 0 ? 1 : -1;

        scorer.scoreOne(actual, predicted);
    }

    Serial.print(&quot;Accuracy: &quot;);
    Serial.print(round(100 * scorer.accuracy()));
    Serial.print(&quot;% out of &quot;);
    Serial.print(scorer.support());
    Serial.println(&quot; predictions&quot;);
}</code></pre>
<hr />
<p>On the <a href="https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/PassiveAggressiveExample/PassiveAggressiveExample.ino">project page</a> you will find the code to reproduce these numbers.</p>
<hr />
<p>L'articolo <a rel="nofollow" href="https://eloquentarduino.github.io/2020/04/passive-aggressive-classifier-for-embedded-devices/">Passive-aggressive classifier for embedded devices</a> proviene da <a rel="nofollow" href="http://eloquentarduino.github.io/">Eloquent Arduino Blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
